##### 2023年计算机视觉和模式识别领域的顶级会议。

CVPR

super resolution

[ResFormer: Scaling ViTs With Multi-Resolution Training](https://openaccess.thecvf.com/content/CVPR2023/html/Tian_ResFormer_Scaling_ViTs_With_Multi-Resolution_Training_CVPR_2023_paper.html)

[Rui Tian](https://openaccess.thecvf.com/CVPR2023#), [Zuxuan Wu](https://openaccess.thecvf.com/CVPR2023#), [Qi Dai](https://openaccess.thecvf.com/CVPR2023#), [Han Hu](https://openaccess.thecvf.com/CVPR2023#), [Yu Qiao](https://openaccess.thecvf.com/CVPR2023#), [Yu-Gang Jiang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Tian_ResFormer_Scaling_ViTs_With_Multi-Resolution_Training_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Tian_ResFormer_Scaling_ViTs_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.00776)] 

[bibtex]


[Ultra-High Resolution Segmentation With Ultra-Rich Context: A Novel Benchmark](https://openaccess.thecvf.com/content/CVPR2023/html/Ji_Ultra-High_Resolution_Segmentation_With_Ultra-Rich_Context_A_Novel_Benchmark_CVPR_2023_paper.html)

[Deyi Ji](https://openaccess.thecvf.com/CVPR2023#), [Feng Zhao](https://openaccess.thecvf.com/CVPR2023#), [Hongtao Lu](https://openaccess.thecvf.com/CVPR2023#), [Mingyuan Tao](https://openaccess.thecvf.com/CVPR2023#), [Jieping Ye](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Ji_Ultra-High_Resolution_Segmentation_With_Ultra-Rich_Context_A_Novel_Benchmark_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2305.10899)] 

[bibtex]


[Towards High-Quality and Efficient Video Super-Resolution via Spatial-Temporal Data Overfitting](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Towards_High-Quality_and_Efficient_Video_Super-Resolution_via_Spatial-Temporal_Data_Overfitting_CVPR_2023_paper.html)

[Gen Li](https://openaccess.thecvf.com/CVPR2023#), [Jie Ji](https://openaccess.thecvf.com/CVPR2023#), [Minghai Qin](https://openaccess.thecvf.com/CVPR2023#), [Wei Niu](https://openaccess.thecvf.com/CVPR2023#), [Bin Ren](https://openaccess.thecvf.com/CVPR2023#), [Fatemeh Afghah](https://openaccess.thecvf.com/CVPR2023#), [Linke Guo](https://openaccess.thecvf.com/CVPR2023#), [Xiaolong Ma](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Towards_High-Quality_and_Efficient_Video_Super-Resolution_via_Spatial-Temporal_Data_Overfitting_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.08331)] 

[bibtex]


[Spectral Bayesian Uncertainty for Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Spectral_Bayesian_Uncertainty_for_Image_Super-Resolution_CVPR_2023_paper.html)

[Tao Liu](https://openaccess.thecvf.com/CVPR2023#), [Jun Cheng](https://openaccess.thecvf.com/CVPR2023#), [Shan Tan](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Spectral_Bayesian_Uncertainty_for_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Liu_Spectral_Bayesian_Uncertainty_CVPR_2023_supplemental.pdf)] 

[bibtex]


[High-Fidelity 3D Human Digitization From Single 2K Resolution Images](https://openaccess.thecvf.com/content/CVPR2023/html/Han_High-Fidelity_3D_Human_Digitization_From_Single_2K_Resolution_Images_CVPR_2023_paper.html)

[Sang-Hun Han](https://openaccess.thecvf.com/CVPR2023#), [Min-Gyu Park](https://openaccess.thecvf.com/CVPR2023#), [Ju Hong Yoon](https://openaccess.thecvf.com/CVPR2023#), [Ju-Mi Kang](https://openaccess.thecvf.com/CVPR2023#), [Young-Jae Park](https://openaccess.thecvf.com/CVPR2023#), [Hae-Gon Jeon](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Han_High-Fidelity_3D_Human_Digitization_From_Single_2K_Resolution_Images_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Han_High-Fidelity_3D_Human_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.15108)] 

[bibtex]


[Automatic High Resolution Wire Segmentation and Removal](https://openaccess.thecvf.com/content/CVPR2023/html/Chiu_Automatic_High_Resolution_Wire_Segmentation_and_Removal_CVPR_2023_paper.html)

[Mang Tik Chiu](https://openaccess.thecvf.com/CVPR2023#), [Xuaner Zhang](https://openaccess.thecvf.com/CVPR2023#), [Zijun Wei](https://openaccess.thecvf.com/CVPR2023#), [Yuqian Zhou](https://openaccess.thecvf.com/CVPR2023#), [Eli Shechtman](https://openaccess.thecvf.com/CVPR2023#), [Connelly Barnes](https://openaccess.thecvf.com/CVPR2023#), [Zhe Lin](https://openaccess.thecvf.com/CVPR2023#), [Florian Kainz](https://openaccess.thecvf.com/CVPR2023#), [Sohrab Amirghodsi](https://openaccess.thecvf.com/CVPR2023#), [Humphrey Shi](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chiu_Automatic_High_Resolution_Wire_Segmentation_and_Removal_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chiu_Automatic_High_Resolution_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.00221)] 

[bibtex]


[RefSR-NeRF: Towards High Fidelity and Super Resolution View Synthesis](https://openaccess.thecvf.com/content/CVPR2023/html/Huang_RefSR-NeRF_Towards_High_Fidelity_and_Super_Resolution_View_Synthesis_CVPR_2023_paper.html)

[Xudong Huang](https://openaccess.thecvf.com/CVPR2023#), [Wei Li](https://openaccess.thecvf.com/CVPR2023#), [Jie Hu](https://openaccess.thecvf.com/CVPR2023#), [Hanting Chen](https://openaccess.thecvf.com/CVPR2023#), [Yunhe Wang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_RefSR-NeRF_Towards_High_Fidelity_and_Super_Resolution_View_Synthesis_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Huang_RefSR-NeRF_Towards_High_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Self-Supervised Super-Plane for Neural 3D Reconstruction](https://openaccess.thecvf.com/content/CVPR2023/html/Ye_Self-Supervised_Super-Plane_for_Neural_3D_Reconstruction_CVPR_2023_paper.html)

[Botao Ye](https://openaccess.thecvf.com/CVPR2023#), [Sifei Liu](https://openaccess.thecvf.com/CVPR2023#), [Xueting Li](https://openaccess.thecvf.com/CVPR2023#), [Ming-Hsuan Yang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_Self-Supervised_Super-Plane_for_Neural_3D_Reconstruction_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Ye_Self-Supervised_Super-Plane_for_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Cross-Guided Optimization of Radiance Fields With Multi-View Image Super-Resolution for High-Resolution Novel View Synthesis](https://openaccess.thecvf.com/content/CVPR2023/html/Yoon_Cross-Guided_Optimization_of_Radiance_Fields_With_Multi-View_Image_Super-Resolution_for_CVPR_2023_paper.html)

[Youngho Yoon](https://openaccess.thecvf.com/CVPR2023#), [Kuk-Jin Yoon](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yoon_Cross-Guided_Optimization_of_Radiance_Fields_With_Multi-View_Image_Super-Resolution_for_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yoon_Cross-Guided_Optimization_of_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Compression-Aware Video Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Compression-Aware_Video_Super-Resolution_CVPR_2023_paper.html)

[Yingwei Wang](https://openaccess.thecvf.com/CVPR2023#), [Takashi Isobe](https://openaccess.thecvf.com/CVPR2023#), [Xu Jia](https://openaccess.thecvf.com/CVPR2023#), [Xin Tao](https://openaccess.thecvf.com/CVPR2023#), [Huchuan Lu](https://openaccess.thecvf.com/CVPR2023#), [Yu-Wing Tai](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Compression-Aware_Video_Super-Resolution_CVPR_2023_paper.pdf)] 

[bibtex]


[Guided Depth Super-Resolution by Deep Anisotropic Diffusion](https://openaccess.thecvf.com/content/CVPR2023/html/Metzger_Guided_Depth_Super-Resolution_by_Deep_Anisotropic_Diffusion_CVPR_2023_paper.html)

[Nando Metzger](https://openaccess.thecvf.com/CVPR2023#), [Rodrigo Caye Daudt](https://openaccess.thecvf.com/CVPR2023#), [Konrad Schindler](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Metzger_Guided_Depth_Super-Resolution_by_Deep_Anisotropic_Diffusion_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Metzger_Guided_Depth_Super-Resolution_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2211.11592)] 

[bibtex]


[Recognizability Embedding Enhancement for Very Low-Resolution Face Recognition and Quality Estimation](https://openaccess.thecvf.com/content/CVPR2023/html/Chai_Recognizability_Embedding_Enhancement_for_Very_Low-Resolution_Face_Recognition_and_Quality_CVPR_2023_paper.html)

[Jacky Chen Long Chai](https://openaccess.thecvf.com/CVPR2023#), [Tiong-Sik Ng](https://openaccess.thecvf.com/CVPR2023#), [Cheng-Yaw Low](https://openaccess.thecvf.com/CVPR2023#), [Jaewoo Park](https://openaccess.thecvf.com/CVPR2023#), [Andrew Beng Jin Teoh](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chai_Recognizability_Embedding_Enhancement_for_Very_Low-Resolution_Face_Recognition_and_Quality_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chai_Recognizability_Embedding_Enhancement_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.10066)] 

[bibtex]


[CutMIB: Boosting Light Field Super-Resolution via Multi-View Image Blending](https://openaccess.thecvf.com/content/CVPR2023/html/Xiao_CutMIB_Boosting_Light_Field_Super-Resolution_via_Multi-View_Image_Blending_CVPR_2023_paper.html)

[Zeyu Xiao](https://openaccess.thecvf.com/CVPR2023#), [Yutong Liu](https://openaccess.thecvf.com/CVPR2023#), [Ruisheng Gao](https://openaccess.thecvf.com/CVPR2023#), [Zhiwei Xiong](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xiao_CutMIB_Boosting_Light_Field_Super-Resolution_via_Multi-View_Image_Blending_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xiao_CutMIB_Boosting_Light_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Spring: A High-Resolution High-Detail Dataset and Benchmark for Scene Flow, Optical Flow and Stereo](https://openaccess.thecvf.com/content/CVPR2023/html/Mehl_Spring_A_High-Resolution_High-Detail_Dataset_and_Benchmark_for_Scene_Flow_CVPR_2023_paper.html)

[Lukas Mehl](https://openaccess.thecvf.com/CVPR2023#), [Jenny Schmalfuss](https://openaccess.thecvf.com/CVPR2023#), [Azin Jahedi](https://openaccess.thecvf.com/CVPR2023#), [Yaroslava Nalivayko](https://openaccess.thecvf.com/CVPR2023#), [Andrés Bruhn](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Mehl_Spring_A_High-Resolution_High-Detail_Dataset_and_Benchmark_for_Scene_Flow_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Mehl_Spring_A_High-Resolution_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.01943)] 

[bibtex]


[MAESTER: Masked Autoencoder Guided Segmentation at Pixel Resolution for Accurate, Self-Supervised Subcellular Structure Recognition](https://openaccess.thecvf.com/content/CVPR2023/html/Xie_MAESTER_Masked_Autoencoder_Guided_Segmentation_at_Pixel_Resolution_for_Accurate_CVPR_2023_paper.html)

[Ronald Xie](https://openaccess.thecvf.com/CVPR2023#), [Kuan Pang](https://openaccess.thecvf.com/CVPR2023#), [Gary D. Bader](https://openaccess.thecvf.com/CVPR2023#), [Bo Wang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_MAESTER_Masked_Autoencoder_Guided_Segmentation_at_Pixel_Resolution_for_Accurate_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xie_MAESTER_Masked_Autoencoder_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Image Super-Resolution Using T-Tetromino Pixels](https://openaccess.thecvf.com/content/CVPR2023/html/Grosche_Image_Super-Resolution_Using_T-Tetromino_Pixels_CVPR_2023_paper.html)

[Simon Grosche](https://openaccess.thecvf.com/CVPR2023#), [Andy Regensky](https://openaccess.thecvf.com/CVPR2023#), [Jürgen Seiler](https://openaccess.thecvf.com/CVPR2023#), [André Kaup](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Grosche_Image_Super-Resolution_Using_T-Tetromino_Pixels_CVPR_2023_paper.pdf)] 

[bibtex]


[Toward Accurate Post-Training Quantization for Image Super Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Tu_Toward_Accurate_Post-Training_Quantization_for_Image_Super_Resolution_CVPR_2023_paper.html)

[Zhijun Tu](https://openaccess.thecvf.com/CVPR2023#), [Jie Hu](https://openaccess.thecvf.com/CVPR2023#), [Hanting Chen](https://openaccess.thecvf.com/CVPR2023#), [Yunhe Wang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Tu_Toward_Accurate_Post-Training_Quantization_for_Image_Super_Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Tu_Toward_Accurate_Post-Training_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Implicit Diffusion Models for Continuous Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Gao_Implicit_Diffusion_Models_for_Continuous_Super-Resolution_CVPR_2023_paper.html)

[Sicheng Gao](https://openaccess.thecvf.com/CVPR2023#), [Xuhui Liu](https://openaccess.thecvf.com/CVPR2023#), [Bohan Zeng](https://openaccess.thecvf.com/CVPR2023#), [Sheng Xu](https://openaccess.thecvf.com/CVPR2023#), [Yanjing Li](https://openaccess.thecvf.com/CVPR2023#), [Xiaoyan Luo](https://openaccess.thecvf.com/CVPR2023#), [Jianzhuang Liu](https://openaccess.thecvf.com/CVPR2023#), [Xiantong Zhen](https://openaccess.thecvf.com/CVPR2023#), [Baochang Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Gao_Implicit_Diffusion_Models_for_Continuous_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Gao_Implicit_Diffusion_Models_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.16491)] 

[bibtex]


[Correspondence Transformers With Asymmetric Feature Learning and Matching Flow Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Sun_Correspondence_Transformers_With_Asymmetric_Feature_Learning_and_Matching_Flow_Super-Resolution_CVPR_2023_paper.html)

[Yixuan Sun](https://openaccess.thecvf.com/CVPR2023#), [Dongyang Zhao](https://openaccess.thecvf.com/CVPR2023#), [Zhangyue Yin](https://openaccess.thecvf.com/CVPR2023#), [Yiwen Huang](https://openaccess.thecvf.com/CVPR2023#), [Tao Gui](https://openaccess.thecvf.com/CVPR2023#), [Wenqiang Zhang](https://openaccess.thecvf.com/CVPR2023#), [Weifeng Ge](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Correspondence_Transformers_With_Asymmetric_Feature_Learning_and_Matching_Flow_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Sun_Correspondence_Transformers_With_CVPR_2023_supplemental.pdf)] 

[bibtex]


[UMat: Uncertainty-Aware Single Image High Resolution Material Capture](https://openaccess.thecvf.com/content/CVPR2023/html/Rodriguez-Pardo_UMat_Uncertainty-Aware_Single_Image_High_Resolution_Material_Capture_CVPR_2023_paper.html)

[Carlos Rodriguez-Pardo](https://openaccess.thecvf.com/CVPR2023#), [Henar Domínguez-Elvira](https://openaccess.thecvf.com/CVPR2023#), [David Pascual-Hernández](https://openaccess.thecvf.com/CVPR2023#), [Elena Garces](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Rodriguez-Pardo_UMat_Uncertainty-Aware_Single_Image_High_Resolution_Material_Capture_CVPR_2023_paper.pdf)] 

[bibtex]


[Rethinking Image Super Resolution From Long-Tailed Distribution Learning Perspective](https://openaccess.thecvf.com/content/CVPR2023/html/Gou_Rethinking_Image_Super_Resolution_From_Long-Tailed_Distribution_Learning_Perspective_CVPR_2023_paper.html)

[Yuanbiao Gou](https://openaccess.thecvf.com/CVPR2023#), [Peng Hu](https://openaccess.thecvf.com/CVPR2023#), [Jiancheng Lv](https://openaccess.thecvf.com/CVPR2023#), [Hongyuan Zhu](https://openaccess.thecvf.com/CVPR2023#), [Xi Peng](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Gou_Rethinking_Image_Super_Resolution_From_Long-Tailed_Distribution_Learning_Perspective_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Gou_Rethinking_Image_Super_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Azimuth Super-Resolution for FMCW Radar in Autonomous Driving](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Azimuth_Super-Resolution_for_FMCW_Radar_in_Autonomous_Driving_CVPR_2023_paper.html)

[Yu-Jhe Li](https://openaccess.thecvf.com/CVPR2023#), [Shawn Hunt](https://openaccess.thecvf.com/CVPR2023#), [Jinhyung Park](https://openaccess.thecvf.com/CVPR2023#), [Matthew O’Toole](https://openaccess.thecvf.com/CVPR2023#), [Kris Kitani](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Azimuth_Super-Resolution_for_FMCW_Radar_in_Autonomous_Driving_CVPR_2023_paper.pdf)] 

[bibtex]


[Magic3D: High-Resolution Text-to-3D Content Creation](https://openaccess.thecvf.com/content/CVPR2023/html/Lin_Magic3D_High-Resolution_Text-to-3D_Content_Creation_CVPR_2023_paper.html)

[Chen-Hsuan Lin](https://openaccess.thecvf.com/CVPR2023#), [Jun Gao](https://openaccess.thecvf.com/CVPR2023#), [Luming Tang](https://openaccess.thecvf.com/CVPR2023#), [Towaki Takikawa](https://openaccess.thecvf.com/CVPR2023#), [Xiaohui Zeng](https://openaccess.thecvf.com/CVPR2023#), [Xun Huang](https://openaccess.thecvf.com/CVPR2023#), [Karsten Kreis](https://openaccess.thecvf.com/CVPR2023#), [Sanja Fidler](https://openaccess.thecvf.com/CVPR2023#), [Ming-Yu Liu](https://openaccess.thecvf.com/CVPR2023#), [Tsung-Yi Lin](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Magic3D_High-Resolution_Text-to-3D_Content_Creation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Lin_Magic3D_High-Resolution_Text-to-3D_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.10440)] 

[bibtex]


[Spatial-Frequency Mutual Learning for Face Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Spatial-Frequency_Mutual_Learning_for_Face_Super-Resolution_CVPR_2023_paper.html)

[Chenyang Wang](https://openaccess.thecvf.com/CVPR2023#), [Junjun Jiang](https://openaccess.thecvf.com/CVPR2023#), [Zhiwei Zhong](https://openaccess.thecvf.com/CVPR2023#), [Xianming Liu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Spatial-Frequency_Mutual_Learning_for_Face_Super-Resolution_CVPR_2023_paper.pdf)] 

[bibtex]


[Super-CLEVR: A Virtual Benchmark To Diagnose Domain Robustness in Visual Reasoning](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Super-CLEVR_A_Virtual_Benchmark_To_Diagnose_Domain_Robustness_in_Visual_CVPR_2023_paper.html)

[Zhuowan Li](https://openaccess.thecvf.com/CVPR2023#), [Xingrui Wang](https://openaccess.thecvf.com/CVPR2023#), [Elias Stengel-Eskin](https://openaccess.thecvf.com/CVPR2023#), [Adam Kortylewski](https://openaccess.thecvf.com/CVPR2023#), [Wufei Ma](https://openaccess.thecvf.com/CVPR2023#), [Benjamin Van Durme](https://openaccess.thecvf.com/CVPR2023#), [Alan L. Yuille](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Super-CLEVR_A_Virtual_Benchmark_To_Diagnose_Domain_Robustness_in_Visual_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_Super-CLEVR_A_Virtual_CVPR_2023_supplemental.zip)] 

[bibtex]


[B-Spline Texture Coefficients Estimator for Screen Content Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Pak_B-Spline_Texture_Coefficients_Estimator_for_Screen_Content_Image_Super-Resolution_CVPR_2023_paper.html)

[Byeonghyun Pak](https://openaccess.thecvf.com/CVPR2023#), [Jaewon Lee](https://openaccess.thecvf.com/CVPR2023#), [Kyong Hwan Jin](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Pak_B-Spline_Texture_Coefficients_Estimator_for_Screen_Content_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Pak_B-Spline_Texture_Coefficients_CVPR_2023_supplemental.pdf)] 

[bibtex]


[CABM: Content-Aware Bit Mapping for Single Image Super-Resolution Network With Large Input](https://openaccess.thecvf.com/content/CVPR2023/html/Tian_CABM_Content-Aware_Bit_Mapping_for_Single_Image_Super-Resolution_Network_With_CVPR_2023_paper.html)

[Senmao Tian](https://openaccess.thecvf.com/CVPR2023#), [Ming Lu](https://openaccess.thecvf.com/CVPR2023#), [Jiaming Liu](https://openaccess.thecvf.com/CVPR2023#), [Yandong Guo](https://openaccess.thecvf.com/CVPR2023#), [Yurong Chen](https://openaccess.thecvf.com/CVPR2023#), [Shunli Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Tian_CABM_Content-Aware_Bit_Mapping_for_Single_Image_Super-Resolution_Network_With_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2304.06454)] 

[bibtex]


[Bi-Directional Feature Fusion Generative Adversarial Network for Ultra-High Resolution Pathological Image Virtual Re-Staining](https://openaccess.thecvf.com/content/CVPR2023/html/Sun_Bi-Directional_Feature_Fusion_Generative_Adversarial_Network_for_Ultra-High_Resolution_Pathological_CVPR_2023_paper.html)

[Kexin Sun](https://openaccess.thecvf.com/CVPR2023#), [Zhineng Chen](https://openaccess.thecvf.com/CVPR2023#), [Gongwei Wang](https://openaccess.thecvf.com/CVPR2023#), [Jun Liu](https://openaccess.thecvf.com/CVPR2023#), [Xiongjun Ye](https://openaccess.thecvf.com/CVPR2023#), [Yu-Gang Jiang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Bi-Directional_Feature_Fusion_Generative_Adversarial_Network_for_Ultra-High_Resolution_Pathological_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Sun_Bi-Directional_Feature_Fusion_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Memory-Friendly Scalable Super-Resolution via Rewinding Lottery Ticket Hypothesis](https://openaccess.thecvf.com/content/CVPR2023/html/Lin_Memory-Friendly_Scalable_Super-Resolution_via_Rewinding_Lottery_Ticket_Hypothesis_CVPR_2023_paper.html)

[Jin Lin](https://openaccess.thecvf.com/CVPR2023#), [Xiaotong Luo](https://openaccess.thecvf.com/CVPR2023#), [Ming Hong](https://openaccess.thecvf.com/CVPR2023#), [Yanyun Qu](https://openaccess.thecvf.com/CVPR2023#), [Yuan Xie](https://openaccess.thecvf.com/CVPR2023#), [Zongze Wu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Memory-Friendly_Scalable_Super-Resolution_via_Rewinding_Lottery_Ticket_Hypothesis_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Lin_Memory-Friendly_Scalable_Super-Resolution_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Structured Sparsity Learning for Efficient Video Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Xia_Structured_Sparsity_Learning_for_Efficient_Video_Super-Resolution_CVPR_2023_paper.html)

[Bin Xia](https://openaccess.thecvf.com/CVPR2023#), [Jingwen He](https://openaccess.thecvf.com/CVPR2023#), [Yulun Zhang](https://openaccess.thecvf.com/CVPR2023#), [Yitong Wang](https://openaccess.thecvf.com/CVPR2023#), [Yapeng Tian](https://openaccess.thecvf.com/CVPR2023#), [Wenming Yang](https://openaccess.thecvf.com/CVPR2023#), [Luc Van Gool](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xia_Structured_Sparsity_Learning_for_Efficient_Video_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xia_Structured_Sparsity_Learning_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2206.07687)] 

[bibtex]


[Omni Aggregation Networks for Lightweight Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Omni_Aggregation_Networks_for_Lightweight_Image_Super-Resolution_CVPR_2023_paper.html)

[Hang Wang](https://openaccess.thecvf.com/CVPR2023#), [Xuanhong Chen](https://openaccess.thecvf.com/CVPR2023#), [Bingbing Ni](https://openaccess.thecvf.com/CVPR2023#), [Yutian Liu](https://openaccess.thecvf.com/CVPR2023#), [Jinfan Liu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Omni_Aggregation_Networks_for_Lightweight_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Omni_Aggregation_Networks_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.10244)] 

[bibtex]


[OSRT: Omnidirectional Image Super-Resolution With Distortion-Aware Transformer](https://openaccess.thecvf.com/content/CVPR2023/html/Yu_OSRT_Omnidirectional_Image_Super-Resolution_With_Distortion-Aware_Transformer_CVPR_2023_paper.html)

[Fanghua Yu](https://openaccess.thecvf.com/CVPR2023#), [Xintao Wang](https://openaccess.thecvf.com/CVPR2023#), [Mingdeng Cao](https://openaccess.thecvf.com/CVPR2023#), [Gen Li](https://openaccess.thecvf.com/CVPR2023#), [Ying Shan](https://openaccess.thecvf.com/CVPR2023#), [Chao Dong](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_OSRT_Omnidirectional_Image_Super-Resolution_With_Distortion-Aware_Transformer_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yu_OSRT_Omnidirectional_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.03453)] 

[bibtex]


[SuperDisco: Super-Class Discovery Improves Visual Recognition for the Long-Tail](https://openaccess.thecvf.com/content/CVPR2023/html/Du_SuperDisco_Super-Class_Discovery_Improves_Visual_Recognition_for_the_Long-Tail_CVPR_2023_paper.html)

[Yingjun Du](https://openaccess.thecvf.com/CVPR2023#), [Jiayi Shen](https://openaccess.thecvf.com/CVPR2023#), [Xiantong Zhen](https://openaccess.thecvf.com/CVPR2023#), [Cees G. M. Snoek](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Du_SuperDisco_Super-Class_Discovery_Improves_Visual_Recognition_for_the_Long-Tail_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Du_SuperDisco_Super-Class_Discovery_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.00101)] 

[bibtex]


[Human Guided Ground-Truth Generation for Realistic Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Human_Guided_Ground-Truth_Generation_for_Realistic_Image_Super-Resolution_CVPR_2023_paper.html)

[Du Chen](https://openaccess.thecvf.com/CVPR2023#), [Jie Liang](https://openaccess.thecvf.com/CVPR2023#), [Xindong Zhang](https://openaccess.thecvf.com/CVPR2023#), [Ming Liu](https://openaccess.thecvf.com/CVPR2023#), [Hui Zeng](https://openaccess.thecvf.com/CVPR2023#), [Lei Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Human_Guided_Ground-Truth_Generation_for_Realistic_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chen_Human_Guided_Ground-Truth_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.13069)] 

[bibtex]


[Learning Generative Structure Prior for Blind Text Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Learning_Generative_Structure_Prior_for_Blind_Text_Image_Super-Resolution_CVPR_2023_paper.html)

[Xiaoming Li](https://openaccess.thecvf.com/CVPR2023#), [Wangmeng Zuo](https://openaccess.thecvf.com/CVPR2023#), [Chen Change Loy](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Learning_Generative_Structure_Prior_for_Blind_Text_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_Learning_Generative_Structure_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.14726)] 

[bibtex]


[Super-Resolution Neural Operator](https://openaccess.thecvf.com/content/CVPR2023/html/Wei_Super-Resolution_Neural_Operator_CVPR_2023_paper.html)

[Min Wei](https://openaccess.thecvf.com/CVPR2023#), [Xuesong Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_Super-Resolution_Neural_Operator_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wei_Super-Resolution_Neural_Operator_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.02584)] 

[bibtex]


[PyramidFlow: High-Resolution Defect Contrastive Localization Using Pyramid Normalizing Flow](https://openaccess.thecvf.com/content/CVPR2023/html/Lei_PyramidFlow_High-Resolution_Defect_Contrastive_Localization_Using_Pyramid_Normalizing_Flow_CVPR_2023_paper.html)

[Jiarui Lei](https://openaccess.thecvf.com/CVPR2023#), [Xiaobo Hu](https://openaccess.thecvf.com/CVPR2023#), [Yue Wang](https://openaccess.thecvf.com/CVPR2023#), [Dong Liu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Lei_PyramidFlow_High-Resolution_Defect_Contrastive_Localization_Using_Pyramid_Normalizing_Flow_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Lei_PyramidFlow_High-Resolution_Defect_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.02595)] 

[bibtex]


[OPE-SR: Orthogonal Position Encoding for Designing a Parameter-Free Upsampling Module in Arbitrary-Scale Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Song_OPE-SR_Orthogonal_Position_Encoding_for_Designing_a_Parameter-Free_Upsampling_Module_CVPR_2023_paper.html)

[Gaochao Song](https://openaccess.thecvf.com/CVPR2023#), [Qian Sun](https://openaccess.thecvf.com/CVPR2023#), [Luo Zhang](https://openaccess.thecvf.com/CVPR2023#), [Ran Su](https://openaccess.thecvf.com/CVPR2023#), [Jianfeng Shi](https://openaccess.thecvf.com/CVPR2023#), [Ying He](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Song_OPE-SR_Orthogonal_Position_Encoding_for_Designing_a_Parameter-Free_Upsampling_Module_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Song_OPE-SR_Orthogonal_Position_CVPR_2023_supplemental.pdf)] 

[bibtex]


[PCT-Net: Full Resolution Image Harmonization Using Pixel-Wise Color Transformations](https://openaccess.thecvf.com/content/CVPR2023/html/Guerreiro_PCT-Net_Full_Resolution_Image_Harmonization_Using_Pixel-Wise_Color_Transformations_CVPR_2023_paper.html)

[Julian Jorge Andrade Guerreiro](https://openaccess.thecvf.com/CVPR2023#), [Mitsuru Nakazawa](https://openaccess.thecvf.com/CVPR2023#), [Björn Stenger](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Guerreiro_PCT-Net_Full_Resolution_Image_Harmonization_Using_Pixel-Wise_Color_Transformations_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Guerreiro_PCT-Net_Full_Resolution_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Equivalent Transformation and Dual Stream Network Construction for Mobile Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Chao_Equivalent_Transformation_and_Dual_Stream_Network_Construction_for_Mobile_Image_CVPR_2023_paper.html)

[Jiahao Chao](https://openaccess.thecvf.com/CVPR2023#), [Zhou Zhou](https://openaccess.thecvf.com/CVPR2023#), [Hongfan Gao](https://openaccess.thecvf.com/CVPR2023#), [Jiali Gong](https://openaccess.thecvf.com/CVPR2023#), [Zhengfeng Yang](https://openaccess.thecvf.com/CVPR2023#), [Zhenbing Zeng](https://openaccess.thecvf.com/CVPR2023#), [Lydia Dehbi](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chao_Equivalent_Transformation_and_Dual_Stream_Network_Construction_for_Mobile_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chao_Equivalent_Transformation_and_CVPR_2023_supplemental.pdf)] 

[bibtex]


[High-Resolution Image Reconstruction With Latent Diffusion Models From Human Brain Activity](https://openaccess.thecvf.com/content/CVPR2023/html/Takagi_High-Resolution_Image_Reconstruction_With_Latent_Diffusion_Models_From_Human_Brain_CVPR_2023_paper.html)

[Yu Takagi](https://openaccess.thecvf.com/CVPR2023#), [Shinji Nishimoto](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Takagi_High-Resolution_Image_Reconstruction_With_Latent_Diffusion_Models_From_Human_Brain_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Takagi_High-Resolution_Image_Reconstruction_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Activating More Pixels in Image Super-Resolution Transformer](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Activating_More_Pixels_in_Image_Super-Resolution_Transformer_CVPR_2023_paper.html)

[Xiangyu Chen](https://openaccess.thecvf.com/CVPR2023#), [Xintao Wang](https://openaccess.thecvf.com/CVPR2023#), [Jiantao Zhou](https://openaccess.thecvf.com/CVPR2023#), [Yu Qiao](https://openaccess.thecvf.com/CVPR2023#), [Chao Dong](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Activating_More_Pixels_in_Image_Super-Resolution_Transformer_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chen_Activating_More_Pixels_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2205.04437)] 

[bibtex]


[Better "CMOS" Produces Clearer Images: Learning Space-Variant Blur Estimation for Blind Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Better_CMOS_Produces_Clearer_Images_Learning_Space-Variant_Blur_Estimation_for_CVPR_2023_paper.html)

[Xuhai Chen](https://openaccess.thecvf.com/CVPR2023#), [Jiangning Zhang](https://openaccess.thecvf.com/CVPR2023#), [Chao Xu](https://openaccess.thecvf.com/CVPR2023#), [Yabiao Wang](https://openaccess.thecvf.com/CVPR2023#), [Chengjie Wang](https://openaccess.thecvf.com/CVPR2023#), [Yong Liu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Better_CMOS_Produces_Clearer_Images_Learning_Space-Variant_Blur_Estimation_for_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chen_Better_CMOS_Produces_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.03542)] 

[bibtex]


[Ultrahigh Resolution Image/Video Matting With Spatio-Temporal Sparsity](https://openaccess.thecvf.com/content/CVPR2023/html/Sun_Ultrahigh_Resolution_ImageVideo_Matting_With_Spatio-Temporal_Sparsity_CVPR_2023_paper.html)

[Yanan Sun](https://openaccess.thecvf.com/CVPR2023#), [Chi-Keung Tang](https://openaccess.thecvf.com/CVPR2023#), [Yu-Wing Tai](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Ultrahigh_Resolution_ImageVideo_Matting_With_Spatio-Temporal_Sparsity_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Sun_Ultrahigh_Resolution_ImageVideo_CVPR_2023_supplemental.zip)] 

[bibtex]


[Cascaded Local Implicit Transformer for Arbitrary-Scale Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Cascaded_Local_Implicit_Transformer_for_Arbitrary-Scale_Super-Resolution_CVPR_2023_paper.html)

[Hao-Wei Chen](https://openaccess.thecvf.com/CVPR2023#), [Yu-Syuan Xu](https://openaccess.thecvf.com/CVPR2023#), [Min-Fong Hong](https://openaccess.thecvf.com/CVPR2023#), [Yi-Min Tsai](https://openaccess.thecvf.com/CVPR2023#), [Hsien-Kai Kuo](https://openaccess.thecvf.com/CVPR2023#), [Chun-Yi Lee](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Cascaded_Local_Implicit_Transformer_for_Arbitrary-Scale_Super-Resolution_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.16513)] 

[bibtex]


[SparseViT: Revisiting Activation Sparsity for Efficient High-Resolution Vision Transformer](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_SparseViT_Revisiting_Activation_Sparsity_for_Efficient_High-Resolution_Vision_Transformer_CVPR_2023_paper.html)

[Xuanyao Chen](https://openaccess.thecvf.com/CVPR2023#), [Zhijian Liu](https://openaccess.thecvf.com/CVPR2023#), [Haotian Tang](https://openaccess.thecvf.com/CVPR2023#), [Li Yi](https://openaccess.thecvf.com/CVPR2023#), [Hang Zhao](https://openaccess.thecvf.com/CVPR2023#), [Song Han](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_SparseViT_Revisiting_Activation_Sparsity_for_Efficient_High-Resolution_Vision_Transformer_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.17605)] 

[bibtex]


[Deep Arbitrary-Scale Image Super-Resolution via Scale-Equivariance Pursuit](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Deep_Arbitrary-Scale_Image_Super-Resolution_via_Scale-Equivariance_Pursuit_CVPR_2023_paper.html)

[Xiaohang Wang](https://openaccess.thecvf.com/CVPR2023#), [Xuanhong Chen](https://openaccess.thecvf.com/CVPR2023#), [Bingbing Ni](https://openaccess.thecvf.com/CVPR2023#), [Hang Wang](https://openaccess.thecvf.com/CVPR2023#), [Zhengyan Tong](https://openaccess.thecvf.com/CVPR2023#), [Yutian Liu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Deep_Arbitrary-Scale_Image_Super-Resolution_via_Scale-Equivariance_Pursuit_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Deep_Arbitrary-Scale_Image_CVPR_2023_supplemental.pdf)] 

[bibtex]


[N-Gram in Swin Transformers for Efficient Lightweight Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Choi_N-Gram_in_Swin_Transformers_for_Efficient_Lightweight_Image_Super-Resolution_CVPR_2023_paper.html)

[Haram Choi](https://openaccess.thecvf.com/CVPR2023#), [Jeongmin Lee](https://openaccess.thecvf.com/CVPR2023#), [Jihoon Yang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Choi_N-Gram_in_Swin_Transformers_for_Efficient_Lightweight_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Choi_N-Gram_in_Swin_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Perception-Oriented Single Image Super-Resolution Using Optimal Objective Estimation](https://openaccess.thecvf.com/content/CVPR2023/html/Park_Perception-Oriented_Single_Image_Super-Resolution_Using_Optimal_Objective_Estimation_CVPR_2023_paper.html)

[Seung Ho Park](https://openaccess.thecvf.com/CVPR2023#), [Young Su Moon](https://openaccess.thecvf.com/CVPR2023#), [Nam Ik Cho](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Park_Perception-Oriented_Single_Image_Super-Resolution_Using_Optimal_Objective_Estimation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Park_Perception-Oriented_Single_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.13676)] 

[bibtex]


[Learning Spatial-Temporal Implicit Neural Representations for Event-Guided Video Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Lu_Learning_Spatial-Temporal_Implicit_Neural_Representations_for_Event-Guided_Video_Super-Resolution_CVPR_2023_paper.html)

[Yunfan Lu](https://openaccess.thecvf.com/CVPR2023#), [Zipeng Wang](https://openaccess.thecvf.com/CVPR2023#), [Minjie Liu](https://openaccess.thecvf.com/CVPR2023#), [Hongjian Wang](https://openaccess.thecvf.com/CVPR2023#), [Lin Wang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Lu_Learning_Spatial-Temporal_Implicit_Neural_Representations_for_Event-Guided_Video_Super-Resolution_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.13767)] 

[bibtex]


[Toward Stable, Interpretable, and Lightweight Hyperspectral Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Xie_Toward_Stable_Interpretable_and_Lightweight_Hyperspectral_Super-Resolution_CVPR_2023_paper.html)

[Wen-jin Guo](https://openaccess.thecvf.com/CVPR2023#), [Weiying Xie](https://openaccess.thecvf.com/CVPR2023#), [Kai Jiang](https://openaccess.thecvf.com/CVPR2023#), [Yunsong Li](https://openaccess.thecvf.com/CVPR2023#), [Jie Lei](https://openaccess.thecvf.com/CVPR2023#), [Leyuan Fang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_Toward_Stable_Interpretable_and_Lightweight_Hyperspectral_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xie_Toward_Stable_Interpretable_CVPR_2023_supplemental.pdf)] 

[bibtex]


[CiaoSR: Continuous Implicit Attention-in-Attention Network for Arbitrary-Scale Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Cao_CiaoSR_Continuous_Implicit_Attention-in-Attention_Network_for_Arbitrary-Scale_Image_Super-Resolution_CVPR_2023_paper.html)

[Jiezhang Cao](https://openaccess.thecvf.com/CVPR2023#), [Qin Wang](https://openaccess.thecvf.com/CVPR2023#), [Yongqin Xian](https://openaccess.thecvf.com/CVPR2023#), [Yawei Li](https://openaccess.thecvf.com/CVPR2023#), [Bingbing Ni](https://openaccess.thecvf.com/CVPR2023#), [Zhiming Pi](https://openaccess.thecvf.com/CVPR2023#), [Kai Zhang](https://openaccess.thecvf.com/CVPR2023#), [Yulun Zhang](https://openaccess.thecvf.com/CVPR2023#), [Radu Timofte](https://openaccess.thecvf.com/CVPR2023#), [Luc Van Gool](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_CiaoSR_Continuous_Implicit_Attention-in-Attention_Network_for_Arbitrary-Scale_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Cao_CiaoSR_Continuous_Implicit_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.04362)] 

[bibtex]


[Gated Multi-Resolution Transfer Network for Burst Restoration and Enhancement](https://openaccess.thecvf.com/content/CVPR2023/html/Mehta_Gated_Multi-Resolution_Transfer_Network_for_Burst_Restoration_and_Enhancement_CVPR_2023_paper.html)

[Nancy Mehta](https://openaccess.thecvf.com/CVPR2023#), [Akshay Dudhane](https://openaccess.thecvf.com/CVPR2023#), [Subrahmanyam Murala](https://openaccess.thecvf.com/CVPR2023#), [Syed Waqas Zamir](https://openaccess.thecvf.com/CVPR2023#), [Salman Khan](https://openaccess.thecvf.com/CVPR2023#), [Fahad Shahbaz Khan](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Mehta_Gated_Multi-Resolution_Transfer_Network_for_Burst_Restoration_and_Enhancement_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Mehta_Gated_Multi-Resolution_Transfer_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.06703)] 

[bibtex]


[Consistent Direct Time-of-Flight Video Depth Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Sun_Consistent_Direct_Time-of-Flight_Video_Depth_Super-Resolution_CVPR_2023_paper.html)

[Zhanghao Sun](https://openaccess.thecvf.com/CVPR2023#), [Wei Ye](https://openaccess.thecvf.com/CVPR2023#), [Jinhui Xiong](https://openaccess.thecvf.com/CVPR2023#), [Gyeongmin Choe](https://openaccess.thecvf.com/CVPR2023#), [Jialiang Wang](https://openaccess.thecvf.com/CVPR2023#), [Shuochen Su](https://openaccess.thecvf.com/CVPR2023#), [Rakesh Ranjan](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Consistent_Direct_Time-of-Flight_Video_Depth_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Sun_Consistent_Direct_Time-of-Flight_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.08658)] 

[bibtex]


[Local Implicit Normalizing Flow for Arbitrary-Scale Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Yao_Local_Implicit_Normalizing_Flow_for_Arbitrary-Scale_Image_Super-Resolution_CVPR_2023_paper.html)

[Jie-En Yao](https://openaccess.thecvf.com/CVPR2023#), [Li-Yuan Tsao](https://openaccess.thecvf.com/CVPR2023#), [Yi-Chen Lo](https://openaccess.thecvf.com/CVPR2023#), [Roy Tseng](https://openaccess.thecvf.com/CVPR2023#), [Chia-Che Chang](https://openaccess.thecvf.com/CVPR2023#), [Chun-Yi Lee](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yao_Local_Implicit_Normalizing_Flow_for_Arbitrary-Scale_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.05156)] 

[bibtex]


[Align Your Latents: High-Resolution Video Synthesis With Latent Diffusion Models](https://openaccess.thecvf.com/content/CVPR2023/html/Blattmann_Align_Your_Latents_High-Resolution_Video_Synthesis_With_Latent_Diffusion_Models_CVPR_2023_paper.html)

[Andreas Blattmann](https://openaccess.thecvf.com/CVPR2023#), [Robin Rombach](https://openaccess.thecvf.com/CVPR2023#), [Huan Ling](https://openaccess.thecvf.com/CVPR2023#), [Tim Dockhorn](https://openaccess.thecvf.com/CVPR2023#), [Seung Wook Kim](https://openaccess.thecvf.com/CVPR2023#), [Sanja Fidler](https://openaccess.thecvf.com/CVPR2023#), [Karsten Kreis](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Blattmann_Align_Your_Latents_High-Resolution_Video_Synthesis_With_Latent_Diffusion_Models_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Blattmann_Align_Your_Latents_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.08818)] 

[bibtex]


[Zero-Shot Dual-Lens Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Xu_Zero-Shot_Dual-Lens_Super-Resolution_CVPR_2023_paper.html)

[Ruikang Xu](https://openaccess.thecvf.com/CVPR2023#), [Mingde Yao](https://openaccess.thecvf.com/CVPR2023#), [Zhiwei Xiong](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Zero-Shot_Dual-Lens_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xu_Zero-Shot_Dual-Lens_Super-Resolution_CVPR_2023_supplemental.pdf)] 

[bibtex]

#####计算机视觉国际大会

ICCV

[A Benchmark for Chinese-English Scene Text Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_A_Benchmark_for_Chinese-English_Scene_Text_Image_Super-Resolution_ICCV_2023_paper.html)

[Jianqi Ma](https://openaccess.thecvf.com/ICCV2023#), [Zhetong Liang](https://openaccess.thecvf.com/ICCV2023#), [Wangmeng Xiang](https://openaccess.thecvf.com/ICCV2023#), [Xi Yang](https://openaccess.thecvf.com/ICCV2023#), [Lei Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_A_Benchmark_for_Chinese-English_Scene_Text_Image_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ma_A_Benchmark_for_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.03262)] 

[bibtex]


[HSR-Diff: Hyperspectral Image Super-Resolution via Conditional Diffusion Models](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_HSR-Diff_Hyperspectral_Image_Super-Resolution_via_Conditional_Diffusion_Models_ICCV_2023_paper.html)

[Chanyue Wu](https://openaccess.thecvf.com/ICCV2023#), [Dong Wang](https://openaccess.thecvf.com/ICCV2023#), [Yunpeng Bai](https://openaccess.thecvf.com/ICCV2023#), [Hanyu Mao](https://openaccess.thecvf.com/ICCV2023#), [Ying Li](https://openaccess.thecvf.com/ICCV2023#), [Qiang Shen](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_HSR-Diff_Hyperspectral_Image_Super-Resolution_via_Conditional_Diffusion_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_HSR-Diff_Hyperspectral_Image_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Rethinking Multi-Contrast MRI Super-Resolution: Rectangle-Window Cross-Attention Transformer and Arbitrary-Scale Upsampling](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Rethinking_Multi-Contrast_MRI_Super-Resolution_Rectangle-Window_Cross-Attention_Transformer_and_Arbitrary-Scale_Upsampling_ICCV_2023_paper.html)

[Guangyuan Li](https://openaccess.thecvf.com/ICCV2023#), [Lei Zhao](https://openaccess.thecvf.com/ICCV2023#), [Jiakai Sun](https://openaccess.thecvf.com/ICCV2023#), [Zehua Lan](https://openaccess.thecvf.com/ICCV2023#), [Zhanjie Zhang](https://openaccess.thecvf.com/ICCV2023#), [Jiafu Chen](https://openaccess.thecvf.com/ICCV2023#), [Zhijie Lin](https://openaccess.thecvf.com/ICCV2023#), [Huaizhong Lin](https://openaccess.thecvf.com/ICCV2023#), [Wei Xing](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Rethinking_Multi-Contrast_MRI_Super-Resolution_Rectangle-Window_Cross-Attention_Transformer_and_Arbitrary-Scale_Upsampling_ICCV_2023_paper.pdf)] 

[bibtex]


[Dual Aggregation Transformer for Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Dual_Aggregation_Transformer_for_Image_Super-Resolution_ICCV_2023_paper.html)

[Zheng Chen](https://openaccess.thecvf.com/ICCV2023#), [Yulun Zhang](https://openaccess.thecvf.com/ICCV2023#), [Jinjin Gu](https://openaccess.thecvf.com/ICCV2023#), [Linghe Kong](https://openaccess.thecvf.com/ICCV2023#), [Xiaokang Yang](https://openaccess.thecvf.com/ICCV2023#), [Fisher Yu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Dual_Aggregation_Transformer_for_Image_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Dual_Aggregation_Transformer_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.03364)] 

[bibtex]


[Lightweight Image Super-Resolution with Superpixel Token Interaction](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Lightweight_Image_Super-Resolution_with_Superpixel_Token_Interaction_ICCV_2023_paper.html)

[Aiping Zhang](https://openaccess.thecvf.com/ICCV2023#), [Wenqi Ren](https://openaccess.thecvf.com/ICCV2023#), [Yi Liu](https://openaccess.thecvf.com/ICCV2023#), [Xiaochun Cao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Lightweight_Image_Super-Resolution_with_Superpixel_Token_Interaction_ICCV_2023_paper.pdf)] 

[bibtex]


[MetaF2N: Blind Image Super-Resolution by Learning Efficient Model Adaptation from Faces](https://openaccess.thecvf.com/content/ICCV2023/html/Yin_MetaF2N_Blind_Image_Super-Resolution_by_Learning_Efficient_Model_Adaptation_from_ICCV_2023_paper.html)

[Zhicun Yin](https://openaccess.thecvf.com/ICCV2023#), [Ming Liu](https://openaccess.thecvf.com/ICCV2023#), [Xiaoming Li](https://openaccess.thecvf.com/ICCV2023#), [Hui Yang](https://openaccess.thecvf.com/ICCV2023#), [Longan Xiao](https://openaccess.thecvf.com/ICCV2023#), [Wangmeng Zuo](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_MetaF2N_Blind_Image_Super-Resolution_by_Learning_Efficient_Model_Adaptation_from_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yin_MetaF2N_Blind_Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.08113)] 

[bibtex]


[Iterative Soft Shrinkage Learning for Efficient Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Iterative_Soft_Shrinkage_Learning_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.html)

[Jiamian Wang](https://openaccess.thecvf.com/ICCV2023#), [Huan Wang](https://openaccess.thecvf.com/ICCV2023#), [Yulun Zhang](https://openaccess.thecvf.com/ICCV2023#), [Yun Fu](https://openaccess.thecvf.com/ICCV2023#), [Zhiqiang Tao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Iterative_Soft_Shrinkage_Learning_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Iterative_Soft_Shrinkage_Learning_for_Efficient_Image_Super-Resolution_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.09650)] 

[bibtex]


[Learning Non-Local Spatial-Angular Correlation for Light Field Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Learning_Non-Local_Spatial-Angular_Correlation_for_Light_Field_Image_Super-Resolution_ICCV_2023_paper.html)

[Zhengyu Liang](https://openaccess.thecvf.com/ICCV2023#), [Yingqian Wang](https://openaccess.thecvf.com/ICCV2023#), [Longguang Wang](https://openaccess.thecvf.com/ICCV2023#), [Jungang Yang](https://openaccess.thecvf.com/ICCV2023#), [Shilin Zhou](https://openaccess.thecvf.com/ICCV2023#), [Yulan Guo](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Learning_Non-Local_Spatial-Angular_Correlation_for_Light_Field_Image_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liang_Learning_Non-Local_Spatial-Angular_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.08058)] 

[bibtex]


[Who Are You Referring To? Coreference Resolution In Image Narrations](https://openaccess.thecvf.com/content/ICCV2023/html/Goel_Who_Are_You_Referring_To_Coreference_Resolution_In_Image_Narrations_ICCV_2023_paper.html)

[Arushi Goel](https://openaccess.thecvf.com/ICCV2023#), [Basura Fernando](https://openaccess.thecvf.com/ICCV2023#), [Frank Keller](https://openaccess.thecvf.com/ICCV2023#), [Hakan Bilen](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Goel_Who_Are_You_Referring_To_Coreference_Resolution_In_Image_Narrations_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Goel_Who_Are_You_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.14563)] 

[bibtex]


[Feature Modulation Transformer: Cross-Refinement of Global Representation via High-Frequency Prior for Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Feature_Modulation_Transformer_Cross-Refinement_of_Global_Representation_via_High-Frequency_Prior_ICCV_2023_paper.html)

[Ao Li](https://openaccess.thecvf.com/ICCV2023#), [Le Zhang](https://openaccess.thecvf.com/ICCV2023#), [Yun Liu](https://openaccess.thecvf.com/ICCV2023#), [Ce Zhu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Feature_Modulation_Transformer_Cross-Refinement_of_Global_Representation_via_High-Frequency_Prior_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Feature_Modulation_Transformer_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.05022)] 

[bibtex]


[MoTIF: Learning Motion Trajectories with Local Implicit Neural Functions for Continuous Space-Time Video Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_MoTIF_Learning_Motion_Trajectories_with_Local_Implicit_Neural_Functions_for_ICCV_2023_paper.html)

[Yi-Hsin Chen](https://openaccess.thecvf.com/ICCV2023#), [Si-Cun Chen](https://openaccess.thecvf.com/ICCV2023#), [Yi-Hsin Chen](https://openaccess.thecvf.com/ICCV2023#), [Yen-Yu Lin](https://openaccess.thecvf.com/ICCV2023#), [Wen-Hsiao Peng](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_MoTIF_Learning_Motion_Trajectories_with_Local_Implicit_Neural_Functions_for_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_MoTIF_Learning_Motion_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.07988)] 

[bibtex]


[SIDGAN: High-Resolution Dubbed Video Generation via Shift-Invariant Learning](https://openaccess.thecvf.com/content/ICCV2023/html/Muaz_SIDGAN_High-Resolution_Dubbed_Video_Generation_via_Shift-Invariant_Learning_ICCV_2023_paper.html)

[Urwa Muaz](https://openaccess.thecvf.com/ICCV2023#), [Wondong Jang](https://openaccess.thecvf.com/ICCV2023#), [Rohun Tripathi](https://openaccess.thecvf.com/ICCV2023#), [Santhosh Mani](https://openaccess.thecvf.com/ICCV2023#), [Wenbin Ouyang](https://openaccess.thecvf.com/ICCV2023#), [Ravi Teja Gadde](https://openaccess.thecvf.com/ICCV2023#), [Baris Gecer](https://openaccess.thecvf.com/ICCV2023#), [Sergio Elizondo](https://openaccess.thecvf.com/ICCV2023#), [Reza Madad](https://openaccess.thecvf.com/ICCV2023#), [Naveen Nair](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Muaz_SIDGAN_High-Resolution_Dubbed_Video_Generation_via_Shift-Invariant_Learning_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Muaz_SIDGAN_High-Resolution_Dubbed_Video_Generation_via_Shift-Invariant_Learning_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Self-Supervised Burst Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Bhat_Self-Supervised_Burst_Super-Resolution_ICCV_2023_paper.html)

[Goutam Bhat](https://openaccess.thecvf.com/ICCV2023#), [Michaël Gharbi](https://openaccess.thecvf.com/ICCV2023#), [Jiawen Chen](https://openaccess.thecvf.com/ICCV2023#), [Luc Van Gool](https://openaccess.thecvf.com/ICCV2023#), [Zhihao Xia](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bhat_Self-Supervised_Burst_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bhat_Self-Supervised_Burst_Super-Resolution_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Reconstructed Convolution Module Based Look-Up Tables for Efficient Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Reconstructed_Convolution_Module_Based_Look-Up_Tables_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.html)

[Guandu Liu](https://openaccess.thecvf.com/ICCV2023#), [Yukang Ding](https://openaccess.thecvf.com/ICCV2023#), [Mading Li](https://openaccess.thecvf.com/ICCV2023#), [Ming Sun](https://openaccess.thecvf.com/ICCV2023#), [Xing Wen](https://openaccess.thecvf.com/ICCV2023#), [Bin Wang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Reconstructed_Convolution_Module_Based_Look-Up_Tables_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2307.08544)] 

[bibtex]


[Seeing Beyond the Patch: Scale-Adaptive Semantic Segmentation of High-resolution Remote Sensing Imagery based on Reinforcement Learning](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Seeing_Beyond_the_Patch_Scale-Adaptive_Semantic_Segmentation_of_High-resolution_Remote_ICCV_2023_paper.html)

[Yinhe Liu](https://openaccess.thecvf.com/ICCV2023#), [Sunan Shi](https://openaccess.thecvf.com/ICCV2023#), [Junjue Wang](https://openaccess.thecvf.com/ICCV2023#), [Yanfei Zhong](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Seeing_Beyond_the_Patch_Scale-Adaptive_Semantic_Segmentation_of_High-resolution_Remote_ICCV_2023_paper.pdf)] 

[bibtex]


[Boosting Single Image Super-Resolution via Partial Channel Shifting](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Boosting_Single_Image_Super-Resolution_via_Partial_Channel_Shifting_ICCV_2023_paper.html)

[Xiaoming Zhang](https://openaccess.thecvf.com/ICCV2023#), [Tianrui Li](https://openaccess.thecvf.com/ICCV2023#), [Xiaole Zhao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Boosting_Single_Image_Super-Resolution_via_Partial_Channel_Shifting_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Boosting_Single_Image_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Preface: A Data-driven Volumetric Prior for Few-shot Ultra High-resolution Face Synthesis](https://openaccess.thecvf.com/content/ICCV2023/html/Buhler_Preface_A_Data-driven_Volumetric_Prior_for_Few-shot_Ultra_High-resolution_Face_ICCV_2023_paper.html)

[Marcel C. Bühler](https://openaccess.thecvf.com/ICCV2023#), [Kripasindhu Sarkar](https://openaccess.thecvf.com/ICCV2023#), [Tanmay Shah](https://openaccess.thecvf.com/ICCV2023#), [Gengyan Li](https://openaccess.thecvf.com/ICCV2023#), [Daoye Wang](https://openaccess.thecvf.com/ICCV2023#), [Leonhard Helminger](https://openaccess.thecvf.com/ICCV2023#), [Sergio Orts-Escolano](https://openaccess.thecvf.com/ICCV2023#), [Dmitry Lagun](https://openaccess.thecvf.com/ICCV2023#), [Otmar Hilliges](https://openaccess.thecvf.com/ICCV2023#), [Thabo Beeler](https://openaccess.thecvf.com/ICCV2023#), [Abhimitra Meka](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Buhler_Preface_A_Data-driven_Volumetric_Prior_for_Few-shot_Ultra_High-resolution_Face_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Buhler_Preface_A_Data-driven_ICCV_2023_supplemental.zip)] 

[bibtex]


[SEMPART: Self-supervised Multi-resolution Partitioning of Image Semantics](https://openaccess.thecvf.com/content/ICCV2023/html/Ravindran_SEMPART_Self-supervised_Multi-resolution_Partitioning_of_Image_Semantics_ICCV_2023_paper.html)

[Sriram Ravindran](https://openaccess.thecvf.com/ICCV2023#), [Debraj Basu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ravindran_SEMPART_Self-supervised_Multi-resolution_Partitioning_of_Image_Semantics_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ravindran_SEMPART_Self-supervised_Multi-resolution_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.10972)] 

[bibtex]


[Towards Real-World Burst Image Super-Resolution: Benchmark and Method](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Towards_Real-World_Burst_Image_Super-Resolution_Benchmark_and_Method_ICCV_2023_paper.html)

[Pengxu Wei](https://openaccess.thecvf.com/ICCV2023#), [Yujing Sun](https://openaccess.thecvf.com/ICCV2023#), [Xingbei Guo](https://openaccess.thecvf.com/ICCV2023#), [Chang Liu](https://openaccess.thecvf.com/ICCV2023#), [Guanbin Li](https://openaccess.thecvf.com/ICCV2023#), [Jie Chen](https://openaccess.thecvf.com/ICCV2023#), [Xiangyang Ji](https://openaccess.thecvf.com/ICCV2023#), [Liang Lin](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Towards_Real-World_Burst_Image_Super-Resolution_Benchmark_and_Method_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_Towards_Real-World_Burst_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Content-Aware Local GAN for Photo-Realistic Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Park_Content-Aware_Local_GAN_for_Photo-Realistic_Super-Resolution_ICCV_2023_paper.html)

[JoonKyu Park](https://openaccess.thecvf.com/ICCV2023#), [Sanghyun Son](https://openaccess.thecvf.com/ICCV2023#), [Kyoung Mu Lee](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Content-Aware_Local_GAN_for_Photo-Realistic_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Park_Content-Aware_Local_GAN_ICCV_2023_supplemental.pdf)] 

[bibtex]


[UnitedHuman: Harnessing Multi-Source Data for High-Resolution Human Generation](https://openaccess.thecvf.com/content/ICCV2023/html/Fu_UnitedHuman_Harnessing_Multi-Source_Data_for_High-Resolution_Human_Generation_ICCV_2023_paper.html)

[Jianglin Fu](https://openaccess.thecvf.com/ICCV2023#), [Shikai Li](https://openaccess.thecvf.com/ICCV2023#), [Yuming Jiang](https://openaccess.thecvf.com/ICCV2023#), [Kwan-Yee Lin](https://openaccess.thecvf.com/ICCV2023#), [Wayne Wu](https://openaccess.thecvf.com/ICCV2023#), [Ziwei Liu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fu_UnitedHuman_Harnessing_Multi-Source_Data_for_High-Resolution_Human_Generation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fu_UnitedHuman_Harnessing_Multi-Source_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2309.14335)] 

[bibtex]


[Decomposition-Based Variational Network for Multi-Contrast MRI Super-Resolution and Reconstruction](https://openaccess.thecvf.com/content/ICCV2023/html/Lei_Decomposition-Based_Variational_Network_for_Multi-Contrast_MRI_Super-Resolution_and_Reconstruction_ICCV_2023_paper.html)

[Pengcheng Lei](https://openaccess.thecvf.com/ICCV2023#), [Faming Fang](https://openaccess.thecvf.com/ICCV2023#), [Guixu Zhang](https://openaccess.thecvf.com/ICCV2023#), [Tieyong Zeng](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lei_Decomposition-Based_Variational_Network_for_Multi-Contrast_MRI_Super-Resolution_and_Reconstruction_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lei_Decomposition-Based_Variational_Network_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Learning Data-Driven Vector-Quantized Degradation Model for Animation Video Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Tuo_Learning_Data-Driven_Vector-Quantized_Degradation_Model_for_Animation_Video_Super-Resolution_ICCV_2023_paper.html)

[Zixi Tuo](https://openaccess.thecvf.com/ICCV2023#), [Huan Yang](https://openaccess.thecvf.com/ICCV2023#), [Jianlong Fu](https://openaccess.thecvf.com/ICCV2023#), [Yujie Dun](https://openaccess.thecvf.com/ICCV2023#), [Xueming Qian](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tuo_Learning_Data-Driven_Vector-Quantized_Degradation_Model_for_Animation_Video_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tuo_Learning_Data-Driven_Vector-Quantized_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.09826)] 

[bibtex]


[LMR: A Large-Scale Multi-Reference Dataset for Reference-Based Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_LMR_A_Large-Scale_Multi-Reference_Dataset_for_Reference-Based_Super-Resolution_ICCV_2023_paper.html)

[Lin Zhang](https://openaccess.thecvf.com/ICCV2023#), [Xin Li](https://openaccess.thecvf.com/ICCV2023#), [Dongliang He](https://openaccess.thecvf.com/ICCV2023#), [Fu Li](https://openaccess.thecvf.com/ICCV2023#), [Errui Ding](https://openaccess.thecvf.com/ICCV2023#), [Zhaoxiang Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_LMR_A_Large-Scale_Multi-Reference_Dataset_for_Reference-Based_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_LMR_A_Large-Scale_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.04970)] 

[bibtex]


[CuNeRF: Cube-Based Neural Radiance Field for Zero-Shot Medical Image Arbitrary-Scale Super Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_CuNeRF_Cube-Based_Neural_Radiance_Field_for_Zero-Shot_Medical_Image_Arbitrary-Scale_ICCV_2023_paper.html)

[Zixuan Chen](https://openaccess.thecvf.com/ICCV2023#), [Lingxiao Yang](https://openaccess.thecvf.com/ICCV2023#), [Jian-Huang Lai](https://openaccess.thecvf.com/ICCV2023#), [Xiaohua Xie](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_CuNeRF_Cube-Based_Neural_Radiance_Field_for_Zero-Shot_Medical_Image_Arbitrary-Scale_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.16242)] 

[bibtex]


[Spatially-Adaptive Feature Modulation for Efficient Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Spatially-Adaptive_Feature_Modulation_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.html)

[Long Sun](https://openaccess.thecvf.com/ICCV2023#), [Jiangxin Dong](https://openaccess.thecvf.com/ICCV2023#), [Jinhui Tang](https://openaccess.thecvf.com/ICCV2023#), [Jinshan Pan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Spatially-Adaptive_Feature_Modulation_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_Spatially-Adaptive_Feature_Modulation_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.13800)] 

[bibtex]


[ESSAformer: Efficient Transformer for Hyperspectral Image Super-resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ESSAformer_Efficient_Transformer_for_Hyperspectral_Image_Super-resolution_ICCV_2023_paper.html)

[Mingjin Zhang](https://openaccess.thecvf.com/ICCV2023#), [Chi Zhang](https://openaccess.thecvf.com/ICCV2023#), [Qiming Zhang](https://openaccess.thecvf.com/ICCV2023#), [Jie Guo](https://openaccess.thecvf.com/ICCV2023#), [Xinbo Gao](https://openaccess.thecvf.com/ICCV2023#), [Jing Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ESSAformer_Efficient_Transformer_for_Hyperspectral_Image_Super-resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_ESSAformer_Efficient_Transformer_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.14010)] 

[bibtex]


[IHNet: Iterative Hierarchical Network Guided by High-Resolution Estimated Information for Scene Flow Estimation](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_IHNet_Iterative_Hierarchical_Network_Guided_by_High-Resolution_Estimated_Information_for_ICCV_2023_paper.html)

[Yun Wang](https://openaccess.thecvf.com/ICCV2023#), [Cheng Chi](https://openaccess.thecvf.com/ICCV2023#), [Min Lin](https://openaccess.thecvf.com/ICCV2023#), [Xin Yang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_IHNet_Iterative_Hierarchical_Network_Guided_by_High-Resolution_Estimated_Information_for_ICCV_2023_paper.pdf)] 

[bibtex]


[High-Resolution Document Shadow Removal via A Large-Scale Real-World Dataset and A Frequency-Aware Shadow Erasing Net](https://openaccess.thecvf.com/content/ICCV2023/html/Li_High-Resolution_Document_Shadow_Removal_via_A_Large-Scale_Real-World_Dataset_and_ICCV_2023_paper.html)

[Zinuo Li](https://openaccess.thecvf.com/ICCV2023#), [Xuhang Chen](https://openaccess.thecvf.com/ICCV2023#), [Chi-Man Pun](https://openaccess.thecvf.com/ICCV2023#), [Xiaodong Cun](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_High-Resolution_Document_Shadow_Removal_via_A_Large-Scale_Real-World_Dataset_and_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_High-Resolution_Document_Shadow_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.14221)] 

[bibtex]


[Multi-Frequency Representation Enhancement with Privilege Information for Video Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Multi-Frequency_Representation_Enhancement_with_Privilege_Information_for_Video_Super-Resolution_ICCV_2023_paper.html)

[Fei Li](https://openaccess.thecvf.com/ICCV2023#), [Linfeng Zhang](https://openaccess.thecvf.com/ICCV2023#), [Zikun Liu](https://openaccess.thecvf.com/ICCV2023#), [Juan Lei](https://openaccess.thecvf.com/ICCV2023#), [Zhenbo Li](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Multi-Frequency_Representation_Enhancement_with_Privilege_Information_for_Video_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Multi-Frequency_Representation_Enhancement_ICCV_2023_supplemental.pdf)] 

[bibtex]


[GRAM-HD: 3D-Consistent Image Generation at High Resolution with Generative Radiance Manifolds](https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_GRAM-HD_3D-Consistent_Image_Generation_at_High_Resolution_with_Generative_Radiance_ICCV_2023_paper.html)

[Jianfeng Xiang](https://openaccess.thecvf.com/ICCV2023#), [Jiaolong Yang](https://openaccess.thecvf.com/ICCV2023#), [Yu Deng](https://openaccess.thecvf.com/ICCV2023#), [Xin Tong](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_GRAM-HD_3D-Consistent_Image_Generation_at_High_Resolution_with_Generative_Radiance_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiang_GRAM-HD_3D-Consistent_Image_ICCV_2023_supplemental.pdf)] 

[bibtex]


[UMC: A Unified Bandwidth-efficient and Multi-resolution based Collaborative Perception Framework](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_UMC_A_Unified_Bandwidth-efficient_and_Multi-resolution_based_Collaborative_Perception_Framework_ICCV_2023_paper.html)

[Tianhang Wang](https://openaccess.thecvf.com/ICCV2023#), [Guang Chen](https://openaccess.thecvf.com/ICCV2023#), [Kai Chen](https://openaccess.thecvf.com/ICCV2023#), [Zhengfa Liu](https://openaccess.thecvf.com/ICCV2023#), [Bo Zhang](https://openaccess.thecvf.com/ICCV2023#), [Alois Knoll](https://openaccess.thecvf.com/ICCV2023#), [Changjun Jiang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_UMC_A_Unified_Bandwidth-efficient_and_Multi-resolution_based_Collaborative_Perception_Framework_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_UMC_A_Unified_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.12400)] 

[bibtex]


[Efficient-VQGAN: Towards High-Resolution Image Generation with Efficient Vision Transformers](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Efficient-VQGAN_Towards_High-Resolution_Image_Generation_with_Efficient_Vision_Transformers_ICCV_2023_paper.html)

[Shiyue Cao](https://openaccess.thecvf.com/ICCV2023#), [Yueqin Yin](https://openaccess.thecvf.com/ICCV2023#), [Lianghua Huang](https://openaccess.thecvf.com/ICCV2023#), [Yu Liu](https://openaccess.thecvf.com/ICCV2023#), [Xin Zhao](https://openaccess.thecvf.com/ICCV2023#), [Deli Zhao](https://openaccess.thecvf.com/ICCV2023#), [Kaigi Huang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Efficient-VQGAN_Towards_High-Resolution_Image_Generation_with_Efficient_Vision_Transformers_ICCV_2023_paper.pdf)] 

[bibtex]


[DLGSANet: Lightweight Dynamic Local and Global Self-Attention Networks for Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Li_DLGSANet_Lightweight_Dynamic_Local_and_Global_Self-Attention_Networks_for_Image_ICCV_2023_paper.html)

[Xiang Li](https://openaccess.thecvf.com/ICCV2023#), [Jiangxin Dong](https://openaccess.thecvf.com/ICCV2023#), [Jinhui Tang](https://openaccess.thecvf.com/ICCV2023#), [Jinshan Pan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DLGSANet_Lightweight_Dynamic_Local_and_Global_Self-Attention_Networks_for_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_DLGSANet_Lightweight_Dynamic_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2301.02031)] 

[bibtex]


[Learning Correction Filter via Degradation-Adaptive Regression for Blind Single Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Learning_Correction_Filter_via_Degradation-Adaptive_Regression_for_Blind_Single_Image_ICCV_2023_paper.html)

[Hongyang Zhou](https://openaccess.thecvf.com/ICCV2023#), [Xiaobin Zhu](https://openaccess.thecvf.com/ICCV2023#), [Jianqing Zhu](https://openaccess.thecvf.com/ICCV2023#), [Zheng Han](https://openaccess.thecvf.com/ICCV2023#), [Shi-Xue Zhang](https://openaccess.thecvf.com/ICCV2023#), [Jingyan Qin](https://openaccess.thecvf.com/ICCV2023#), [Xu-Cheng Yin](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learning_Correction_Filter_via_Degradation-Adaptive_Regression_for_Blind_Single_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_Learning_Correction_Filter_ICCV_2023_supplemental.pdf)] 

[bibtex]


[OmniZoomer: Learning to Move and Zoom in on Sphere at High-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_OmniZoomer_Learning_to_Move_and_Zoom_in_on_Sphere_at_ICCV_2023_paper.html)

[Zidong Cao](https://openaccess.thecvf.com/ICCV2023#), [Hao Ai](https://openaccess.thecvf.com/ICCV2023#), [Yan-Pei Cao](https://openaccess.thecvf.com/ICCV2023#), [Ying Shan](https://openaccess.thecvf.com/ICCV2023#), [Xiaohu Qie](https://openaccess.thecvf.com/ICCV2023#), [Lin Wang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_OmniZoomer_Learning_to_Move_and_Zoom_in_on_Sphere_at_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_OmniZoomer_Learning_to_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2308.08114)] 

[bibtex]


[Distributed Bundle Adjustment with Block-Based Sparse Matrix Compression for Super Large Scale Datasets](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Distributed_Bundle_Adjustment_with_Block-Based_Sparse_Matrix_Compression_for_Super_ICCV_2023_paper.html)

[Maoteng Zheng](https://openaccess.thecvf.com/ICCV2023#), [Nengcheng Chen](https://openaccess.thecvf.com/ICCV2023#), [Junfeng Zhu](https://openaccess.thecvf.com/ICCV2023#), [Xiaoru Zeng](https://openaccess.thecvf.com/ICCV2023#), [Huanbin Qiu](https://openaccess.thecvf.com/ICCV2023#), [Yuyao Jiang](https://openaccess.thecvf.com/ICCV2023#), [Xingyue Lu](https://openaccess.thecvf.com/ICCV2023#), [Hao Qu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Distributed_Bundle_Adjustment_with_Block-Based_Sparse_Matrix_Compression_for_Super_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_Distributed_Bundle_Adjustment_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.08383)] 

[bibtex]


[EfficientViT: Lightweight Multi-Scale Attention for High-Resolution Dense Prediction](https://openaccess.thecvf.com/content/ICCV2023/html/Cai_EfficientViT_Lightweight_Multi-Scale_Attention_for_High-Resolution_Dense_Prediction_ICCV_2023_paper.html)

[Han Cai](https://openaccess.thecvf.com/ICCV2023#), [Junyan Li](https://openaccess.thecvf.com/ICCV2023#), [Muyan Hu](https://openaccess.thecvf.com/ICCV2023#), [Chuang Gan](https://openaccess.thecvf.com/ICCV2023#), [Song Han](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_EfficientViT_Lightweight_Multi-Scale_Attention_for_High-Resolution_Dense_Prediction_ICCV_2023_paper.pdf)] 

[bibtex]


[Spherical Space Feature Decomposition for Guided Depth Map Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Spherical_Space_Feature_Decomposition_for_Guided_Depth_Map_Super-Resolution_ICCV_2023_paper.html)

[Zixiang Zhao](https://openaccess.thecvf.com/ICCV2023#), [Jiangshe Zhang](https://openaccess.thecvf.com/ICCV2023#), [Xiang Gu](https://openaccess.thecvf.com/ICCV2023#), [Chengli Tan](https://openaccess.thecvf.com/ICCV2023#), [Shuang Xu](https://openaccess.thecvf.com/ICCV2023#), [Yulun Zhang](https://openaccess.thecvf.com/ICCV2023#), [Radu Timofte](https://openaccess.thecvf.com/ICCV2023#), [Luc Van Gool](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Spherical_Space_Feature_Decomposition_for_Guided_Depth_Map_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_Spherical_Space_Feature_Decomposition_for_Guided_Depth_Map_Super-Resolution_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.08942)] 

[bibtex]


[PointDC: Unsupervised Semantic Segmentation of 3D Point Clouds via Cross-Modal Distillation and Super-Voxel Clustering](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_PointDC_Unsupervised_Semantic_Segmentation_of_3D_Point_Clouds_via_Cross-Modal_ICCV_2023_paper.html)

[Zisheng Chen](https://openaccess.thecvf.com/ICCV2023#), [Hongbin Xu](https://openaccess.thecvf.com/ICCV2023#), [Weitao Chen](https://openaccess.thecvf.com/ICCV2023#), [Zhipeng Zhou](https://openaccess.thecvf.com/ICCV2023#), [Haihong Xiao](https://openaccess.thecvf.com/ICCV2023#), [Baigui Sun](https://openaccess.thecvf.com/ICCV2023#), [Xuansong Xie](https://openaccess.thecvf.com/ICCV2023#), [Wenxiong kang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_PointDC_Unsupervised_Semantic_Segmentation_of_3D_Point_Clouds_via_Cross-Modal_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_PointDC_Unsupervised_Semantic_ICCV_2023_supplemental.pdf)] 

[bibtex]


[SRFormer: Permuted Self-Attention for Single Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_SRFormer_Permuted_Self-Attention_for_Single_Image_Super-Resolution_ICCV_2023_paper.html)

[Yupeng Zhou](https://openaccess.thecvf.com/ICCV2023#), [Zhen Li](https://openaccess.thecvf.com/ICCV2023#), [Chun-Le Guo](https://openaccess.thecvf.com/ICCV2023#), [Song Bai](https://openaccess.thecvf.com/ICCV2023#), [Ming-Ming Cheng](https://openaccess.thecvf.com/ICCV2023#), [Qibin Hou](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SRFormer_Permuted_Self-Attention_for_Single_Image_Super-Resolution_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.09735)] 

[bibtex]

##### 图像信号处理领域的旗舰会议

ICIP