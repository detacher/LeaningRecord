##### 2023年计算机视觉和模式识别领域的顶级会议。

CVPR

image denoising

[NoisyTwins: Class-Consistent and Diverse Image Generation Through StyleGANs](https://openaccess.thecvf.com/content/CVPR2023/html/Rangwani_NoisyTwins_Class-Consistent_and_Diverse_Image_Generation_Through_StyleGANs_CVPR_2023_paper.html)

[Harsh Rangwani](https://openaccess.thecvf.com/CVPR2023#), [Lavish Bansal](https://openaccess.thecvf.com/CVPR2023#), [Kartik Sharma](https://openaccess.thecvf.com/CVPR2023#), [Tejan Karmali](https://openaccess.thecvf.com/CVPR2023#), [Varun Jampani](https://openaccess.thecvf.com/CVPR2023#), [R. Venkatesh Babu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Rangwani_NoisyTwins_Class-Consistent_and_Diverse_Image_Generation_Through_StyleGANs_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Rangwani_NoisyTwins_Class-Consistent_and_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.05866)] 

[bibtex]


[Revisiting Self-Similarity: Structural Embedding for Image Retrieval](https://openaccess.thecvf.com/content/CVPR2023/html/Lee_Revisiting_Self-Similarity_Structural_Embedding_for_Image_Retrieval_CVPR_2023_paper.html)

[Seongwon Lee](https://openaccess.thecvf.com/CVPR2023#), [Suhyeon Lee](https://openaccess.thecvf.com/CVPR2023#), [Hongje Seong](https://openaccess.thecvf.com/CVPR2023#), [Euntai Kim](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Lee_Revisiting_Self-Similarity_Structural_Embedding_for_Image_Retrieval_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Lee_Revisiting_Self-Similarity_Structural_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Decoupling-and-Aggregating for Image Exposure Correction](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Decoupling-and-Aggregating_for_Image_Exposure_Correction_CVPR_2023_paper.html)

[Yang Wang](https://openaccess.thecvf.com/CVPR2023#), [Long Peng](https://openaccess.thecvf.com/CVPR2023#), [Liang Li](https://openaccess.thecvf.com/CVPR2023#), [Yang Cao](https://openaccess.thecvf.com/CVPR2023#), [Zheng-Jun Zha](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Decoupling-and-Aggregating_for_Image_Exposure_Correction_CVPR_2023_paper.pdf)] 

[bibtex]


[An Image Quality Assessment Dataset for Portraits](https://openaccess.thecvf.com/content/CVPR2023/html/Chahine_An_Image_Quality_Assessment_Dataset_for_Portraits_CVPR_2023_paper.html)

[Nicolas Chahine](https://openaccess.thecvf.com/CVPR2023#), [Stefania Calarasanu](https://openaccess.thecvf.com/CVPR2023#), [Davide Garcia-Civiero](https://openaccess.thecvf.com/CVPR2023#), [Théo Cayla](https://openaccess.thecvf.com/CVPR2023#), [Sira Ferradans](https://openaccess.thecvf.com/CVPR2023#), [Jean Ponce](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chahine_An_Image_Quality_Assessment_Dataset_for_Portraits_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chahine_An_Image_Quality_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.05772)] 

[bibtex]


[LANIT: Language-Driven Image-to-Image Translation for Unlabeled Data](https://openaccess.thecvf.com/content/CVPR2023/html/Park_LANIT_Language-Driven_Image-to-Image_Translation_for_Unlabeled_Data_CVPR_2023_paper.html)

[Jihye Park](https://openaccess.thecvf.com/CVPR2023#), [Sunwoo Kim](https://openaccess.thecvf.com/CVPR2023#), [Soohyun Kim](https://openaccess.thecvf.com/CVPR2023#), [Seokju Cho](https://openaccess.thecvf.com/CVPR2023#), [Jaejun Yoo](https://openaccess.thecvf.com/CVPR2023#), [Youngjung Uh](https://openaccess.thecvf.com/CVPR2023#), [Seungryong Kim](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Park_LANIT_Language-Driven_Image-to-Image_Translation_for_Unlabeled_Data_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Park_LANIT_Language-Driven_Image-to-Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2208.14889)] 

[bibtex]


[Text-Guided Unsupervised Latent Transformation for Multi-Attribute Image Manipulation](https://openaccess.thecvf.com/content/CVPR2023/html/Wei_Text-Guided_Unsupervised_Latent_Transformation_for_Multi-Attribute_Image_Manipulation_CVPR_2023_paper.html)

[Xiwen Wei](https://openaccess.thecvf.com/CVPR2023#), [Zhen Xu](https://openaccess.thecvf.com/CVPR2023#), [Cheng Liu](https://openaccess.thecvf.com/CVPR2023#), [Si Wu](https://openaccess.thecvf.com/CVPR2023#), [Zhiwen Yu](https://openaccess.thecvf.com/CVPR2023#), [Hau San Wong](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_Text-Guided_Unsupervised_Latent_Transformation_for_Multi-Attribute_Image_Manipulation_CVPR_2023_paper.pdf)] 

[bibtex]


[Picture That Sketch: Photorealistic Image Generation From Abstract Sketches](https://openaccess.thecvf.com/content/CVPR2023/html/Koley_Picture_That_Sketch_Photorealistic_Image_Generation_From_Abstract_Sketches_CVPR_2023_paper.html)

[Subhadeep Koley](https://openaccess.thecvf.com/CVPR2023#), [Ayan Kumar Bhunia](https://openaccess.thecvf.com/CVPR2023#), [Aneeshan Sain](https://openaccess.thecvf.com/CVPR2023#), [Pinaki Nath Chowdhury](https://openaccess.thecvf.com/CVPR2023#), [Tao Xiang](https://openaccess.thecvf.com/CVPR2023#), [Yi-Zhe Song](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Koley_Picture_That_Sketch_Photorealistic_Image_Generation_From_Abstract_Sketches_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Koley_Picture_That_Sketch_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.11162)] 

[bibtex]


[Contrastive Semi-Supervised Learning for Underwater Image Restoration via Reliable Bank](https://openaccess.thecvf.com/content/CVPR2023/html/Huang_Contrastive_Semi-Supervised_Learning_for_Underwater_Image_Restoration_via_Reliable_Bank_CVPR_2023_paper.html)

[Shirui Huang](https://openaccess.thecvf.com/CVPR2023#), [Keyan Wang](https://openaccess.thecvf.com/CVPR2023#), [Huan Liu](https://openaccess.thecvf.com/CVPR2023#), [Jun Chen](https://openaccess.thecvf.com/CVPR2023#), [Yunsong Li](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Contrastive_Semi-Supervised_Learning_for_Underwater_Image_Restoration_via_Reliable_Bank_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Huang_Contrastive_Semi-Supervised_Learning_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.09101)] 

[bibtex]


[Shape, Pose, and Appearance From a Single Image via Bootstrapped Radiance Field Inversion](https://openaccess.thecvf.com/content/CVPR2023/html/Pavllo_Shape_Pose_and_Appearance_From_a_Single_Image_via_Bootstrapped_CVPR_2023_paper.html)

[Dario Pavllo](https://openaccess.thecvf.com/CVPR2023#), [David Joseph Tan](https://openaccess.thecvf.com/CVPR2023#), [Marie-Julie Rakotosaona](https://openaccess.thecvf.com/CVPR2023#), [Federico Tombari](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Pavllo_Shape_Pose_and_Appearance_From_a_Single_Image_via_Bootstrapped_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Pavllo_Shape_Pose_and_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2211.11674)] 

[bibtex]


[SIEDOB: Semantic Image Editing by Disentangling Object and Background](https://openaccess.thecvf.com/content/CVPR2023/html/Luo_SIEDOB_Semantic_Image_Editing_by_Disentangling_Object_and_Background_CVPR_2023_paper.html)

[Wuyang Luo](https://openaccess.thecvf.com/CVPR2023#), [Su Yang](https://openaccess.thecvf.com/CVPR2023#), [Xinjian Zhang](https://openaccess.thecvf.com/CVPR2023#), [Weishan Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_SIEDOB_Semantic_Image_Editing_by_Disentangling_Object_and_Background_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.13062)] 

[bibtex]


[Boosting Verified Training for Robust Image Classifications via Abstraction](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Boosting_Verified_Training_for_Robust_Image_Classifications_via_Abstraction_CVPR_2023_paper.html)

[Zhaodi Zhang](https://openaccess.thecvf.com/CVPR2023#), [Zhiyi Xue](https://openaccess.thecvf.com/CVPR2023#), [Yang Chen](https://openaccess.thecvf.com/CVPR2023#), [Si Liu](https://openaccess.thecvf.com/CVPR2023#), [Yueling Zhang](https://openaccess.thecvf.com/CVPR2023#), [Jing Liu](https://openaccess.thecvf.com/CVPR2023#), [Min Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Boosting_Verified_Training_for_Robust_Image_Classifications_via_Abstraction_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.11552)] 

[bibtex]


[Bitstream-Corrupted JPEG Images Are Restorable: Two-Stage Compensation and Alignment Framework for Image Restoration](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Bitstream-Corrupted_JPEG_Images_Are_Restorable_Two-Stage_Compensation_and_Alignment_Framework_CVPR_2023_paper.html)

[Wenyang Liu](https://openaccess.thecvf.com/CVPR2023#), [Yi Wang](https://openaccess.thecvf.com/CVPR2023#), [Kim-Hui Yap](https://openaccess.thecvf.com/CVPR2023#), [Lap-Pui Chau](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Bitstream-Corrupted_JPEG_Images_Are_Restorable_Two-Stage_Compensation_and_Alignment_Framework_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Liu_Bitstream-Corrupted_JPEG_Images_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.06976)] 

[bibtex]


[Histopathology Whole Slide Image Analysis With Heterogeneous Graph Representation Learning](https://openaccess.thecvf.com/content/CVPR2023/html/Chan_Histopathology_Whole_Slide_Image_Analysis_With_Heterogeneous_Graph_Representation_Learning_CVPR_2023_paper.html)

[Tsai Hor Chan](https://openaccess.thecvf.com/CVPR2023#), [Fernando Julio Cendra](https://openaccess.thecvf.com/CVPR2023#), [Lan Ma](https://openaccess.thecvf.com/CVPR2023#), [Guosheng Yin](https://openaccess.thecvf.com/CVPR2023#), [Lequan Yu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chan_Histopathology_Whole_Slide_Image_Analysis_With_Heterogeneous_Graph_Representation_Learning_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chan_Histopathology_Whole_Slide_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Rethinking Out-of-Distribution (OOD) Detection: Masked Image Modeling Is All You Need](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Rethinking_Out-of-Distribution_OOD_Detection_Masked_Image_Modeling_Is_All_You_CVPR_2023_paper.html)

[Jingyao Li](https://openaccess.thecvf.com/CVPR2023#), [Pengguang Chen](https://openaccess.thecvf.com/CVPR2023#), [Zexin He](https://openaccess.thecvf.com/CVPR2023#), [Shaozuo Yu](https://openaccess.thecvf.com/CVPR2023#), [Shu Liu](https://openaccess.thecvf.com/CVPR2023#), [Jiaya Jia](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Rethinking_Out-of-Distribution_OOD_Detection_Masked_Image_Modeling_Is_All_You_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_Rethinking_Out-of-Distribution_OOD_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.02615)] 

[bibtex]


[WeatherStream: Light Transport Automation of Single Image Deweathering](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_WeatherStream_Light_Transport_Automation_of_Single_Image_Deweathering_CVPR_2023_paper.html)

[Howard Zhang](https://openaccess.thecvf.com/CVPR2023#), [Yunhao Ba](https://openaccess.thecvf.com/CVPR2023#), [Ethan Yang](https://openaccess.thecvf.com/CVPR2023#), [Varan Mehra](https://openaccess.thecvf.com/CVPR2023#), [Blake Gella](https://openaccess.thecvf.com/CVPR2023#), [Akira Suzuki](https://openaccess.thecvf.com/CVPR2023#), [Arnold Pfahnl](https://openaccess.thecvf.com/CVPR2023#), [Chethan Chinder Chandrappa](https://openaccess.thecvf.com/CVPR2023#), [Alex Wong](https://openaccess.thecvf.com/CVPR2023#), [Achuta Kadambi](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_WeatherStream_Light_Transport_Automation_of_Single_Image_Deweathering_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhang_WeatherStream_Light_Transport_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Paint by Example: Exemplar-Based Image Editing With Diffusion Models](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_Paint_by_Example_Exemplar-Based_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.html)

[Binxin Yang](https://openaccess.thecvf.com/CVPR2023#), [Shuyang Gu](https://openaccess.thecvf.com/CVPR2023#), [Bo Zhang](https://openaccess.thecvf.com/CVPR2023#), [Ting Zhang](https://openaccess.thecvf.com/CVPR2023#), [Xuejin Chen](https://openaccess.thecvf.com/CVPR2023#), [Xiaoyan Sun](https://openaccess.thecvf.com/CVPR2023#), [Dong Chen](https://openaccess.thecvf.com/CVPR2023#), [Fang Wen](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Paint_by_Example_Exemplar-Based_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yang_Paint_by_Example_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.13227)] 

[bibtex]


[Towards Robust Tampered Text Detection in Document Image: New Dataset and New Solution](https://openaccess.thecvf.com/content/CVPR2023/html/Qu_Towards_Robust_Tampered_Text_Detection_in_Document_Image_New_Dataset_CVPR_2023_paper.html)

[Chenfan Qu](https://openaccess.thecvf.com/CVPR2023#), [Chongyu Liu](https://openaccess.thecvf.com/CVPR2023#), [Yuliang Liu](https://openaccess.thecvf.com/CVPR2023#), [Xinhong Chen](https://openaccess.thecvf.com/CVPR2023#), [Dezhi Peng](https://openaccess.thecvf.com/CVPR2023#), [Fengjun Guo](https://openaccess.thecvf.com/CVPR2023#), [Lianwen Jin](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Qu_Towards_Robust_Tampered_Text_Detection_in_Document_Image_New_Dataset_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Qu_Towards_Robust_Tampered_CVPR_2023_supplemental.pdf)] 

[bibtex]


[DeSTSeg: Segmentation Guided Denoising Student-Teacher for Anomaly Detection](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_DeSTSeg_Segmentation_Guided_Denoising_Student-Teacher_for_Anomaly_Detection_CVPR_2023_paper.html)

[Xuan Zhang](https://openaccess.thecvf.com/CVPR2023#), [Shiyu Li](https://openaccess.thecvf.com/CVPR2023#), [Xi Li](https://openaccess.thecvf.com/CVPR2023#), [Ping Huang](https://openaccess.thecvf.com/CVPR2023#), [Jiulong Shan](https://openaccess.thecvf.com/CVPR2023#), [Ting Chen](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_DeSTSeg_Segmentation_Guided_Denoising_Student-Teacher_for_Anomaly_Detection_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhang_DeSTSeg_Segmentation_Guided_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.11317)] 

[bibtex]


[Neural Rate Estimator and Unsupervised Learning for Efficient Distributed Image Analytics in Split-DNN Models](https://openaccess.thecvf.com/content/CVPR2023/html/Ahuja_Neural_Rate_Estimator_and_Unsupervised_Learning_for_Efficient_Distributed_Image_CVPR_2023_paper.html)

[Nilesh Ahuja](https://openaccess.thecvf.com/CVPR2023#), [Parual Datta](https://openaccess.thecvf.com/CVPR2023#), [Bhavya Kanzariya](https://openaccess.thecvf.com/CVPR2023#), [V. Srinivasa Somayazulu](https://openaccess.thecvf.com/CVPR2023#), [Omesh Tickoo](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Ahuja_Neural_Rate_Estimator_and_Unsupervised_Learning_for_Efficient_Distributed_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Ahuja_Neural_Rate_Estimator_CVPR_2023_supplemental.pdf)] 

[bibtex]


[You Do Not Need Additional Priors or Regularizers in Retinex-Based Low-Light Image Enhancement](https://openaccess.thecvf.com/content/CVPR2023/html/Fu_You_Do_Not_Need_Additional_Priors_or_Regularizers_in_Retinex-Based_CVPR_2023_paper.html)

[Huiyuan Fu](https://openaccess.thecvf.com/CVPR2023#), [Wenkai Zheng](https://openaccess.thecvf.com/CVPR2023#), [Xiangyu Meng](https://openaccess.thecvf.com/CVPR2023#), [Xin Wang](https://openaccess.thecvf.com/CVPR2023#), [Chuanming Wang](https://openaccess.thecvf.com/CVPR2023#), [Huadong Ma](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Fu_You_Do_Not_Need_Additional_Priors_or_Regularizers_in_Retinex-Based_CVPR_2023_paper.pdf)] 

[bibtex]


[PIP-Net: Patch-Based Intuitive Prototypes for Interpretable Image Classification](https://openaccess.thecvf.com/content/CVPR2023/html/Nauta_PIP-Net_Patch-Based_Intuitive_Prototypes_for_Interpretable_Image_Classification_CVPR_2023_paper.html)

[Meike Nauta](https://openaccess.thecvf.com/CVPR2023#), [Jörg Schlötterer](https://openaccess.thecvf.com/CVPR2023#), [Maurice van Keulen](https://openaccess.thecvf.com/CVPR2023#), [Christin Seifert](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Nauta_PIP-Net_Patch-Based_Intuitive_Prototypes_for_Interpretable_Image_Classification_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Nauta_PIP-Net_Patch-Based_Intuitive_CVPR_2023_supplemental.pdf)] 

[bibtex]


[BUOL: A Bottom-Up Framework With Occupancy-Aware Lifting for Panoptic 3D Scene Reconstruction From a Single Image](https://openaccess.thecvf.com/content/CVPR2023/html/Chu_BUOL_A_Bottom-Up_Framework_With_Occupancy-Aware_Lifting_for_Panoptic_3D_CVPR_2023_paper.html)

[Tao Chu](https://openaccess.thecvf.com/CVPR2023#), [Pan Zhang](https://openaccess.thecvf.com/CVPR2023#), [Qiong Liu](https://openaccess.thecvf.com/CVPR2023#), [Jiaqi Wang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chu_BUOL_A_Bottom-Up_Framework_With_Occupancy-Aware_Lifting_for_Panoptic_3D_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chu_BUOL_A_Bottom-Up_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2306.00965)] 

[bibtex]


[PolyFormer: Referring Image Segmentation As Sequential Polygon Generation](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_PolyFormer_Referring_Image_Segmentation_As_Sequential_Polygon_Generation_CVPR_2023_paper.html)

[Jiang Liu](https://openaccess.thecvf.com/CVPR2023#), [Hui Ding](https://openaccess.thecvf.com/CVPR2023#), [Zhaowei Cai](https://openaccess.thecvf.com/CVPR2023#), [Yuting Zhang](https://openaccess.thecvf.com/CVPR2023#), [Ravi Kumar Satzoda](https://openaccess.thecvf.com/CVPR2023#), [Vijay Mahadevan](https://openaccess.thecvf.com/CVPR2023#), [R. Manmatha](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_PolyFormer_Referring_Image_Segmentation_As_Sequential_Polygon_Generation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Liu_PolyFormer_Referring_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.07387)] 

[bibtex]


[Variational Distribution Learning for Unsupervised Text-to-Image Generation](https://openaccess.thecvf.com/content/CVPR2023/html/Kang_Variational_Distribution_Learning_for_Unsupervised_Text-to-Image_Generation_CVPR_2023_paper.html)

[Minsoo Kang](https://openaccess.thecvf.com/CVPR2023#), [Doyup Lee](https://openaccess.thecvf.com/CVPR2023#), [Jiseob Kim](https://openaccess.thecvf.com/CVPR2023#), [Saehoon Kim](https://openaccess.thecvf.com/CVPR2023#), [Bohyung Han](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Kang_Variational_Distribution_Learning_for_Unsupervised_Text-to-Image_Generation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Kang_Variational_Distribution_Learning_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.16105)] 

[bibtex]


[Cross-Domain Image Captioning With Discriminative Finetuning](https://openaccess.thecvf.com/content/CVPR2023/html/Dessi_Cross-Domain_Image_Captioning_With_Discriminative_Finetuning_CVPR_2023_paper.html)

[Roberto Dessì](https://openaccess.thecvf.com/CVPR2023#), [Michele Bevilacqua](https://openaccess.thecvf.com/CVPR2023#), [Eleonora Gualdoni](https://openaccess.thecvf.com/CVPR2023#), [Nathanaël Carraz Rakotonirina](https://openaccess.thecvf.com/CVPR2023#), [Francesca Franzon](https://openaccess.thecvf.com/CVPR2023#), [Marco Baroni](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Dessi_Cross-Domain_Image_Captioning_With_Discriminative_Finetuning_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Dessi_Cross-Domain_Image_Captioning_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Efficient Mask Correction for Click-Based Interactive Image Segmentation](https://openaccess.thecvf.com/content/CVPR2023/html/Du_Efficient_Mask_Correction_for_Click-Based_Interactive_Image_Segmentation_CVPR_2023_paper.html)

[Fei Du](https://openaccess.thecvf.com/CVPR2023#), [Jianlong Yuan](https://openaccess.thecvf.com/CVPR2023#), [Zhibin Wang](https://openaccess.thecvf.com/CVPR2023#), [Fan Wang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Du_Efficient_Mask_Correction_for_Click-Based_Interactive_Image_Segmentation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Du_Efficient_Mask_Correction_CVPR_2023_supplemental.pdf)] 

[bibtex]


[OneFormer: One Transformer To Rule Universal Image Segmentation](https://openaccess.thecvf.com/content/CVPR2023/html/Jain_OneFormer_One_Transformer_To_Rule_Universal_Image_Segmentation_CVPR_2023_paper.html)

[Jitesh Jain](https://openaccess.thecvf.com/CVPR2023#), [Jiachen Li](https://openaccess.thecvf.com/CVPR2023#), [Mang Tik Chiu](https://openaccess.thecvf.com/CVPR2023#), [Ali Hassani](https://openaccess.thecvf.com/CVPR2023#), [Nikita Orlov](https://openaccess.thecvf.com/CVPR2023#), [Humphrey Shi](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Jain_OneFormer_One_Transformer_To_Rule_Universal_Image_Segmentation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Jain_OneFormer_One_Transformer_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.06220)] 

[bibtex]


[Spectral Bayesian Uncertainty for Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Spectral_Bayesian_Uncertainty_for_Image_Super-Resolution_CVPR_2023_paper.html)

[Tao Liu](https://openaccess.thecvf.com/CVPR2023#), [Jun Cheng](https://openaccess.thecvf.com/CVPR2023#), [Shan Tan](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Spectral_Bayesian_Uncertainty_for_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Liu_Spectral_Bayesian_Uncertainty_CVPR_2023_supplemental.pdf)] 

[bibtex]


[CLIP for All Things Zero-Shot Sketch-Based Image Retrieval, Fine-Grained or Not](https://openaccess.thecvf.com/content/CVPR2023/html/Sain_CLIP_for_All_Things_Zero-Shot_Sketch-Based_Image_Retrieval_Fine-Grained_or_CVPR_2023_paper.html)

[Aneeshan Sain](https://openaccess.thecvf.com/CVPR2023#), [Ayan Kumar Bhunia](https://openaccess.thecvf.com/CVPR2023#), [Pinaki Nath Chowdhury](https://openaccess.thecvf.com/CVPR2023#), [Subhadeep Koley](https://openaccess.thecvf.com/CVPR2023#), [Tao Xiang](https://openaccess.thecvf.com/CVPR2023#), [Yi-Zhe Song](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Sain_CLIP_for_All_Things_Zero-Shot_Sketch-Based_Image_Retrieval_Fine-Grained_or_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Sain_CLIP_for_All_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.13440)] 

[bibtex]


[Wavelet Diffusion Models Are Fast and Scalable Image Generators](https://openaccess.thecvf.com/content/CVPR2023/html/Phung_Wavelet_Diffusion_Models_Are_Fast_and_Scalable_Image_Generators_CVPR_2023_paper.html)

[Hao Phung](https://openaccess.thecvf.com/CVPR2023#), [Quan Dao](https://openaccess.thecvf.com/CVPR2023#), [Anh Tran](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Phung_Wavelet_Diffusion_Models_Are_Fast_and_Scalable_Image_Generators_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Phung_Wavelet_Diffusion_Models_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.16152)] 

[bibtex]


[ViTs for SITS: Vision Transformers for Satellite Image Time Series](https://openaccess.thecvf.com/content/CVPR2023/html/Tarasiou_ViTs_for_SITS_Vision_Transformers_for_Satellite_Image_Time_Series_CVPR_2023_paper.html)

[Michail Tarasiou](https://openaccess.thecvf.com/CVPR2023#), [Erik Chavez](https://openaccess.thecvf.com/CVPR2023#), [Stefanos Zafeiriou](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Tarasiou_ViTs_for_SITS_Vision_Transformers_for_Satellite_Image_Time_Series_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Tarasiou_ViTs_for_SITS_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2301.04944)] 

[bibtex]


[Deep Random Projector: Accelerated Deep Image Prior](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Deep_Random_Projector_Accelerated_Deep_Image_Prior_CVPR_2023_paper.html)

[Taihui Li](https://openaccess.thecvf.com/CVPR2023#), [Hengkang Wang](https://openaccess.thecvf.com/CVPR2023#), [Zhong Zhuang](https://openaccess.thecvf.com/CVPR2023#), [Ju Sun](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Deep_Random_Projector_Accelerated_Deep_Image_Prior_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_Deep_Random_Projector_CVPR_2023_supplemental.pdf)] 

[bibtex]


[RA-CLIP: Retrieval Augmented Contrastive Language-Image Pre-Training](https://openaccess.thecvf.com/content/CVPR2023/html/Xie_RA-CLIP_Retrieval_Augmented_Contrastive_Language-Image_Pre-Training_CVPR_2023_paper.html)

[Chen-Wei Xie](https://openaccess.thecvf.com/CVPR2023#), [Siyang Sun](https://openaccess.thecvf.com/CVPR2023#), [Xiong Xiong](https://openaccess.thecvf.com/CVPR2023#), [Yun Zheng](https://openaccess.thecvf.com/CVPR2023#), [Deli Zhao](https://openaccess.thecvf.com/CVPR2023#), [Jingren Zhou](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_RA-CLIP_Retrieval_Augmented_Contrastive_Language-Image_Pre-Training_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xie_RA-CLIP_Retrieval_Augmented_CVPR_2023_supplemental.pdf)] 

[bibtex]


[ERNIE-ViLG 2.0: Improving Text-to-Image Diffusion Model With Knowledge-Enhanced Mixture-of-Denoising-Experts](https://openaccess.thecvf.com/content/CVPR2023/html/Feng_ERNIE-ViLG_2.0_Improving_Text-to-Image_Diffusion_Model_With_Knowledge-Enhanced_Mixture-of-Denoising-Experts_CVPR_2023_paper.html)

[Zhida Feng](https://openaccess.thecvf.com/CVPR2023#), [Zhenyu Zhang](https://openaccess.thecvf.com/CVPR2023#), [Xintong Yu](https://openaccess.thecvf.com/CVPR2023#), [Yewei Fang](https://openaccess.thecvf.com/CVPR2023#), [Lanxin Li](https://openaccess.thecvf.com/CVPR2023#), [Xuyi Chen](https://openaccess.thecvf.com/CVPR2023#), [Yuxiang Lu](https://openaccess.thecvf.com/CVPR2023#), [Jiaxiang Liu](https://openaccess.thecvf.com/CVPR2023#), [Weichong Yin](https://openaccess.thecvf.com/CVPR2023#), [Shikun Feng](https://openaccess.thecvf.com/CVPR2023#), [Yu Sun](https://openaccess.thecvf.com/CVPR2023#), [Li Chen](https://openaccess.thecvf.com/CVPR2023#), [Hao Tian](https://openaccess.thecvf.com/CVPR2023#), [Hua Wu](https://openaccess.thecvf.com/CVPR2023#), [Haifeng Wang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_ERNIE-ViLG_2.0_Improving_Text-to-Image_Diffusion_Model_With_Knowledge-Enhanced_Mixture-of-Denoising-Experts_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Feng_ERNIE-ViLG_2.0_Improving_CVPR_2023_supplemental.pdf)] 

[bibtex]


[LG-BPN: Local and Global Blind-Patch Network for Self-Supervised Real-World Denoising](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_LG-BPN_Local_and_Global_Blind-Patch_Network_for_Self-Supervised_Real-World_Denoising_CVPR_2023_paper.html)

[Zichun Wang](https://openaccess.thecvf.com/CVPR2023#), [Ying Fu](https://openaccess.thecvf.com/CVPR2023#), [Ji Liu](https://openaccess.thecvf.com/CVPR2023#), [Yulun Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_LG-BPN_Local_and_Global_Blind-Patch_Network_for_Self-Supervised_Real-World_Denoising_CVPR_2023_paper.pdf)] 

[bibtex]


[Efficient View Synthesis and 3D-Based Multi-Frame Denoising With Multiplane Feature Representations](https://openaccess.thecvf.com/content/CVPR2023/html/Tanay_Efficient_View_Synthesis_and_3D-Based_Multi-Frame_Denoising_With_Multiplane_Feature_CVPR_2023_paper.html)

[Thomas Tanay](https://openaccess.thecvf.com/CVPR2023#), [Aleš Leonardis](https://openaccess.thecvf.com/CVPR2023#), [Matteo Maggioni](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Tanay_Efficient_View_Synthesis_and_3D-Based_Multi-Frame_Denoising_With_Multiplane_Feature_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Tanay_Efficient_View_Synthesis_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.18139)] 

[bibtex]


[Learning To Generate Image Embeddings With User-Level Differential Privacy](https://openaccess.thecvf.com/content/CVPR2023/html/Xu_Learning_To_Generate_Image_Embeddings_With_User-Level_Differential_Privacy_CVPR_2023_paper.html)

[Zheng Xu](https://openaccess.thecvf.com/CVPR2023#), [Maxwell Collins](https://openaccess.thecvf.com/CVPR2023#), [Yuxiao Wang](https://openaccess.thecvf.com/CVPR2023#), [Liviu Panait](https://openaccess.thecvf.com/CVPR2023#), [Sewoong Oh](https://openaccess.thecvf.com/CVPR2023#), [Sean Augenstein](https://openaccess.thecvf.com/CVPR2023#), [Ting Liu](https://openaccess.thecvf.com/CVPR2023#), [Florian Schroff](https://openaccess.thecvf.com/CVPR2023#), [H. Brendan McMahan](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Learning_To_Generate_Image_Embeddings_With_User-Level_Differential_Privacy_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xu_Learning_To_Generate_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.10844)] 

[bibtex]


[Open-Vocabulary Panoptic Segmentation With Text-to-Image Diffusion Models](https://openaccess.thecvf.com/content/CVPR2023/html/Xu_Open-Vocabulary_Panoptic_Segmentation_With_Text-to-Image_Diffusion_Models_CVPR_2023_paper.html)

[Jiarui Xu](https://openaccess.thecvf.com/CVPR2023#), [Sifei Liu](https://openaccess.thecvf.com/CVPR2023#), [Arash Vahdat](https://openaccess.thecvf.com/CVPR2023#), [Wonmin Byeon](https://openaccess.thecvf.com/CVPR2023#), [Xiaolong Wang](https://openaccess.thecvf.com/CVPR2023#), [Shalini De Mello](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Open-Vocabulary_Panoptic_Segmentation_With_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xu_Open-Vocabulary_Panoptic_Segmentation_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.04803)] 

[bibtex]


[DeepLSD: Line Segment Detection and Refinement With Deep Image Gradients](https://openaccess.thecvf.com/content/CVPR2023/html/Pautrat_DeepLSD_Line_Segment_Detection_and_Refinement_With_Deep_Image_Gradients_CVPR_2023_paper.html)

[Rémi Pautrat](https://openaccess.thecvf.com/CVPR2023#), [Daniel Barath](https://openaccess.thecvf.com/CVPR2023#), [Viktor Larsson](https://openaccess.thecvf.com/CVPR2023#), [Martin R. Oswald](https://openaccess.thecvf.com/CVPR2023#), [Marc Pollefeys](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Pautrat_DeepLSD_Line_Segment_Detection_and_Refinement_With_Deep_Image_Gradients_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Pautrat_DeepLSD_Line_Segment_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.07766)] 

[bibtex]


[Learning Distortion Invariant Representation for Image Restoration From a Causality Perspective](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Learning_Distortion_Invariant_Representation_for_Image_Restoration_From_a_Causality_CVPR_2023_paper.html)

[Xin Li](https://openaccess.thecvf.com/CVPR2023#), [Bingchen Li](https://openaccess.thecvf.com/CVPR2023#), [Xin Jin](https://openaccess.thecvf.com/CVPR2023#), [Cuiling Lan](https://openaccess.thecvf.com/CVPR2023#), [Zhibo Chen](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Learning_Distortion_Invariant_Representation_for_Image_Restoration_From_a_Causality_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_Learning_Distortion_Invariant_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.06859)] 

[bibtex]


[Complete 3D Human Reconstruction From a Single Incomplete Image](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Complete_3D_Human_Reconstruction_From_a_Single_Incomplete_Image_CVPR_2023_paper.html)

[Junying Wang](https://openaccess.thecvf.com/CVPR2023#), [Jae Shin Yoon](https://openaccess.thecvf.com/CVPR2023#), [Tuanfeng Y. Wang](https://openaccess.thecvf.com/CVPR2023#), [Krishna Kumar Singh](https://openaccess.thecvf.com/CVPR2023#), [Ulrich Neumann](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Complete_3D_Human_Reconstruction_From_a_Single_Incomplete_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Complete_3D_Human_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Learning a Simple Low-Light Image Enhancer From Paired Low-Light Instances](https://openaccess.thecvf.com/content/CVPR2023/html/Fu_Learning_a_Simple_Low-Light_Image_Enhancer_From_Paired_Low-Light_Instances_CVPR_2023_paper.html)

[Zhenqi Fu](https://openaccess.thecvf.com/CVPR2023#), [Yan Yang](https://openaccess.thecvf.com/CVPR2023#), [Xiaotong Tu](https://openaccess.thecvf.com/CVPR2023#), [Yue Huang](https://openaccess.thecvf.com/CVPR2023#), [Xinghao Ding](https://openaccess.thecvf.com/CVPR2023#), [Kai-Kuang Ma](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Fu_Learning_a_Simple_Low-Light_Image_Enhancer_From_Paired_Low-Light_Instances_CVPR_2023_paper.pdf)] 

[bibtex]


[IFSeg: Image-Free Semantic Segmentation via Vision-Language Model](https://openaccess.thecvf.com/content/CVPR2023/html/Yun_IFSeg_Image-Free_Semantic_Segmentation_via_Vision-Language_Model_CVPR_2023_paper.html)

[Sukmin Yun](https://openaccess.thecvf.com/CVPR2023#), [Seong Hyeon Park](https://openaccess.thecvf.com/CVPR2023#), [Paul Hongsuck Seo](https://openaccess.thecvf.com/CVPR2023#), [Jinwoo Shin](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yun_IFSeg_Image-Free_Semantic_Segmentation_via_Vision-Language_Model_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yun_IFSeg_Image-Free_Semantic_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.14396)] 

[bibtex]


[Data-Free Sketch-Based Image Retrieval](https://openaccess.thecvf.com/content/CVPR2023/html/Chaudhuri_Data-Free_Sketch-Based_Image_Retrieval_CVPR_2023_paper.html)

[Abhra Chaudhuri](https://openaccess.thecvf.com/CVPR2023#), [Ayan Kumar Bhunia](https://openaccess.thecvf.com/CVPR2023#), [Yi-Zhe Song](https://openaccess.thecvf.com/CVPR2023#), [Anjan Dutta](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chaudhuri_Data-Free_Sketch-Based_Image_Retrieval_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chaudhuri_Data-Free_Sketch-Based_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.07775)] 

[bibtex]


[Towards Generalisable Video Moment Retrieval: Visual-Dynamic Injection to Image-Text Pre-Training](https://openaccess.thecvf.com/content/CVPR2023/html/Luo_Towards_Generalisable_Video_Moment_Retrieval_Visual-Dynamic_Injection_to_Image-Text_Pre-Training_CVPR_2023_paper.html)

[Dezhao Luo](https://openaccess.thecvf.com/CVPR2023#), [Jiabo Huang](https://openaccess.thecvf.com/CVPR2023#), [Shaogang Gong](https://openaccess.thecvf.com/CVPR2023#), [Hailin Jin](https://openaccess.thecvf.com/CVPR2023#), [Yang Liu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_Towards_Generalisable_Video_Moment_Retrieval_Visual-Dynamic_Injection_to_Image-Text_Pre-Training_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Luo_Towards_Generalisable_Video_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.00040)] 

[bibtex]


[Learning Adaptive Dense Event Stereo From the Image Domain](https://openaccess.thecvf.com/content/CVPR2023/html/Cho_Learning_Adaptive_Dense_Event_Stereo_From_the_Image_Domain_CVPR_2023_paper.html)

[Hoonhee Cho](https://openaccess.thecvf.com/CVPR2023#), [Jegyeong Cho](https://openaccess.thecvf.com/CVPR2023#), [Kuk-Jin Yoon](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Cho_Learning_Adaptive_Dense_Event_Stereo_From_the_Image_Domain_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Cho_Learning_Adaptive_Dense_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Reproducible Scaling Laws for Contrastive Language-Image Learning](https://openaccess.thecvf.com/content/CVPR2023/html/Cherti_Reproducible_Scaling_Laws_for_Contrastive_Language-Image_Learning_CVPR_2023_paper.html)

[Mehdi Cherti](https://openaccess.thecvf.com/CVPR2023#), [Romain Beaumont](https://openaccess.thecvf.com/CVPR2023#), [Ross Wightman](https://openaccess.thecvf.com/CVPR2023#), [Mitchell Wortsman](https://openaccess.thecvf.com/CVPR2023#), [Gabriel Ilharco](https://openaccess.thecvf.com/CVPR2023#), [Cade Gordon](https://openaccess.thecvf.com/CVPR2023#), [Christoph Schuhmann](https://openaccess.thecvf.com/CVPR2023#), [Ludwig Schmidt](https://openaccess.thecvf.com/CVPR2023#), [Jenia Jitsev](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Cherti_Reproducible_Scaling_Laws_for_Contrastive_Language-Image_Learning_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Cherti_Reproducible_Scaling_Laws_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.07143)] 

[bibtex]


[Multi-Realism Image Compression With a Conditional Generator](https://openaccess.thecvf.com/content/CVPR2023/html/Agustsson_Multi-Realism_Image_Compression_With_a_Conditional_Generator_CVPR_2023_paper.html)

[Eirikur Agustsson](https://openaccess.thecvf.com/CVPR2023#), [David Minnen](https://openaccess.thecvf.com/CVPR2023#), [George Toderici](https://openaccess.thecvf.com/CVPR2023#), [Fabian Mentzer](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Agustsson_Multi-Realism_Image_Compression_With_a_Conditional_Generator_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Agustsson_Multi-Realism_Image_Compression_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.13824)] 

[bibtex]


[Pic2Word: Mapping Pictures to Words for Zero-Shot Composed Image Retrieval](https://openaccess.thecvf.com/content/CVPR2023/html/Saito_Pic2Word_Mapping_Pictures_to_Words_for_Zero-Shot_Composed_Image_Retrieval_CVPR_2023_paper.html)

[Kuniaki Saito](https://openaccess.thecvf.com/CVPR2023#), [Kihyuk Sohn](https://openaccess.thecvf.com/CVPR2023#), [Xiang Zhang](https://openaccess.thecvf.com/CVPR2023#), [Chun-Liang Li](https://openaccess.thecvf.com/CVPR2023#), [Chen-Yu Lee](https://openaccess.thecvf.com/CVPR2023#), [Kate Saenko](https://openaccess.thecvf.com/CVPR2023#), [Tomas Pfister](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Saito_Pic2Word_Mapping_Pictures_to_Words_for_Zero-Shot_Composed_Image_Retrieval_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Saito_Pic2Word_Mapping_Pictures_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.03084)] 

[bibtex]


[Regularized Vector Quantization for Tokenized Image Synthesis](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Regularized_Vector_Quantization_for_Tokenized_Image_Synthesis_CVPR_2023_paper.html)

[Jiahui Zhang](https://openaccess.thecvf.com/CVPR2023#), [Fangneng Zhan](https://openaccess.thecvf.com/CVPR2023#), [Christian Theobalt](https://openaccess.thecvf.com/CVPR2023#), [Shijian Lu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Regularized_Vector_Quantization_for_Tokenized_Image_Synthesis_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.06424)] 

[bibtex]


[Improving Image Recognition by Retrieving From Web-Scale Image-Text Data](https://openaccess.thecvf.com/content/CVPR2023/html/Iscen_Improving_Image_Recognition_by_Retrieving_From_Web-Scale_Image-Text_Data_CVPR_2023_paper.html)

[Ahmet Iscen](https://openaccess.thecvf.com/CVPR2023#), [Alireza Fathi](https://openaccess.thecvf.com/CVPR2023#), [Cordelia Schmid](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Iscen_Improving_Image_Recognition_by_Retrieving_From_Web-Scale_Image-Text_Data_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Iscen_Improving_Image_Recognition_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.05173)] 

[bibtex]


[Dual-Path Adaptation From Image to Video Transformers](https://openaccess.thecvf.com/content/CVPR2023/html/Park_Dual-Path_Adaptation_From_Image_to_Video_Transformers_CVPR_2023_paper.html)

[Jungin Park](https://openaccess.thecvf.com/CVPR2023#), [Jiyoung Lee](https://openaccess.thecvf.com/CVPR2023#), [Kwanghoon Sohn](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Park_Dual-Path_Adaptation_From_Image_to_Video_Transformers_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Park_Dual-Path_Adaptation_From_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.09857)] 

[bibtex]


[Learning To Exploit the Sequence-Specific Prior Knowledge for Image Processing Pipelines Optimization](https://openaccess.thecvf.com/content/CVPR2023/html/Qin_Learning_To_Exploit_the_Sequence-Specific_Prior_Knowledge_for_Image_Processing_CVPR_2023_paper.html)

[Haina Qin](https://openaccess.thecvf.com/CVPR2023#), [Longfei Han](https://openaccess.thecvf.com/CVPR2023#), [Weihua Xiong](https://openaccess.thecvf.com/CVPR2023#), [Juan Wang](https://openaccess.thecvf.com/CVPR2023#), [Wentao Ma](https://openaccess.thecvf.com/CVPR2023#), [Bing Li](https://openaccess.thecvf.com/CVPR2023#), [Weiming Hu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Qin_Learning_To_Exploit_the_Sequence-Specific_Prior_Knowledge_for_Image_Processing_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Qin_Learning_To_Exploit_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Light Source Separation and Intrinsic Image Decomposition Under AC Illumination](https://openaccess.thecvf.com/content/CVPR2023/html/Yoshida_Light_Source_Separation_and_Intrinsic_Image_Decomposition_Under_AC_Illumination_CVPR_2023_paper.html)

[Yusaku Yoshida](https://openaccess.thecvf.com/CVPR2023#), [Ryo Kawahara](https://openaccess.thecvf.com/CVPR2023#), [Takahiro Okabe](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yoshida_Light_Source_Separation_and_Intrinsic_Image_Decomposition_Under_AC_Illumination_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yoshida_Light_Source_Separation_CVPR_2023_supplemental.zip)] 

[bibtex]


[Revisiting Temporal Modeling for CLIP-Based Image-to-Video Knowledge Transferring](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Revisiting_Temporal_Modeling_for_CLIP-Based_Image-to-Video_Knowledge_Transferring_CVPR_2023_paper.html)

[Ruyang Liu](https://openaccess.thecvf.com/CVPR2023#), [Jingjia Huang](https://openaccess.thecvf.com/CVPR2023#), [Ge Li](https://openaccess.thecvf.com/CVPR2023#), [Jiashi Feng](https://openaccess.thecvf.com/CVPR2023#), [Xinglong Wu](https://openaccess.thecvf.com/CVPR2023#), [Thomas H. Li](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Revisiting_Temporal_Modeling_for_CLIP-Based_Image-to-Video_Knowledge_Transferring_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2301.11116)] 

[bibtex]


[NeRFInvertor: High Fidelity NeRF-GAN Inversion for Single-Shot Real Image Animation](https://openaccess.thecvf.com/content/CVPR2023/html/Yin_NeRFInvertor_High_Fidelity_NeRF-GAN_Inversion_for_Single-Shot_Real_Image_Animation_CVPR_2023_paper.html)

[Yu Yin](https://openaccess.thecvf.com/CVPR2023#), [Kamran Ghasedi](https://openaccess.thecvf.com/CVPR2023#), [HsiangTao Wu](https://openaccess.thecvf.com/CVPR2023#), [Jiaolong Yang](https://openaccess.thecvf.com/CVPR2023#), [Xin Tong](https://openaccess.thecvf.com/CVPR2023#), [Yun Fu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yin_NeRFInvertor_High_Fidelity_NeRF-GAN_Inversion_for_Single-Shot_Real_Image_Animation_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2211.17235)] 

[bibtex]


[Self-Supervised Non-Uniform Kernel Estimation With Flow-Based Motion Prior for Blind Image Deblurring](https://openaccess.thecvf.com/content/CVPR2023/html/Fang_Self-Supervised_Non-Uniform_Kernel_Estimation_With_Flow-Based_Motion_Prior_for_Blind_CVPR_2023_paper.html)

[Zhenxuan Fang](https://openaccess.thecvf.com/CVPR2023#), [Fangfang Wu](https://openaccess.thecvf.com/CVPR2023#), [Weisheng Dong](https://openaccess.thecvf.com/CVPR2023#), [Xin Li](https://openaccess.thecvf.com/CVPR2023#), [Jinjian Wu](https://openaccess.thecvf.com/CVPR2023#), [Guangming Shi](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Fang_Self-Supervised_Non-Uniform_Kernel_Estimation_With_Flow-Based_Motion_Prior_for_Blind_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Fang_Self-Supervised_Non-Uniform_Kernel_CVPR_2023_supplemental.pdf)] 

[bibtex]


[DINER: Depth-Aware Image-Based NEural Radiance Fields](https://openaccess.thecvf.com/content/CVPR2023/html/Prinzler_DINER_Depth-Aware_Image-Based_NEural_Radiance_Fields_CVPR_2023_paper.html)

[Malte Prinzler](https://openaccess.thecvf.com/CVPR2023#), [Otmar Hilliges](https://openaccess.thecvf.com/CVPR2023#), [Justus Thies](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Prinzler_DINER_Depth-Aware_Image-Based_NEural_Radiance_Fields_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Prinzler_DINER_Depth-Aware_Image-Based_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.16630)] 

[bibtex]


[Burstormer: Burst Image Restoration and Enhancement Transformer](https://openaccess.thecvf.com/content/CVPR2023/html/Dudhane_Burstormer_Burst_Image_Restoration_and_Enhancement_Transformer_CVPR_2023_paper.html)

[Akshay Dudhane](https://openaccess.thecvf.com/CVPR2023#), [Syed Waqas Zamir](https://openaccess.thecvf.com/CVPR2023#), [Salman Khan](https://openaccess.thecvf.com/CVPR2023#), [Fahad Shahbaz Khan](https://openaccess.thecvf.com/CVPR2023#), [Ming-Hsuan Yang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Dudhane_Burstormer_Burst_Image_Restoration_and_Enhancement_Transformer_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Dudhane_Burstormer_Burst_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.01194)] 

[bibtex]


[SDC-UDA: Volumetric Unsupervised Domain Adaptation Framework for Slice-Direction Continuous Cross-Modality Medical Image Segmentation](https://openaccess.thecvf.com/content/CVPR2023/html/Shin_SDC-UDA_Volumetric_Unsupervised_Domain_Adaptation_Framework_for_Slice-Direction_Continuous_Cross-Modality_CVPR_2023_paper.html)

[Hyungseob Shin](https://openaccess.thecvf.com/CVPR2023#), [Hyeongyu Kim](https://openaccess.thecvf.com/CVPR2023#), [Sewon Kim](https://openaccess.thecvf.com/CVPR2023#), [Yohan Jun](https://openaccess.thecvf.com/CVPR2023#), [Taejoon Eo](https://openaccess.thecvf.com/CVPR2023#), [Dosik Hwang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Shin_SDC-UDA_Volumetric_Unsupervised_Domain_Adaptation_Framework_for_Slice-Direction_Continuous_Cross-Modality_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Shin_SDC-UDA_Volumetric_Unsupervised_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Perspective Fields for Single Image Camera Calibration](https://openaccess.thecvf.com/content/CVPR2023/html/Jin_Perspective_Fields_for_Single_Image_Camera_Calibration_CVPR_2023_paper.html)

[Linyi Jin](https://openaccess.thecvf.com/CVPR2023#), [Jianming Zhang](https://openaccess.thecvf.com/CVPR2023#), [Yannick Hold-Geoffroy](https://openaccess.thecvf.com/CVPR2023#), [Oliver Wang](https://openaccess.thecvf.com/CVPR2023#), [Kevin Blackburn-Matzen](https://openaccess.thecvf.com/CVPR2023#), [Matthew Sticha](https://openaccess.thecvf.com/CVPR2023#), [David F. Fouhey](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Jin_Perspective_Fields_for_Single_Image_Camera_Calibration_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Jin_Perspective_Fields_for_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.03239)] 

[bibtex]


[Towards Accurate Image Coding: Improved Autoregressive Image Generation With Dynamic Vector Quantization](https://openaccess.thecvf.com/content/CVPR2023/html/Huang_Towards_Accurate_Image_Coding_Improved_Autoregressive_Image_Generation_With_Dynamic_CVPR_2023_paper.html)

[Mengqi Huang](https://openaccess.thecvf.com/CVPR2023#), [Zhendong Mao](https://openaccess.thecvf.com/CVPR2023#), [Zhuowei Chen](https://openaccess.thecvf.com/CVPR2023#), [Yongdong Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Towards_Accurate_Image_Coding_Improved_Autoregressive_Image_Generation_With_Dynamic_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Huang_Towards_Accurate_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2305.11718)] 

[bibtex]


[ReCo: Region-Controlled Text-to-Image Generation](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_ReCo_Region-Controlled_Text-to-Image_Generation_CVPR_2023_paper.html)

[Zhengyuan Yang](https://openaccess.thecvf.com/CVPR2023#), [Jianfeng Wang](https://openaccess.thecvf.com/CVPR2023#), [Zhe Gan](https://openaccess.thecvf.com/CVPR2023#), [Linjie Li](https://openaccess.thecvf.com/CVPR2023#), [Kevin Lin](https://openaccess.thecvf.com/CVPR2023#), [Chenfei Wu](https://openaccess.thecvf.com/CVPR2023#), [Nan Duan](https://openaccess.thecvf.com/CVPR2023#), [Zicheng Liu](https://openaccess.thecvf.com/CVPR2023#), [Ce Liu](https://openaccess.thecvf.com/CVPR2023#), [Michael Zeng](https://openaccess.thecvf.com/CVPR2023#), [Lijuan Wang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_ReCo_Region-Controlled_Text-to-Image_Generation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yang_ReCo_Region-Controlled_Text-to-Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.15518)] 

[bibtex]


[Freestyle Layout-to-Image Synthesis](https://openaccess.thecvf.com/content/CVPR2023/html/Xue_Freestyle_Layout-to-Image_Synthesis_CVPR_2023_paper.html)

[Han Xue](https://openaccess.thecvf.com/CVPR2023#), [Zhiwu Huang](https://openaccess.thecvf.com/CVPR2023#), [Qianru Sun](https://openaccess.thecvf.com/CVPR2023#), [Li Song](https://openaccess.thecvf.com/CVPR2023#), [Wenjun Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_Freestyle_Layout-to-Image_Synthesis_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xue_Freestyle_Layout-to-Image_Synthesis_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.14412)] 

[bibtex]


[Breaching FedMD: Image Recovery via Paired-Logits Inversion Attack](https://openaccess.thecvf.com/content/CVPR2023/html/Takahashi_Breaching_FedMD_Image_Recovery_via_Paired-Logits_Inversion_Attack_CVPR_2023_paper.html)

[Hideaki Takahashi](https://openaccess.thecvf.com/CVPR2023#), [Jingjing Liu](https://openaccess.thecvf.com/CVPR2023#), [Yang Liu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Takahashi_Breaching_FedMD_Image_Recovery_via_Paired-Logits_Inversion_Attack_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Takahashi_Breaching_FedMD_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.11436)] 

[bibtex]


[Cross-Guided Optimization of Radiance Fields With Multi-View Image Super-Resolution for High-Resolution Novel View Synthesis](https://openaccess.thecvf.com/content/CVPR2023/html/Yoon_Cross-Guided_Optimization_of_Radiance_Fields_With_Multi-View_Image_Super-Resolution_for_CVPR_2023_paper.html)

[Youngho Yoon](https://openaccess.thecvf.com/CVPR2023#), [Kuk-Jin Yoon](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yoon_Cross-Guided_Optimization_of_Radiance_Fields_With_Multi-View_Image_Super-Resolution_for_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yoon_Cross-Guided_Optimization_of_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Positive-Augmented Contrastive Learning for Image and Video Captioning Evaluation](https://openaccess.thecvf.com/content/CVPR2023/html/Sarto_Positive-Augmented_Contrastive_Learning_for_Image_and_Video_Captioning_Evaluation_CVPR_2023_paper.html)

[Sara Sarto](https://openaccess.thecvf.com/CVPR2023#), [Manuele Barraco](https://openaccess.thecvf.com/CVPR2023#), [Marcella Cornia](https://openaccess.thecvf.com/CVPR2023#), [Lorenzo Baraldi](https://openaccess.thecvf.com/CVPR2023#), [Rita Cucchiara](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Sarto_Positive-Augmented_Contrastive_Learning_for_Image_and_Video_Captioning_Evaluation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Sarto_Positive-Augmented_Contrastive_Learning_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.12112)] 

[bibtex]


[3D Cinemagraphy From a Single Image](https://openaccess.thecvf.com/content/CVPR2023/html/Li_3D_Cinemagraphy_From_a_Single_Image_CVPR_2023_paper.html)

[Xingyi Li](https://openaccess.thecvf.com/CVPR2023#), [Zhiguo Cao](https://openaccess.thecvf.com/CVPR2023#), [Huiqiang Sun](https://openaccess.thecvf.com/CVPR2023#), [Jianming Zhang](https://openaccess.thecvf.com/CVPR2023#), [Ke Xian](https://openaccess.thecvf.com/CVPR2023#), [Guosheng Lin](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_3D_Cinemagraphy_From_a_Single_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_3D_Cinemagraphy_From_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.05724)] 

[bibtex]


[Learning Bottleneck Concepts in Image Classification](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Learning_Bottleneck_Concepts_in_Image_Classification_CVPR_2023_paper.html)

[Bowen Wang](https://openaccess.thecvf.com/CVPR2023#), [Liangzhi Li](https://openaccess.thecvf.com/CVPR2023#), [Yuta Nakashima](https://openaccess.thecvf.com/CVPR2023#), [Hajime Nagahara](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Learning_Bottleneck_Concepts_in_Image_Classification_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Learning_Bottleneck_Concepts_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.10131)] 

[bibtex]


[StyleRes: Transforming the Residuals for Real Image Editing With StyleGAN](https://openaccess.thecvf.com/content/CVPR2023/html/Pehlivan_StyleRes_Transforming_the_Residuals_for_Real_Image_Editing_With_StyleGAN_CVPR_2023_paper.html)

[Hamza Pehlivan](https://openaccess.thecvf.com/CVPR2023#), [Yusuf Dalva](https://openaccess.thecvf.com/CVPR2023#), [Aysegul Dundar](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Pehlivan_StyleRes_Transforming_the_Residuals_for_Real_Image_Editing_With_StyleGAN_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Pehlivan_StyleRes_Transforming_the_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.14359)] 

[bibtex]


[Conditional Text Image Generation With Diffusion Models](https://openaccess.thecvf.com/content/CVPR2023/html/Zhu_Conditional_Text_Image_Generation_With_Diffusion_Models_CVPR_2023_paper.html)

[Yuanzhi Zhu](https://openaccess.thecvf.com/CVPR2023#), [Zhaohai Li](https://openaccess.thecvf.com/CVPR2023#), [Tianwei Wang](https://openaccess.thecvf.com/CVPR2023#), [Mengchao He](https://openaccess.thecvf.com/CVPR2023#), [Cong Yao](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Conditional_Text_Image_Generation_With_Diffusion_Models_CVPR_2023_paper.pdf)] 

[bibtex]


[Regularization of Polynomial Networks for Image Recognition](https://openaccess.thecvf.com/content/CVPR2023/html/Chrysos_Regularization_of_Polynomial_Networks_for_Image_Recognition_CVPR_2023_paper.html)

[Grigorios G. Chrysos](https://openaccess.thecvf.com/CVPR2023#), [Bohan Wang](https://openaccess.thecvf.com/CVPR2023#), [Jiankang Deng](https://openaccess.thecvf.com/CVPR2023#), [Volkan Cevher](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chrysos_Regularization_of_Polynomial_Networks_for_Image_Recognition_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chrysos_Regularization_of_Polynomial_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.13896)] 

[bibtex]


[DynIBaR: Neural Dynamic Image-Based Rendering](https://openaccess.thecvf.com/content/CVPR2023/html/Li_DynIBaR_Neural_Dynamic_Image-Based_Rendering_CVPR_2023_paper.html)

[Zhengqi Li](https://openaccess.thecvf.com/CVPR2023#), [Qianqian Wang](https://openaccess.thecvf.com/CVPR2023#), [Forrester Cole](https://openaccess.thecvf.com/CVPR2023#), [Richard Tucker](https://openaccess.thecvf.com/CVPR2023#), [Noah Snavely](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_DynIBaR_Neural_Dynamic_Image-Based_Rendering_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_DynIBaR_Neural_Dynamic_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.11082)] 

[bibtex]


[Mofusion: A Framework for Denoising-Diffusion-Based Motion Synthesis](https://openaccess.thecvf.com/content/CVPR2023/html/Dabral_Mofusion_A_Framework_for_Denoising-Diffusion-Based_Motion_Synthesis_CVPR_2023_paper.html)

[Rishabh Dabral](https://openaccess.thecvf.com/CVPR2023#), [Muhammad Hamza Mughal](https://openaccess.thecvf.com/CVPR2023#), [Vladislav Golyanik](https://openaccess.thecvf.com/CVPR2023#), [Christian Theobalt](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Dabral_Mofusion_A_Framework_for_Denoising-Diffusion-Based_Motion_Synthesis_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Dabral_Mofusion_A_Framework_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2212.04495)] 

[bibtex]


[DiffusioNeRF: Regularizing Neural Radiance Fields With Denoising Diffusion Models](https://openaccess.thecvf.com/content/CVPR2023/html/Wynn_DiffusioNeRF_Regularizing_Neural_Radiance_Fields_With_Denoising_Diffusion_Models_CVPR_2023_paper.html)

[Jamie Wynn](https://openaccess.thecvf.com/CVPR2023#), [Daniyar Turmukhambetov](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wynn_DiffusioNeRF_Regularizing_Neural_Radiance_Fields_With_Denoising_Diffusion_Models_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2302.12231)] 

[bibtex]


[Edge-Aware Regional Message Passing Controller for Image Forgery Localization](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Edge-Aware_Regional_Message_Passing_Controller_for_Image_Forgery_Localization_CVPR_2023_paper.html)

[Dong Li](https://openaccess.thecvf.com/CVPR2023#), [Jiaying Zhu](https://openaccess.thecvf.com/CVPR2023#), [Menglu Wang](https://openaccess.thecvf.com/CVPR2023#), [Jiawei Liu](https://openaccess.thecvf.com/CVPR2023#), [Xueyang Fu](https://openaccess.thecvf.com/CVPR2023#), [Zheng-Jun Zha](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Edge-Aware_Regional_Message_Passing_Controller_for_Image_Forgery_Localization_CVPR_2023_paper.pdf)] 

[bibtex]


[Blind Image Quality Assessment via Vision-Language Correspondence: A Multitask Learning Perspective](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Blind_Image_Quality_Assessment_via_Vision-Language_Correspondence_A_Multitask_Learning_CVPR_2023_paper.html)

[Weixia Zhang](https://openaccess.thecvf.com/CVPR2023#), [Guangtao Zhai](https://openaccess.thecvf.com/CVPR2023#), [Ying Wei](https://openaccess.thecvf.com/CVPR2023#), [Xiaokang Yang](https://openaccess.thecvf.com/CVPR2023#), [Kede Ma](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Blind_Image_Quality_Assessment_via_Vision-Language_Correspondence_A_Multitask_Learning_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.14968)] 

[bibtex]


[Structural Multiplane Image: Bridging Neural View Synthesis and 3D Reconstruction](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Structural_Multiplane_Image_Bridging_Neural_View_Synthesis_and_3D_Reconstruction_CVPR_2023_paper.html)

[Mingfang Zhang](https://openaccess.thecvf.com/CVPR2023#), [Jinglu Wang](https://openaccess.thecvf.com/CVPR2023#), [Xiao Li](https://openaccess.thecvf.com/CVPR2023#), [Yifei Huang](https://openaccess.thecvf.com/CVPR2023#), [Yoichi Sato](https://openaccess.thecvf.com/CVPR2023#), [Yan Lu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Structural_Multiplane_Image_Bridging_Neural_View_Synthesis_and_3D_Reconstruction_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.05937)] 

[bibtex]


[Raw Image Reconstruction With Learned Compact Metadata](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Raw_Image_Reconstruction_With_Learned_Compact_Metadata_CVPR_2023_paper.html)

[Yufei Wang](https://openaccess.thecvf.com/CVPR2023#), [Yi Yu](https://openaccess.thecvf.com/CVPR2023#), [Wenhan Yang](https://openaccess.thecvf.com/CVPR2023#), [Lanqing Guo](https://openaccess.thecvf.com/CVPR2023#), [Lap-Pui Chau](https://openaccess.thecvf.com/CVPR2023#), [Alex C. Kot](https://openaccess.thecvf.com/CVPR2023#), [Bihan Wen](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Raw_Image_Reconstruction_With_Learned_Compact_Metadata_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Raw_Image_Reconstruction_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.12995)] 

[bibtex]


[Image Quality-Aware Diagnosis via Meta-Knowledge Co-Embedding](https://openaccess.thecvf.com/content/CVPR2023/html/Che_Image_Quality-Aware_Diagnosis_via_Meta-Knowledge_Co-Embedding_CVPR_2023_paper.html)

[Haoxuan Che](https://openaccess.thecvf.com/CVPR2023#), [Siyu Chen](https://openaccess.thecvf.com/CVPR2023#), [Hao Chen](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Che_Image_Quality-Aware_Diagnosis_via_Meta-Knowledge_Co-Embedding_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Che_Image_Quality-Aware_Diagnosis_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.15038)] 

[bibtex]


[Learning 3D Representations From 2D Pre-Trained Models via Image-to-Point Masked Autoencoders](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Learning_3D_Representations_From_2D_Pre-Trained_Models_via_Image-to-Point_Masked_CVPR_2023_paper.html)

[Renrui Zhang](https://openaccess.thecvf.com/CVPR2023#), [Liuhui Wang](https://openaccess.thecvf.com/CVPR2023#), [Yu Qiao](https://openaccess.thecvf.com/CVPR2023#), [Peng Gao](https://openaccess.thecvf.com/CVPR2023#), [Hongsheng Li](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Learning_3D_Representations_From_2D_Pre-Trained_Models_via_Image-to-Point_Masked_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhang_Learning_3D_Representations_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.06785)] 

[bibtex]


[BEVFormer v2: Adapting Modern Image Backbones to Bird's-Eye-View Recognition via Perspective Supervision](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_BEVFormer_v2_Adapting_Modern_Image_Backbones_to_Birds-Eye-View_Recognition_via_CVPR_2023_paper.html)

[Chenyu Yang](https://openaccess.thecvf.com/CVPR2023#), [Yuntao Chen](https://openaccess.thecvf.com/CVPR2023#), [Hao Tian](https://openaccess.thecvf.com/CVPR2023#), [Chenxin Tao](https://openaccess.thecvf.com/CVPR2023#), [Xizhou Zhu](https://openaccess.thecvf.com/CVPR2023#), [Zhaoxiang Zhang](https://openaccess.thecvf.com/CVPR2023#), [Gao Huang](https://openaccess.thecvf.com/CVPR2023#), [Hongyang Li](https://openaccess.thecvf.com/CVPR2023#), [Yu Qiao](https://openaccess.thecvf.com/CVPR2023#), [Lewei Lu](https://openaccess.thecvf.com/CVPR2023#), [Jie Zhou](https://openaccess.thecvf.com/CVPR2023#), [Jifeng Dai](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_BEVFormer_v2_Adapting_Modern_Image_Backbones_to_Birds-Eye-View_Recognition_via_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yang_BEVFormer_v2_Adapting_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Unpaired Image-to-Image Translation With Shortest Path Regularization](https://openaccess.thecvf.com/content/CVPR2023/html/Xie_Unpaired_Image-to-Image_Translation_With_Shortest_Path_Regularization_CVPR_2023_paper.html)

[Shaoan Xie](https://openaccess.thecvf.com/CVPR2023#), [Yanwu Xu](https://openaccess.thecvf.com/CVPR2023#), [Mingming Gong](https://openaccess.thecvf.com/CVPR2023#), [Kun Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_Unpaired_Image-to-Image_Translation_With_Shortest_Path_Regularization_CVPR_2023_paper.pdf)] 

[bibtex]


[QuantArt: Quantizing Image Style Transfer Towards High Visual Fidelity](https://openaccess.thecvf.com/content/CVPR2023/html/Huang_QuantArt_Quantizing_Image_Style_Transfer_Towards_High_Visual_Fidelity_CVPR_2023_paper.html)

[Siyu Huang](https://openaccess.thecvf.com/CVPR2023#), [Jie An](https://openaccess.thecvf.com/CVPR2023#), [Donglai Wei](https://openaccess.thecvf.com/CVPR2023#), [Jiebo Luo](https://openaccess.thecvf.com/CVPR2023#), [Hanspeter Pfister](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_QuantArt_Quantizing_Image_Style_Transfer_Towards_High_Visual_Fidelity_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Huang_QuantArt_Quantizing_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.10431)] 

[bibtex]


[Learning a Sparse Transformer Network for Effective Image Deraining](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Learning_a_Sparse_Transformer_Network_for_Effective_Image_Deraining_CVPR_2023_paper.html)

[Xiang Chen](https://openaccess.thecvf.com/CVPR2023#), [Hao Li](https://openaccess.thecvf.com/CVPR2023#), [Mingqiang Li](https://openaccess.thecvf.com/CVPR2023#), [Jinshan Pan](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Learning_a_Sparse_Transformer_Network_for_Effective_Image_Deraining_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chen_Learning_a_Sparse_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.11950)] 

[bibtex]


[CutMIB: Boosting Light Field Super-Resolution via Multi-View Image Blending](https://openaccess.thecvf.com/content/CVPR2023/html/Xiao_CutMIB_Boosting_Light_Field_Super-Resolution_via_Multi-View_Image_Blending_CVPR_2023_paper.html)

[Zeyu Xiao](https://openaccess.thecvf.com/CVPR2023#), [Yutong Liu](https://openaccess.thecvf.com/CVPR2023#), [Ruisheng Gao](https://openaccess.thecvf.com/CVPR2023#), [Zhiwei Xiong](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xiao_CutMIB_Boosting_Light_Field_Super-Resolution_via_Multi-View_Image_Blending_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xiao_CutMIB_Boosting_Light_CVPR_2023_supplemental.pdf)] 

[bibtex]


[CR-FIQA: Face Image Quality Assessment by Learning Sample Relative Classifiability](https://openaccess.thecvf.com/content/CVPR2023/html/Boutros_CR-FIQA_Face_Image_Quality_Assessment_by_Learning_Sample_Relative_Classifiability_CVPR_2023_paper.html)

[Fadi Boutros](https://openaccess.thecvf.com/CVPR2023#), [Meiling Fang](https://openaccess.thecvf.com/CVPR2023#), [Marcel Klemt](https://openaccess.thecvf.com/CVPR2023#), [Biying Fu](https://openaccess.thecvf.com/CVPR2023#), [Naser Damer](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Boutros_CR-FIQA_Face_Image_Quality_Assessment_by_Learning_Sample_Relative_Classifiability_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Boutros_CR-FIQA_Face_Image_CVPR_2023_supplemental.pdf)] 

[bibtex]


[GeneCIS: A Benchmark for General Conditional Image Similarity](https://openaccess.thecvf.com/content/CVPR2023/html/Vaze_GeneCIS_A_Benchmark_for_General_Conditional_Image_Similarity_CVPR_2023_paper.html)

[Sagar Vaze](https://openaccess.thecvf.com/CVPR2023#), [Nicolas Carion](https://openaccess.thecvf.com/CVPR2023#), [Ishan Misra](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Vaze_GeneCIS_A_Benchmark_for_General_Conditional_Image_Similarity_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Vaze_GeneCIS_A_Benchmark_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Learning Semantic Relationship Among Instances for Image-Text Matching](https://openaccess.thecvf.com/content/CVPR2023/html/Fu_Learning_Semantic_Relationship_Among_Instances_for_Image-Text_Matching_CVPR_2023_paper.html)

[Zheren Fu](https://openaccess.thecvf.com/CVPR2023#), [Zhendong Mao](https://openaccess.thecvf.com/CVPR2023#), [Yan Song](https://openaccess.thecvf.com/CVPR2023#), [Yongdong Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Fu_Learning_Semantic_Relationship_Among_Instances_for_Image-Text_Matching_CVPR_2023_paper.pdf)] 

[bibtex]


[Self-Supervised Image-to-Point Distillation via Semantically Tolerant Contrastive Loss](https://openaccess.thecvf.com/content/CVPR2023/html/Mahmoud_Self-Supervised_Image-to-Point_Distillation_via_Semantically_Tolerant_Contrastive_Loss_CVPR_2023_paper.html)

[Anas Mahmoud](https://openaccess.thecvf.com/CVPR2023#), [Jordan S. K. Hu](https://openaccess.thecvf.com/CVPR2023#), [Tianshu Kuai](https://openaccess.thecvf.com/CVPR2023#), [Ali Harakeh](https://openaccess.thecvf.com/CVPR2023#), [Liam Paull](https://openaccess.thecvf.com/CVPR2023#), [Steven L. Waslander](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Mahmoud_Self-Supervised_Image-to-Point_Distillation_via_Semantically_Tolerant_Contrastive_Loss_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Mahmoud_Self-Supervised_Image-to-Point_Distillation_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2301.05709)] 

[bibtex]


[Image Super-Resolution Using T-Tetromino Pixels](https://openaccess.thecvf.com/content/CVPR2023/html/Grosche_Image_Super-Resolution_Using_T-Tetromino_Pixels_CVPR_2023_paper.html)

[Simon Grosche](https://openaccess.thecvf.com/CVPR2023#), [Andy Regensky](https://openaccess.thecvf.com/CVPR2023#), [Jürgen Seiler](https://openaccess.thecvf.com/CVPR2023#), [André Kaup](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Grosche_Image_Super-Resolution_Using_T-Tetromino_Pixels_CVPR_2023_paper.pdf)] 

[bibtex]


[Toward Accurate Post-Training Quantization for Image Super Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Tu_Toward_Accurate_Post-Training_Quantization_for_Image_Super_Resolution_CVPR_2023_paper.html)

[Zhijun Tu](https://openaccess.thecvf.com/CVPR2023#), [Jie Hu](https://openaccess.thecvf.com/CVPR2023#), [Hanting Chen](https://openaccess.thecvf.com/CVPR2023#), [Yunhe Wang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Tu_Toward_Accurate_Post-Training_Quantization_for_Image_Super_Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Tu_Toward_Accurate_Post-Training_CVPR_2023_supplemental.pdf)] 

[bibtex]


[High-Fidelity Clothed Avatar Reconstruction From a Single Image](https://openaccess.thecvf.com/content/CVPR2023/html/Liao_High-Fidelity_Clothed_Avatar_Reconstruction_From_a_Single_Image_CVPR_2023_paper.html)

[Tingting Liao](https://openaccess.thecvf.com/CVPR2023#), [Xiaomei Zhang](https://openaccess.thecvf.com/CVPR2023#), [Yuliang Xiu](https://openaccess.thecvf.com/CVPR2023#), [Hongwei Yi](https://openaccess.thecvf.com/CVPR2023#), [Xudong Liu](https://openaccess.thecvf.com/CVPR2023#), [Guo-Jun Qi](https://openaccess.thecvf.com/CVPR2023#), [Yong Zhang](https://openaccess.thecvf.com/CVPR2023#), [Xuan Wang](https://openaccess.thecvf.com/CVPR2023#), [Xiangyu Zhu](https://openaccess.thecvf.com/CVPR2023#), [Zhen Lei](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Liao_High-Fidelity_Clothed_Avatar_Reconstruction_From_a_Single_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Liao_High-Fidelity_Clothed_Avatar_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2304.03903)] 

[bibtex]


[CoralStyleCLIP: Co-Optimized Region and Layer Selection for Image Editing](https://openaccess.thecvf.com/content/CVPR2023/html/Revanur_CoralStyleCLIP_Co-Optimized_Region_and_Layer_Selection_for_Image_Editing_CVPR_2023_paper.html)

[Ambareesh Revanur](https://openaccess.thecvf.com/CVPR2023#), [Debraj Basu](https://openaccess.thecvf.com/CVPR2023#), [Shradha Agrawal](https://openaccess.thecvf.com/CVPR2023#), [Dhwanit Agarwal](https://openaccess.thecvf.com/CVPR2023#), [Deepak Pai](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Revanur_CoralStyleCLIP_Co-Optimized_Region_and_Layer_Selection_for_Image_Editing_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Revanur_CoralStyleCLIP_Co-Optimized_Region_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.05031)] 

[bibtex]


[GALIP: Generative Adversarial CLIPs for Text-to-Image Synthesis](https://openaccess.thecvf.com/content/CVPR2023/html/Tao_GALIP_Generative_Adversarial_CLIPs_for_Text-to-Image_Synthesis_CVPR_2023_paper.html)

[Ming Tao](https://openaccess.thecvf.com/CVPR2023#), [Bing-Kun Bao](https://openaccess.thecvf.com/CVPR2023#), [Hao Tang](https://openaccess.thecvf.com/CVPR2023#), [Changsheng Xu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Tao_GALIP_Generative_Adversarial_CLIPs_for_Text-to-Image_Synthesis_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2301.12959)] 

[bibtex]


[Low-Light Image Enhancement via Structure Modeling and Guidance](https://openaccess.thecvf.com/content/CVPR2023/html/Xu_Low-Light_Image_Enhancement_via_Structure_Modeling_and_Guidance_CVPR_2023_paper.html)

[Xiaogang Xu](https://openaccess.thecvf.com/CVPR2023#), [Ruixing Wang](https://openaccess.thecvf.com/CVPR2023#), [Jiangbo Lu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Low-Light_Image_Enhancement_via_Structure_Modeling_and_Guidance_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2305.05839)] 

[bibtex]


[Person Image Synthesis via Denoising Diffusion Model](https://openaccess.thecvf.com/content/CVPR2023/html/Bhunia_Person_Image_Synthesis_via_Denoising_Diffusion_Model_CVPR_2023_paper.html)

[Ankan Kumar Bhunia](https://openaccess.thecvf.com/CVPR2023#), [Salman Khan](https://openaccess.thecvf.com/CVPR2023#), [Hisham Cholakkal](https://openaccess.thecvf.com/CVPR2023#), [Rao Muhammad Anwer](https://openaccess.thecvf.com/CVPR2023#), [Jorma Laaksonen](https://openaccess.thecvf.com/CVPR2023#), [Mubarak Shah](https://openaccess.thecvf.com/CVPR2023#), [Fahad Shahbaz Khan](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Bhunia_Person_Image_Synthesis_via_Denoising_Diffusion_Model_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Bhunia_Person_Image_Synthesis_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.12500)] 

[bibtex]


[Initialization Noise in Image Gradients and Saliency Maps](https://openaccess.thecvf.com/content/CVPR2023/html/Woerl_Initialization_Noise_in_Image_Gradients_and_Saliency_Maps_CVPR_2023_paper.html)

[Ann-Christin Woerl](https://openaccess.thecvf.com/CVPR2023#), [Jan Disselhoff](https://openaccess.thecvf.com/CVPR2023#), [Michael Wand](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Woerl_Initialization_Noise_in_Image_Gradients_and_Saliency_Maps_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Woerl_Initialization_Noise_in_CVPR_2023_supplemental.zip)] 

[bibtex]


[RIATIG: Reliable and Imperceptible Adversarial Text-to-Image Generation With Natural Prompts](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_RIATIG_Reliable_and_Imperceptible_Adversarial_Text-to-Image_Generation_With_Natural_Prompts_CVPR_2023_paper.html)

[Han Liu](https://openaccess.thecvf.com/CVPR2023#), [Yuhao Wu](https://openaccess.thecvf.com/CVPR2023#), [Shixuan Zhai](https://openaccess.thecvf.com/CVPR2023#), [Bo Yuan](https://openaccess.thecvf.com/CVPR2023#), [Ning Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_RIATIG_Reliable_and_Imperceptible_Adversarial_Text-to-Image_Generation_With_Natural_Prompts_CVPR_2023_paper.pdf)] 

[bibtex]


[GLIGEN: Open-Set Grounded Text-to-Image Generation](https://openaccess.thecvf.com/content/CVPR2023/html/Li_GLIGEN_Open-Set_Grounded_Text-to-Image_Generation_CVPR_2023_paper.html)

[Yuheng Li](https://openaccess.thecvf.com/CVPR2023#), [Haotian Liu](https://openaccess.thecvf.com/CVPR2023#), [Qingyang Wu](https://openaccess.thecvf.com/CVPR2023#), [Fangzhou Mu](https://openaccess.thecvf.com/CVPR2023#), [Jianwei Yang](https://openaccess.thecvf.com/CVPR2023#), [Jianfeng Gao](https://openaccess.thecvf.com/CVPR2023#), [Chunyuan Li](https://openaccess.thecvf.com/CVPR2023#), [Yong Jae Lee](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_GLIGEN_Open-Set_Grounded_Text-to-Image_Generation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_GLIGEN_Open-Set_Grounded_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2301.07093)] 

[bibtex]


[AccelIR: Task-Aware Image Compression for Accelerating Neural Restoration](https://openaccess.thecvf.com/content/CVPR2023/html/Ye_AccelIR_Task-Aware_Image_Compression_for_Accelerating_Neural_Restoration_CVPR_2023_paper.html)

[Juncheol Ye](https://openaccess.thecvf.com/CVPR2023#), [Hyunho Yeo](https://openaccess.thecvf.com/CVPR2023#), [Jinwoo Park](https://openaccess.thecvf.com/CVPR2023#), [Dongsu Han](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Ye_AccelIR_Task-Aware_Image_Compression_for_Accelerating_Neural_Restoration_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Ye_AccelIR_Task-Aware_Image_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Recovering 3D Hand Mesh Sequence From a Single Blurry Image: A New Dataset and Temporal Unfolding](https://openaccess.thecvf.com/content/CVPR2023/html/Oh_Recovering_3D_Hand_Mesh_Sequence_From_a_Single_Blurry_Image_CVPR_2023_paper.html)

[Yeonguk Oh](https://openaccess.thecvf.com/CVPR2023#), [JoonKyu Park](https://openaccess.thecvf.com/CVPR2023#), [Jaeha Kim](https://openaccess.thecvf.com/CVPR2023#), [Gyeongsik Moon](https://openaccess.thecvf.com/CVPR2023#), [Kyoung Mu Lee](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Oh_Recovering_3D_Hand_Mesh_Sequence_From_a_Single_Blurry_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Oh_Recovering_3D_Hand_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2303.15417)] 

[bibtex]


[Task-Specific Fine-Tuning via Variational Information Bottleneck for Weakly-Supervised Pathology Whole Slide Image Classification](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Task-Specific_Fine-Tuning_via_Variational_Information_Bottleneck_for_Weakly-Supervised_Pathology_Whole_CVPR_2023_paper.html)

[Honglin Li](https://openaccess.thecvf.com/CVPR2023#), [Chenglu Zhu](https://openaccess.thecvf.com/CVPR2023#), [Yunlong Zhang](https://openaccess.thecvf.com/CVPR2023#), [Yuxuan Sun](https://openaccess.thecvf.com/CVPR2023#), [Zhongyi Shui](https://openaccess.thecvf.com/CVPR2023#), [Wenwei Kuang](https://openaccess.thecvf.com/CVPR2023#), [Sunyi Zheng](https://openaccess.thecvf.com/CVPR2023#), [Lin Yang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Task-Specific_Fine-Tuning_via_Variational_Information_Bottleneck_for_Weakly-Supervised_Pathology_Whole_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_Task-Specific_Fine-Tuning_via_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.08446)] 

[bibtex]


[Single Image Depth Prediction Made Better: A Multivariate Gaussian Take](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Single_Image_Depth_Prediction_Made_Better_A_Multivariate_Gaussian_Take_CVPR_2023_paper.html)

[Ce Liu](https://openaccess.thecvf.com/CVPR2023#), [Suryansh Kumar](https://openaccess.thecvf.com/CVPR2023#), [Shuhang Gu](https://openaccess.thecvf.com/CVPR2023#), [Radu Timofte](https://openaccess.thecvf.com/CVPR2023#), [Luc Van Gool](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Single_Image_Depth_Prediction_Made_Better_A_Multivariate_Gaussian_Take_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Liu_Single_Image_Depth_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.18164)] 

[bibtex]


[NUWA-LIP: Language-Guided Image Inpainting With Defect-Free VQGAN](https://openaccess.thecvf.com/content/CVPR2023/html/Ni_NUWA-LIP_Language-Guided_Image_Inpainting_With_Defect-Free_VQGAN_CVPR_2023_paper.html)

[Minheng Ni](https://openaccess.thecvf.com/CVPR2023#), [Xiaoming Li](https://openaccess.thecvf.com/CVPR2023#), [Wangmeng Zuo](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Ni_NUWA-LIP_Language-Guided_Image_Inpainting_With_Defect-Free_VQGAN_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Ni_NUWA-LIP_Language-Guided_Image_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Orthogonal Annotation Benefits Barely-Supervised Medical Image Segmentation](https://openaccess.thecvf.com/content/CVPR2023/html/Cai_Orthogonal_Annotation_Benefits_Barely-Supervised_Medical_Image_Segmentation_CVPR_2023_paper.html)

[Heng Cai](https://openaccess.thecvf.com/CVPR2023#), [Shumeng Li](https://openaccess.thecvf.com/CVPR2023#), [Lei Qi](https://openaccess.thecvf.com/CVPR2023#), [Qian Yu](https://openaccess.thecvf.com/CVPR2023#), [Yinghuan Shi](https://openaccess.thecvf.com/CVPR2023#), [Yang Gao](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Cai_Orthogonal_Annotation_Benefits_Barely-Supervised_Medical_Image_Segmentation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Cai_Orthogonal_Annotation_Benefits_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.13090)] 

[bibtex]


[MetaFusion: Infrared and Visible Image Fusion via Meta-Feature Embedding From Object Detection](https://openaccess.thecvf.com/content/CVPR2023/html/Zhao_MetaFusion_Infrared_and_Visible_Image_Fusion_via_Meta-Feature_Embedding_From_CVPR_2023_paper.html)

[Wenda Zhao](https://openaccess.thecvf.com/CVPR2023#), [Shigeng Xie](https://openaccess.thecvf.com/CVPR2023#), [Fan Zhao](https://openaccess.thecvf.com/CVPR2023#), [You He](https://openaccess.thecvf.com/CVPR2023#), [Huchuan Lu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_MetaFusion_Infrared_and_Visible_Image_Fusion_via_Meta-Feature_Embedding_From_CVPR_2023_paper.pdf)] 

[bibtex]


[Spectral Enhanced Rectangle Transformer for Hyperspectral Image Denoising](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Spectral_Enhanced_Rectangle_Transformer_for_Hyperspectral_Image_Denoising_CVPR_2023_paper.html)

[Miaoyu Li](https://openaccess.thecvf.com/CVPR2023#), [Ji Liu](https://openaccess.thecvf.com/CVPR2023#), [Ying Fu](https://openaccess.thecvf.com/CVPR2023#), [Yulun Zhang](https://openaccess.thecvf.com/CVPR2023#), [Dejing Dou](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Spectral_Enhanced_Rectangle_Transformer_for_Hyperspectral_Image_Denoising_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_Spectral_Enhanced_Rectangle_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.00844)] 

[bibtex]


[On Data Scaling in Masked Image Modeling](https://openaccess.thecvf.com/content/CVPR2023/html/Xie_On_Data_Scaling_in_Masked_Image_Modeling_CVPR_2023_paper.html)

[Zhenda Xie](https://openaccess.thecvf.com/CVPR2023#), [Zheng Zhang](https://openaccess.thecvf.com/CVPR2023#), [Yue Cao](https://openaccess.thecvf.com/CVPR2023#), [Yutong Lin](https://openaccess.thecvf.com/CVPR2023#), [Yixuan Wei](https://openaccess.thecvf.com/CVPR2023#), [Qi Dai](https://openaccess.thecvf.com/CVPR2023#), [Han Hu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_On_Data_Scaling_in_Masked_Image_Modeling_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xie_On_Data_Scaling_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2206.04664)] 

[bibtex]


[UMat: Uncertainty-Aware Single Image High Resolution Material Capture](https://openaccess.thecvf.com/content/CVPR2023/html/Rodriguez-Pardo_UMat_Uncertainty-Aware_Single_Image_High_Resolution_Material_Capture_CVPR_2023_paper.html)

[Carlos Rodriguez-Pardo](https://openaccess.thecvf.com/CVPR2023#), [Henar Domínguez-Elvira](https://openaccess.thecvf.com/CVPR2023#), [David Pascual-Hernández](https://openaccess.thecvf.com/CVPR2023#), [Elena Garces](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Rodriguez-Pardo_UMat_Uncertainty-Aware_Single_Image_High_Resolution_Material_Capture_CVPR_2023_paper.pdf)] 

[bibtex]


[Rethinking Image Super Resolution From Long-Tailed Distribution Learning Perspective](https://openaccess.thecvf.com/content/CVPR2023/html/Gou_Rethinking_Image_Super_Resolution_From_Long-Tailed_Distribution_Learning_Perspective_CVPR_2023_paper.html)

[Yuanbiao Gou](https://openaccess.thecvf.com/CVPR2023#), [Peng Hu](https://openaccess.thecvf.com/CVPR2023#), [Jiancheng Lv](https://openaccess.thecvf.com/CVPR2023#), [Hongyuan Zhu](https://openaccess.thecvf.com/CVPR2023#), [Xi Peng](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Gou_Rethinking_Image_Super_Resolution_From_Long-Tailed_Distribution_Learning_Perspective_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Gou_Rethinking_Image_Super_CVPR_2023_supplemental.pdf)] 

[bibtex]


[High-Fidelity Guided Image Synthesis With Latent Diffusion Models](https://openaccess.thecvf.com/content/CVPR2023/html/Singh_High-Fidelity_Guided_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2023_paper.html)

[Jaskirat Singh](https://openaccess.thecvf.com/CVPR2023#), [Stephen Gould](https://openaccess.thecvf.com/CVPR2023#), [Liang Zheng](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Singh_High-Fidelity_Guided_Image_Synthesis_With_Latent_Diffusion_Models_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Singh_High-Fidelity_Guided_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.17084)] 

[bibtex]


[Semi-Supervised Parametric Real-World Image Harmonization](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Semi-Supervised_Parametric_Real-World_Image_Harmonization_CVPR_2023_paper.html)

[Ke Wang](https://openaccess.thecvf.com/CVPR2023#), [Michaël Gharbi](https://openaccess.thecvf.com/CVPR2023#), [He Zhang](https://openaccess.thecvf.com/CVPR2023#), [Zhihao Xia](https://openaccess.thecvf.com/CVPR2023#), [Eli Shechtman](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Semi-Supervised_Parametric_Real-World_Image_Harmonization_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Semi-Supervised_Parametric_Real-World_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.00157)] 

[bibtex]


[Not All Image Regions Matter: Masked Vector Quantization for Autoregressive Image Generation](https://openaccess.thecvf.com/content/CVPR2023/html/Huang_Not_All_Image_Regions_Matter_Masked_Vector_Quantization_for_Autoregressive_CVPR_2023_paper.html)

[Mengqi Huang](https://openaccess.thecvf.com/CVPR2023#), [Zhendong Mao](https://openaccess.thecvf.com/CVPR2023#), [Quan Wang](https://openaccess.thecvf.com/CVPR2023#), [Yongdong Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Huang_Not_All_Image_Regions_Matter_Masked_Vector_Quantization_for_Autoregressive_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Huang_Not_All_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2305.13607)] 

[bibtex]


[Exploring Incompatible Knowledge Transfer in Few-Shot Image Generation](https://openaccess.thecvf.com/content/CVPR2023/html/Zhao_Exploring_Incompatible_Knowledge_Transfer_in_Few-Shot_Image_Generation_CVPR_2023_paper.html)

[Yunqing Zhao](https://openaccess.thecvf.com/CVPR2023#), [Chao Du](https://openaccess.thecvf.com/CVPR2023#), [Milad Abdollahzadeh](https://openaccess.thecvf.com/CVPR2023#), [Tianyu Pang](https://openaccess.thecvf.com/CVPR2023#), [Min Lin](https://openaccess.thecvf.com/CVPR2023#), [Shuicheng Yan](https://openaccess.thecvf.com/CVPR2023#), [Ngai-Man Cheung](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Exploring_Incompatible_Knowledge_Transfer_in_Few-Shot_Image_Generation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhao_Exploring_Incompatible_Knowledge_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.07574)] 

[bibtex]


[All-in-One Image Restoration for Unknown Degradations Using Adaptive Discriminative Filters for Specific Degradations](https://openaccess.thecvf.com/content/CVPR2023/html/Park_All-in-One_Image_Restoration_for_Unknown_Degradations_Using_Adaptive_Discriminative_Filters_CVPR_2023_paper.html)

[Dongwon Park](https://openaccess.thecvf.com/CVPR2023#), [Byung Hyun Lee](https://openaccess.thecvf.com/CVPR2023#), [Se Young Chun](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Park_All-in-One_Image_Restoration_for_Unknown_Degradations_Using_Adaptive_Discriminative_Filters_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Park_All-in-One_Image_Restoration_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Zero-Shot Generative Model Adaptation via Image-Specific Prompt Learning](https://openaccess.thecvf.com/content/CVPR2023/html/Guo_Zero-Shot_Generative_Model_Adaptation_via_Image-Specific_Prompt_Learning_CVPR_2023_paper.html)

[Jiayi Guo](https://openaccess.thecvf.com/CVPR2023#), [Chaofei Wang](https://openaccess.thecvf.com/CVPR2023#), [You Wu](https://openaccess.thecvf.com/CVPR2023#), [Eric Zhang](https://openaccess.thecvf.com/CVPR2023#), [Kai Wang](https://openaccess.thecvf.com/CVPR2023#), [Xingqian Xu](https://openaccess.thecvf.com/CVPR2023#), [Shiji Song](https://openaccess.thecvf.com/CVPR2023#), [Humphrey Shi](https://openaccess.thecvf.com/CVPR2023#), [Gao Huang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Guo_Zero-Shot_Generative_Model_Adaptation_via_Image-Specific_Prompt_Learning_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Guo_Zero-Shot_Generative_Model_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2304.03119)] 

[bibtex]


[Hard Patches Mining for Masked Image Modeling](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Hard_Patches_Mining_for_Masked_Image_Modeling_CVPR_2023_paper.html)

[Haochen Wang](https://openaccess.thecvf.com/CVPR2023#), [Kaiyou Song](https://openaccess.thecvf.com/CVPR2023#), [Junsong Fan](https://openaccess.thecvf.com/CVPR2023#), [Yuxi Wang](https://openaccess.thecvf.com/CVPR2023#), [Jin Xie](https://openaccess.thecvf.com/CVPR2023#), [Zhaoxiang Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Hard_Patches_Mining_for_Masked_Image_Modeling_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Hard_Patches_Mining_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.05919)] 

[bibtex]


[Semantic-Conditional Diffusion Networks for Image Captioning](https://openaccess.thecvf.com/content/CVPR2023/html/Luo_Semantic-Conditional_Diffusion_Networks_for_Image_Captioning_CVPR_2023_paper.html)

[Jianjie Luo](https://openaccess.thecvf.com/CVPR2023#), [Yehao Li](https://openaccess.thecvf.com/CVPR2023#), [Yingwei Pan](https://openaccess.thecvf.com/CVPR2023#), [Ting Yao](https://openaccess.thecvf.com/CVPR2023#), [Jianlin Feng](https://openaccess.thecvf.com/CVPR2023#), [Hongyang Chao](https://openaccess.thecvf.com/CVPR2023#), [Tao Mei](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Luo_Semantic-Conditional_Diffusion_Networks_for_Image_Captioning_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2212.03099)] 

[bibtex]


[Boundary-Aware Backward-Compatible Representation via Adversarial Learning in Image Retrieval](https://openaccess.thecvf.com/content/CVPR2023/html/Pan_Boundary-Aware_Backward-Compatible_Representation_via_Adversarial_Learning_in_Image_Retrieval_CVPR_2023_paper.html)

[Tan Pan](https://openaccess.thecvf.com/CVPR2023#), [Furong Xu](https://openaccess.thecvf.com/CVPR2023#), [Xudong Yang](https://openaccess.thecvf.com/CVPR2023#), [Sifeng He](https://openaccess.thecvf.com/CVPR2023#), [Chen Jiang](https://openaccess.thecvf.com/CVPR2023#), [Qingpei Guo](https://openaccess.thecvf.com/CVPR2023#), [Feng Qian](https://openaccess.thecvf.com/CVPR2023#), [Xiaobo Zhang](https://openaccess.thecvf.com/CVPR2023#), [Yuan Cheng](https://openaccess.thecvf.com/CVPR2023#), [Lei Yang](https://openaccess.thecvf.com/CVPR2023#), [Wei Chu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Pan_Boundary-Aware_Backward-Compatible_Representation_via_Adversarial_Learning_in_Image_Retrieval_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Pan_Boundary-Aware_Backward-Compatible_Representation_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2305.02610)] 

[bibtex]


[Efficient Frequency Domain-Based Transformers for High-Quality Image Deblurring](https://openaccess.thecvf.com/content/CVPR2023/html/Kong_Efficient_Frequency_Domain-Based_Transformers_for_High-Quality_Image_Deblurring_CVPR_2023_paper.html)

[Lingshun Kong](https://openaccess.thecvf.com/CVPR2023#), [Jiangxin Dong](https://openaccess.thecvf.com/CVPR2023#), [Jianjun Ge](https://openaccess.thecvf.com/CVPR2023#), [Mingqiang Li](https://openaccess.thecvf.com/CVPR2023#), [Jinshan Pan](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Kong_Efficient_Frequency_Domain-Based_Transformers_for_High-Quality_Image_Deblurring_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Kong_Efficient_Frequency_Domain-Based_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.12250)] 

[bibtex]


[SINE: Semantic-Driven Image-Based NeRF Editing With Prior-Guided Editing Field](https://openaccess.thecvf.com/content/CVPR2023/html/Bao_SINE_Semantic-Driven_Image-Based_NeRF_Editing_With_Prior-Guided_Editing_Field_CVPR_2023_paper.html)

[Chong Bao](https://openaccess.thecvf.com/CVPR2023#), [Yinda Zhang](https://openaccess.thecvf.com/CVPR2023#), [Bangbang Yang](https://openaccess.thecvf.com/CVPR2023#), [Tianxing Fan](https://openaccess.thecvf.com/CVPR2023#), [Zesong Yang](https://openaccess.thecvf.com/CVPR2023#), [Hujun Bao](https://openaccess.thecvf.com/CVPR2023#), [Guofeng Zhang](https://openaccess.thecvf.com/CVPR2023#), [Zhaopeng Cui](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Bao_SINE_Semantic-Driven_Image-Based_NeRF_Editing_With_Prior-Guided_Editing_Field_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Bao_SINE_Semantic-Driven_Image-Based_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2303.13277)] 

[bibtex]


[B-Spline Texture Coefficients Estimator for Screen Content Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Pak_B-Spline_Texture_Coefficients_Estimator_for_Screen_Content_Image_Super-Resolution_CVPR_2023_paper.html)

[Byeonghyun Pak](https://openaccess.thecvf.com/CVPR2023#), [Jaewon Lee](https://openaccess.thecvf.com/CVPR2023#), [Kyong Hwan Jin](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Pak_B-Spline_Texture_Coefficients_Estimator_for_Screen_Content_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Pak_B-Spline_Texture_Coefficients_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Domain Expansion of Image Generators](https://openaccess.thecvf.com/content/CVPR2023/html/Nitzan_Domain_Expansion_of_Image_Generators_CVPR_2023_paper.html)

[Yotam Nitzan](https://openaccess.thecvf.com/CVPR2023#), [Michaël Gharbi](https://openaccess.thecvf.com/CVPR2023#), [Richard Zhang](https://openaccess.thecvf.com/CVPR2023#), [Taesung Park](https://openaccess.thecvf.com/CVPR2023#), [Jun-Yan Zhu](https://openaccess.thecvf.com/CVPR2023#), [Daniel Cohen-Or](https://openaccess.thecvf.com/CVPR2023#), [Eli Shechtman](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Nitzan_Domain_Expansion_of_Image_Generators_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Nitzan_Domain_Expansion_of_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2301.05225)] 

[bibtex]


[LVQAC: Lattice Vector Quantization Coupled With Spatially Adaptive Companding for Efficient Learned Image Compression](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_LVQAC_Lattice_Vector_Quantization_Coupled_With_Spatially_Adaptive_Companding_for_CVPR_2023_paper.html)

[Xi Zhang](https://openaccess.thecvf.com/CVPR2023#), [Xiaolin Wu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_LVQAC_Lattice_Vector_Quantization_Coupled_With_Spatially_Adaptive_Companding_for_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2304.12319)] 

[bibtex]


[Where Is My Spot? Few-Shot Image Generation via Latent Subspace Optimization](https://openaccess.thecvf.com/content/CVPR2023/html/Zheng_Where_Is_My_Spot_Few-Shot_Image_Generation_via_Latent_Subspace_CVPR_2023_paper.html)

[Chenxi Zheng](https://openaccess.thecvf.com/CVPR2023#), [Bangzhen Liu](https://openaccess.thecvf.com/CVPR2023#), [Huaidong Zhang](https://openaccess.thecvf.com/CVPR2023#), [Xuemiao Xu](https://openaccess.thecvf.com/CVPR2023#), [Shengfeng He](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_Where_Is_My_Spot_Few-Shot_Image_Generation_via_Latent_Subspace_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zheng_Where_Is_My_CVPR_2023_supplemental.pdf)] 

[bibtex]


[TopNet: Transformer-Based Object Placement Network for Image Compositing](https://openaccess.thecvf.com/content/CVPR2023/html/Zhu_TopNet_Transformer-Based_Object_Placement_Network_for_Image_Compositing_CVPR_2023_paper.html)

[Sijie Zhu](https://openaccess.thecvf.com/CVPR2023#), [Zhe Lin](https://openaccess.thecvf.com/CVPR2023#), [Scott Cohen](https://openaccess.thecvf.com/CVPR2023#), [Jason Kuen](https://openaccess.thecvf.com/CVPR2023#), [Zhifei Zhang](https://openaccess.thecvf.com/CVPR2023#), [Chen Chen](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_TopNet_Transformer-Based_Object_Placement_Network_for_Image_Compositing_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhu_TopNet_Transformer-Based_Object_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.03372)] 

[bibtex]


[Robot Structure Prior Guided Temporal Attention for Camera-to-Robot Pose Estimation From Image Sequence](https://openaccess.thecvf.com/content/CVPR2023/html/Tian_Robot_Structure_Prior_Guided_Temporal_Attention_for_Camera-to-Robot_Pose_Estimation_CVPR_2023_paper.html)

[Yang Tian](https://openaccess.thecvf.com/CVPR2023#), [Jiyao Zhang](https://openaccess.thecvf.com/CVPR2023#), [Zekai Yin](https://openaccess.thecvf.com/CVPR2023#), [Hao Dong](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Tian_Robot_Structure_Prior_Guided_Temporal_Attention_for_Camera-to-Robot_Pose_Estimation_CVPR_2023_paper.pdf)] 

[bibtex]


[SimpleNet: A Simple Network for Image Anomaly Detection and Localization](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_SimpleNet_A_Simple_Network_for_Image_Anomaly_Detection_and_Localization_CVPR_2023_paper.html)

[Zhikang Liu](https://openaccess.thecvf.com/CVPR2023#), [Yiming Zhou](https://openaccess.thecvf.com/CVPR2023#), [Yuansheng Xu](https://openaccess.thecvf.com/CVPR2023#), [Zilei Wang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_SimpleNet_A_Simple_Network_for_Image_Anomaly_Detection_and_Localization_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.15140)] 

[bibtex]


[Siamese Image Modeling for Self-Supervised Vision Representation Learning](https://openaccess.thecvf.com/content/CVPR2023/html/Tao_Siamese_Image_Modeling_for_Self-Supervised_Vision_Representation_Learning_CVPR_2023_paper.html)

[Chenxin Tao](https://openaccess.thecvf.com/CVPR2023#), [Xizhou Zhu](https://openaccess.thecvf.com/CVPR2023#), [Weijie Su](https://openaccess.thecvf.com/CVPR2023#), [Gao Huang](https://openaccess.thecvf.com/CVPR2023#), [Bin Li](https://openaccess.thecvf.com/CVPR2023#), [Jie Zhou](https://openaccess.thecvf.com/CVPR2023#), [Yu Qiao](https://openaccess.thecvf.com/CVPR2023#), [Xiaogang Wang](https://openaccess.thecvf.com/CVPR2023#), [Jifeng Dai](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Tao_Siamese_Image_Modeling_for_Self-Supervised_Vision_Representation_Learning_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Tao_Siamese_Image_Modeling_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2206.01204)] 

[bibtex]


[CABM: Content-Aware Bit Mapping for Single Image Super-Resolution Network With Large Input](https://openaccess.thecvf.com/content/CVPR2023/html/Tian_CABM_Content-Aware_Bit_Mapping_for_Single_Image_Super-Resolution_Network_With_CVPR_2023_paper.html)

[Senmao Tian](https://openaccess.thecvf.com/CVPR2023#), [Ming Lu](https://openaccess.thecvf.com/CVPR2023#), [Jiaming Liu](https://openaccess.thecvf.com/CVPR2023#), [Yandong Guo](https://openaccess.thecvf.com/CVPR2023#), [Yurong Chen](https://openaccess.thecvf.com/CVPR2023#), [Shunli Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Tian_CABM_Content-Aware_Bit_Mapping_for_Single_Image_Super-Resolution_Network_With_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2304.06454)] 

[bibtex]


[Delving StyleGAN Inversion for Image Editing: A Foundation Latent Space Viewpoint](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Delving_StyleGAN_Inversion_for_Image_Editing_A_Foundation_Latent_Space_CVPR_2023_paper.html)

[Hongyu Liu](https://openaccess.thecvf.com/CVPR2023#), [Yibing Song](https://openaccess.thecvf.com/CVPR2023#), [Qifeng Chen](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Delving_StyleGAN_Inversion_for_Image_Editing_A_Foundation_Latent_Space_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Liu_Delving_StyleGAN_Inversion_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.11448)] 

[bibtex]


[MCF: Mutual Correction Framework for Semi-Supervised Medical Image Segmentation](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_MCF_Mutual_Correction_Framework_for_Semi-Supervised_Medical_Image_Segmentation_CVPR_2023_paper.html)

[Yongchao Wang](https://openaccess.thecvf.com/CVPR2023#), [Bin Xiao](https://openaccess.thecvf.com/CVPR2023#), [Xiuli Bi](https://openaccess.thecvf.com/CVPR2023#), [Weisheng Li](https://openaccess.thecvf.com/CVPR2023#), [Xinbo Gao](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_MCF_Mutual_Correction_Framework_for_Semi-Supervised_Medical_Image_Segmentation_CVPR_2023_paper.pdf)] 

[bibtex]


[VILA: Learning Image Aesthetics From User Comments With Vision-Language Pretraining](https://openaccess.thecvf.com/content/CVPR2023/html/Ke_VILA_Learning_Image_Aesthetics_From_User_Comments_With_Vision-Language_Pretraining_CVPR_2023_paper.html)

[Junjie Ke](https://openaccess.thecvf.com/CVPR2023#), [Keren Ye](https://openaccess.thecvf.com/CVPR2023#), [Jiahui Yu](https://openaccess.thecvf.com/CVPR2023#), [Yonghui Wu](https://openaccess.thecvf.com/CVPR2023#), [Peyman Milanfar](https://openaccess.thecvf.com/CVPR2023#), [Feng Yang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Ke_VILA_Learning_Image_Aesthetics_From_User_Comments_With_Vision-Language_Pretraining_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Ke_VILA_Learning_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.14302)] 

[bibtex]


[Re-IQA: Unsupervised Learning for Image Quality Assessment in the Wild](https://openaccess.thecvf.com/content/CVPR2023/html/Saha_Re-IQA_Unsupervised_Learning_for_Image_Quality_Assessment_in_the_Wild_CVPR_2023_paper.html)

[Avinab Saha](https://openaccess.thecvf.com/CVPR2023#), [Sandeep Mishra](https://openaccess.thecvf.com/CVPR2023#), [Alan C. Bovik](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Saha_Re-IQA_Unsupervised_Learning_for_Image_Quality_Assessment_in_the_Wild_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Saha_Re-IQA_Unsupervised_Learning_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Catch Missing Details: Image Reconstruction With Frequency Augmented Variational Autoencoder](https://openaccess.thecvf.com/content/CVPR2023/html/Lin_Catch_Missing_Details_Image_Reconstruction_With_Frequency_Augmented_Variational_Autoencoder_CVPR_2023_paper.html)

[Xinmiao Lin](https://openaccess.thecvf.com/CVPR2023#), [Yikang Li](https://openaccess.thecvf.com/CVPR2023#), [Jenhao Hsiao](https://openaccess.thecvf.com/CVPR2023#), [Chiuman Ho](https://openaccess.thecvf.com/CVPR2023#), [Yu Kong](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Catch_Missing_Details_Image_Reconstruction_With_Frequency_Augmented_Variational_Autoencoder_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Lin_Catch_Missing_Details_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2305.02541)] 

[bibtex]


[ConZIC: Controllable Zero-Shot Image Captioning by Sampling-Based Polishing](https://openaccess.thecvf.com/content/CVPR2023/html/Zeng_ConZIC_Controllable_Zero-Shot_Image_Captioning_by_Sampling-Based_Polishing_CVPR_2023_paper.html)

[Zequn Zeng](https://openaccess.thecvf.com/CVPR2023#), [Hao Zhang](https://openaccess.thecvf.com/CVPR2023#), [Ruiying Lu](https://openaccess.thecvf.com/CVPR2023#), [Dongsheng Wang](https://openaccess.thecvf.com/CVPR2023#), [Bo Chen](https://openaccess.thecvf.com/CVPR2023#), [Zhengjue Wang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zeng_ConZIC_Controllable_Zero-Shot_Image_Captioning_by_Sampling-Based_Polishing_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zeng_ConZIC_Controllable_Zero-Shot_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.02437)] 

[bibtex]


[Curricular Contrastive Regularization for Physics-Aware Single Image Dehazing](https://openaccess.thecvf.com/content/CVPR2023/html/Zheng_Curricular_Contrastive_Regularization_for_Physics-Aware_Single_Image_Dehazing_CVPR_2023_paper.html)

[Yu Zheng](https://openaccess.thecvf.com/CVPR2023#), [Jiahui Zhan](https://openaccess.thecvf.com/CVPR2023#), [Shengfeng He](https://openaccess.thecvf.com/CVPR2023#), [Junyu Dong](https://openaccess.thecvf.com/CVPR2023#), [Yong Du](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_Curricular_Contrastive_Regularization_for_Physics-Aware_Single_Image_Dehazing_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zheng_Curricular_Contrastive_Regularization_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.14218)] 

[bibtex]


[Language in a Bottle: Language Model Guided Concept Bottlenecks for Interpretable Image Classification](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_Language_in_a_Bottle_Language_Model_Guided_Concept_Bottlenecks_for_CVPR_2023_paper.html)

[Yue Yang](https://openaccess.thecvf.com/CVPR2023#), [Artemis Panagopoulou](https://openaccess.thecvf.com/CVPR2023#), [Shenghao Zhou](https://openaccess.thecvf.com/CVPR2023#), [Daniel Jin](https://openaccess.thecvf.com/CVPR2023#), [Chris Callison-Burch](https://openaccess.thecvf.com/CVPR2023#), [Mark Yatskar](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Language_in_a_Bottle_Language_Model_Guided_Concept_Bottlenecks_for_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yang_Language_in_a_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.11158)] 

[bibtex]


[Bi-Directional Feature Fusion Generative Adversarial Network for Ultra-High Resolution Pathological Image Virtual Re-Staining](https://openaccess.thecvf.com/content/CVPR2023/html/Sun_Bi-Directional_Feature_Fusion_Generative_Adversarial_Network_for_Ultra-High_Resolution_Pathological_CVPR_2023_paper.html)

[Kexin Sun](https://openaccess.thecvf.com/CVPR2023#), [Zhineng Chen](https://openaccess.thecvf.com/CVPR2023#), [Gongwei Wang](https://openaccess.thecvf.com/CVPR2023#), [Jun Liu](https://openaccess.thecvf.com/CVPR2023#), [Xiongjun Ye](https://openaccess.thecvf.com/CVPR2023#), [Yu-Gang Jiang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Bi-Directional_Feature_Fusion_Generative_Adversarial_Network_for_Ultra-High_Resolution_Pathological_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Sun_Bi-Directional_Feature_Fusion_CVPR_2023_supplemental.pdf)] 

[bibtex]


[NeRDi: Single-View NeRF Synthesis With Language-Guided Diffusion As General Image Priors](https://openaccess.thecvf.com/content/CVPR2023/html/Deng_NeRDi_Single-View_NeRF_Synthesis_With_Language-Guided_Diffusion_As_General_Image_CVPR_2023_paper.html)

[Congyue Deng](https://openaccess.thecvf.com/CVPR2023#), [Chiyu “Max” Jiang](https://openaccess.thecvf.com/CVPR2023#), [Charles R. Qi](https://openaccess.thecvf.com/CVPR2023#), [Xinchen Yan](https://openaccess.thecvf.com/CVPR2023#), [Yin Zhou](https://openaccess.thecvf.com/CVPR2023#), [Leonidas Guibas](https://openaccess.thecvf.com/CVPR2023#), [Dragomir Anguelov](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Deng_NeRDi_Single-View_NeRF_Synthesis_With_Language-Guided_Diffusion_As_General_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Deng_NeRDi_Single-View_NeRF_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.03267)] 

[bibtex]


[Robust Single Image Reflection Removal Against Adversarial Attacks](https://openaccess.thecvf.com/content/CVPR2023/html/Song_Robust_Single_Image_Reflection_Removal_Against_Adversarial_Attacks_CVPR_2023_paper.html)

[Zhenbo Song](https://openaccess.thecvf.com/CVPR2023#), [Zhenyuan Zhang](https://openaccess.thecvf.com/CVPR2023#), [Kaihao Zhang](https://openaccess.thecvf.com/CVPR2023#), [Wenhan Luo](https://openaccess.thecvf.com/CVPR2023#), [Zhaoxin Fan](https://openaccess.thecvf.com/CVPR2023#), [Wenqi Ren](https://openaccess.thecvf.com/CVPR2023#), [Jianfeng Lu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Song_Robust_Single_Image_Reflection_Removal_Against_Adversarial_Attacks_CVPR_2023_paper.pdf)] 

[bibtex]


[Uncovering the Disentanglement Capability in Text-to-Image Diffusion Models](https://openaccess.thecvf.com/content/CVPR2023/html/Wu_Uncovering_the_Disentanglement_Capability_in_Text-to-Image_Diffusion_Models_CVPR_2023_paper.html)

[Qiucheng Wu](https://openaccess.thecvf.com/CVPR2023#), [Yujian Liu](https://openaccess.thecvf.com/CVPR2023#), [Handong Zhao](https://openaccess.thecvf.com/CVPR2023#), [Ajinkya Kale](https://openaccess.thecvf.com/CVPR2023#), [Trung Bui](https://openaccess.thecvf.com/CVPR2023#), [Tong Yu](https://openaccess.thecvf.com/CVPR2023#), [Zhe Lin](https://openaccess.thecvf.com/CVPR2023#), [Yang Zhang](https://openaccess.thecvf.com/CVPR2023#), [Shiyu Chang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Uncovering_the_Disentanglement_Capability_in_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wu_Uncovering_the_Disentanglement_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.08698)] 

[bibtex]


[SadTalker: Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_SadTalker_Learning_Realistic_3D_Motion_Coefficients_for_Stylized_Audio-Driven_Single_CVPR_2023_paper.html)

[Wenxuan Zhang](https://openaccess.thecvf.com/CVPR2023#), [Xiaodong Cun](https://openaccess.thecvf.com/CVPR2023#), [Xuan Wang](https://openaccess.thecvf.com/CVPR2023#), [Yong Zhang](https://openaccess.thecvf.com/CVPR2023#), [Xi Shen](https://openaccess.thecvf.com/CVPR2023#), [Yu Guo](https://openaccess.thecvf.com/CVPR2023#), [Ying Shan](https://openaccess.thecvf.com/CVPR2023#), [Fei Wang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_SadTalker_Learning_Realistic_3D_Motion_Coefficients_for_Stylized_Audio-Driven_Single_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhang_SadTalker_Learning_Realistic_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.12194)] 

[bibtex]


[HAAV: Hierarchical Aggregation of Augmented Views for Image Captioning](https://openaccess.thecvf.com/content/CVPR2023/html/Kuo_HAAV_Hierarchical_Aggregation_of_Augmented_Views_for_Image_Captioning_CVPR_2023_paper.html)

[Chia-Wen Kuo](https://openaccess.thecvf.com/CVPR2023#), [Zsolt Kira](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Kuo_HAAV_Hierarchical_Aggregation_of_Augmented_Views_for_Image_Captioning_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Kuo_HAAV_Hierarchical_Aggregation_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Learned Two-Plane Perspective Prior Based Image Resampling for Efficient Object Detection](https://openaccess.thecvf.com/content/CVPR2023/html/Ghosh_Learned_Two-Plane_Perspective_Prior_Based_Image_Resampling_for_Efficient_Object_CVPR_2023_paper.html)

[Anurag Ghosh](https://openaccess.thecvf.com/CVPR2023#), [N. Dinesh Reddy](https://openaccess.thecvf.com/CVPR2023#), [Christoph Mertz](https://openaccess.thecvf.com/CVPR2023#), [Srinivasa G. Narasimhan](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Ghosh_Learned_Two-Plane_Perspective_Prior_Based_Image_Resampling_for_Efficient_Object_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Ghosh_Learned_Two-Plane_Perspective_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.14311)] 

[bibtex]


[Multilateral Semantic Relations Modeling for Image Text Retrieval](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Multilateral_Semantic_Relations_Modeling_for_Image_Text_Retrieval_CVPR_2023_paper.html)

[Zheng Wang](https://openaccess.thecvf.com/CVPR2023#), [Zhenwei Gao](https://openaccess.thecvf.com/CVPR2023#), [Kangshuai Guo](https://openaccess.thecvf.com/CVPR2023#), [Yang Yang](https://openaccess.thecvf.com/CVPR2023#), [Xiaoming Wang](https://openaccess.thecvf.com/CVPR2023#), [Heng Tao Shen](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Multilateral_Semantic_Relations_Modeling_for_Image_Text_Retrieval_CVPR_2023_paper.pdf)] 

[bibtex]


[TruFor: Leveraging All-Round Clues for Trustworthy Image Forgery Detection and Localization](https://openaccess.thecvf.com/content/CVPR2023/html/Guillaro_TruFor_Leveraging_All-Round_Clues_for_Trustworthy_Image_Forgery_Detection_and_CVPR_2023_paper.html)

[Fabrizio Guillaro](https://openaccess.thecvf.com/CVPR2023#), [Davide Cozzolino](https://openaccess.thecvf.com/CVPR2023#), [Avneesh Sud](https://openaccess.thecvf.com/CVPR2023#), [Nicholas Dufour](https://openaccess.thecvf.com/CVPR2023#), [Luisa Verdoliva](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Guillaro_TruFor_Leveraging_All-Round_Clues_for_Trustworthy_Image_Forgery_Detection_and_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Guillaro_TruFor_Leveraging_All-Round_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.10957)] 

[bibtex]


[Learning 3D-Aware Image Synthesis With Unknown Pose Distribution](https://openaccess.thecvf.com/content/CVPR2023/html/Shi_Learning_3D-Aware_Image_Synthesis_With_Unknown_Pose_Distribution_CVPR_2023_paper.html)

[Zifan Shi](https://openaccess.thecvf.com/CVPR2023#), [Yujun Shen](https://openaccess.thecvf.com/CVPR2023#), [Yinghao Xu](https://openaccess.thecvf.com/CVPR2023#), [Sida Peng](https://openaccess.thecvf.com/CVPR2023#), [Yiyi Liao](https://openaccess.thecvf.com/CVPR2023#), [Sheng Guo](https://openaccess.thecvf.com/CVPR2023#), [Qifeng Chen](https://openaccess.thecvf.com/CVPR2023#), [Dit-Yan Yeung](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Shi_Learning_3D-Aware_Image_Synthesis_With_Unknown_Pose_Distribution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Shi_Learning_3D-Aware_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2301.07702)] 

[bibtex]


[Zero-Shot Everything Sketch-Based Image Retrieval, and in Explainable Style](https://openaccess.thecvf.com/content/CVPR2023/html/Lin_Zero-Shot_Everything_Sketch-Based_Image_Retrieval_and_in_Explainable_Style_CVPR_2023_paper.html)

[Fengyin Lin](https://openaccess.thecvf.com/CVPR2023#), [Mingkang Li](https://openaccess.thecvf.com/CVPR2023#), [Da Li](https://openaccess.thecvf.com/CVPR2023#), [Timothy Hospedales](https://openaccess.thecvf.com/CVPR2023#), [Yi-Zhe Song](https://openaccess.thecvf.com/CVPR2023#), [Yonggang Qi](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Zero-Shot_Everything_Sketch-Based_Image_Retrieval_and_in_Explainable_Style_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.14348)] 

[bibtex]


[Quality-Aware Pre-Trained Models for Blind Image Quality Assessment](https://openaccess.thecvf.com/content/CVPR2023/html/Zhao_Quality-Aware_Pre-Trained_Models_for_Blind_Image_Quality_Assessment_CVPR_2023_paper.html)

[Kai Zhao](https://openaccess.thecvf.com/CVPR2023#), [Kun Yuan](https://openaccess.thecvf.com/CVPR2023#), [Ming Sun](https://openaccess.thecvf.com/CVPR2023#), [Mading Li](https://openaccess.thecvf.com/CVPR2023#), [Xing Wen](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Quality-Aware_Pre-Trained_Models_for_Blind_Image_Quality_Assessment_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.00521)] 

[bibtex]


[Learning Steerable Function for Efficient Image Resampling](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Learning_Steerable_Function_for_Efficient_Image_Resampling_CVPR_2023_paper.html)

[Jiacheng Li](https://openaccess.thecvf.com/CVPR2023#), [Chang Chen](https://openaccess.thecvf.com/CVPR2023#), [Wei Huang](https://openaccess.thecvf.com/CVPR2023#), [Zhiqiang Lang](https://openaccess.thecvf.com/CVPR2023#), [Fenglong Song](https://openaccess.thecvf.com/CVPR2023#), [Youliang Yan](https://openaccess.thecvf.com/CVPR2023#), [Zhiwei Xiong](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Learning_Steerable_Function_for_Efficient_Image_Resampling_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_Learning_Steerable_Function_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Scaling Up GANs for Text-to-Image Synthesis](https://openaccess.thecvf.com/content/CVPR2023/html/Kang_Scaling_Up_GANs_for_Text-to-Image_Synthesis_CVPR_2023_paper.html)

[Minguk Kang](https://openaccess.thecvf.com/CVPR2023#), [Jun-Yan Zhu](https://openaccess.thecvf.com/CVPR2023#), [Richard Zhang](https://openaccess.thecvf.com/CVPR2023#), [Jaesik Park](https://openaccess.thecvf.com/CVPR2023#), [Eli Shechtman](https://openaccess.thecvf.com/CVPR2023#), [Sylvain Paris](https://openaccess.thecvf.com/CVPR2023#), [Taesung Park](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Kang_Scaling_Up_GANs_for_Text-to-Image_Synthesis_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.05511)] 

[bibtex]


[Context-Based Trit-Plane Coding for Progressive Image Compression](https://openaccess.thecvf.com/content/CVPR2023/html/Jeon_Context-Based_Trit-Plane_Coding_for_Progressive_Image_Compression_CVPR_2023_paper.html)

[Seungmin Jeon](https://openaccess.thecvf.com/CVPR2023#), [Kwang Pyo Choi](https://openaccess.thecvf.com/CVPR2023#), [Youngo Park](https://openaccess.thecvf.com/CVPR2023#), [Chang-Su Kim](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Jeon_Context-Based_Trit-Plane_Coding_for_Progressive_Image_Compression_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Jeon_Context-Based_Trit-Plane_Coding_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2303.05715)] 

[bibtex]


[PixHt-Lab: Pixel Height Based Light Effect Generation for Image Compositing](https://openaccess.thecvf.com/content/CVPR2023/html/Sheng_PixHt-Lab_Pixel_Height_Based_Light_Effect_Generation_for_Image_Compositing_CVPR_2023_paper.html)

[Yichen Sheng](https://openaccess.thecvf.com/CVPR2023#), [Jianming Zhang](https://openaccess.thecvf.com/CVPR2023#), [Julien Philip](https://openaccess.thecvf.com/CVPR2023#), [Yannick Hold-Geoffroy](https://openaccess.thecvf.com/CVPR2023#), [Xin Sun](https://openaccess.thecvf.com/CVPR2023#), [He Zhang](https://openaccess.thecvf.com/CVPR2023#), [Lu Ling](https://openaccess.thecvf.com/CVPR2023#), [Bedrich Benes](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Sheng_PixHt-Lab_Pixel_Height_Based_Light_Effect_Generation_for_Image_Compositing_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Sheng_PixHt-Lab_Pixel_Height_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Revealing the Dark Secrets of Masked Image Modeling](https://openaccess.thecvf.com/content/CVPR2023/html/Xie_Revealing_the_Dark_Secrets_of_Masked_Image_Modeling_CVPR_2023_paper.html)

[Zhenda Xie](https://openaccess.thecvf.com/CVPR2023#), [Zigang Geng](https://openaccess.thecvf.com/CVPR2023#), [Jingcheng Hu](https://openaccess.thecvf.com/CVPR2023#), [Zheng Zhang](https://openaccess.thecvf.com/CVPR2023#), [Han Hu](https://openaccess.thecvf.com/CVPR2023#), [Yue Cao](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_Revealing_the_Dark_Secrets_of_Masked_Image_Modeling_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xie_Revealing_the_Dark_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2205.13543)] 

[bibtex]


[Fine-Grained Image-Text Matching by Cross-Modal Hard Aligning Network](https://openaccess.thecvf.com/content/CVPR2023/html/Pan_Fine-Grained_Image-Text_Matching_by_Cross-Modal_Hard_Aligning_Network_CVPR_2023_paper.html)

[Zhengxin Pan](https://openaccess.thecvf.com/CVPR2023#), [Fangyu Wu](https://openaccess.thecvf.com/CVPR2023#), [Bailing Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Pan_Fine-Grained_Image-Text_Matching_by_Cross-Modal_Hard_Aligning_Network_CVPR_2023_paper.pdf)] 

[bibtex]


[Omni Aggregation Networks for Lightweight Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Omni_Aggregation_Networks_for_Lightweight_Image_Super-Resolution_CVPR_2023_paper.html)

[Hang Wang](https://openaccess.thecvf.com/CVPR2023#), [Xuanhong Chen](https://openaccess.thecvf.com/CVPR2023#), [Bingbing Ni](https://openaccess.thecvf.com/CVPR2023#), [Yutian Liu](https://openaccess.thecvf.com/CVPR2023#), [Jinfan Liu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Omni_Aggregation_Networks_for_Lightweight_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Omni_Aggregation_Networks_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.10244)] 

[bibtex]


[Correlational Image Modeling for Self-Supervised Visual Pre-Training](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Correlational_Image_Modeling_for_Self-Supervised_Visual_Pre-Training_CVPR_2023_paper.html)

[Wei Li](https://openaccess.thecvf.com/CVPR2023#), [Jiahao Xie](https://openaccess.thecvf.com/CVPR2023#), [Chen Change Loy](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Correlational_Image_Modeling_for_Self-Supervised_Visual_Pre-Training_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_Correlational_Image_Modeling_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.12670)] 

[bibtex]


[MAGE: MAsked Generative Encoder To Unify Representation Learning and Image Synthesis](https://openaccess.thecvf.com/content/CVPR2023/html/Li_MAGE_MAsked_Generative_Encoder_To_Unify_Representation_Learning_and_Image_CVPR_2023_paper.html)

[Tianhong Li](https://openaccess.thecvf.com/CVPR2023#), [Huiwen Chang](https://openaccess.thecvf.com/CVPR2023#), [Shlok Mishra](https://openaccess.thecvf.com/CVPR2023#), [Han Zhang](https://openaccess.thecvf.com/CVPR2023#), [Dina Katabi](https://openaccess.thecvf.com/CVPR2023#), [Dilip Krishnan](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_MAGE_MAsked_Generative_Encoder_To_Unify_Representation_Learning_and_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_MAGE_MAsked_Generative_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.09117)] 

[bibtex]


[PartSLIP: Low-Shot Part Segmentation for 3D Point Clouds via Pretrained Image-Language Models](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_PartSLIP_Low-Shot_Part_Segmentation_for_3D_Point_Clouds_via_Pretrained_CVPR_2023_paper.html)

[Minghua Liu](https://openaccess.thecvf.com/CVPR2023#), [Yinhao Zhu](https://openaccess.thecvf.com/CVPR2023#), [Hong Cai](https://openaccess.thecvf.com/CVPR2023#), [Shizhong Han](https://openaccess.thecvf.com/CVPR2023#), [Zhan Ling](https://openaccess.thecvf.com/CVPR2023#), [Fatih Porikli](https://openaccess.thecvf.com/CVPR2023#), [Hao Su](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_PartSLIP_Low-Shot_Part_Segmentation_for_3D_Point_Clouds_via_Pretrained_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Liu_PartSLIP_Low-Shot_Part_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.01558)] 

[bibtex]


[Structure Aggregation for Cross-Spectral Stereo Image Guided Denoising](https://openaccess.thecvf.com/content/CVPR2023/html/Sheng_Structure_Aggregation_for_Cross-Spectral_Stereo_Image_Guided_Denoising_CVPR_2023_paper.html)

[Zehua Sheng](https://openaccess.thecvf.com/CVPR2023#), [Zhu Yu](https://openaccess.thecvf.com/CVPR2023#), [Xiongwei Liu](https://openaccess.thecvf.com/CVPR2023#), [Si-Yuan Cao](https://openaccess.thecvf.com/CVPR2023#), [Yuqi Liu](https://openaccess.thecvf.com/CVPR2023#), [Hui-Liang Shen](https://openaccess.thecvf.com/CVPR2023#), [Huaqi Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Sheng_Structure_Aggregation_for_Cross-Spectral_Stereo_Image_Guided_Denoising_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Sheng_Structure_Aggregation_for_CVPR_2023_supplemental.zip)] 

[bibtex]


[Affordance Grounding From Demonstration Video To Target Image](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Affordance_Grounding_From_Demonstration_Video_To_Target_Image_CVPR_2023_paper.html)

[Joya Chen](https://openaccess.thecvf.com/CVPR2023#), [Difei Gao](https://openaccess.thecvf.com/CVPR2023#), [Kevin Qinghong Lin](https://openaccess.thecvf.com/CVPR2023#), [Mike Zheng Shou](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Affordance_Grounding_From_Demonstration_Video_To_Target_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chen_Affordance_Grounding_From_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.14644)] 

[bibtex]


[LayoutDiffusion: Controllable Diffusion Model for Layout-to-Image Generation](https://openaccess.thecvf.com/content/CVPR2023/html/Zheng_LayoutDiffusion_Controllable_Diffusion_Model_for_Layout-to-Image_Generation_CVPR_2023_paper.html)

[Guangcong Zheng](https://openaccess.thecvf.com/CVPR2023#), [Xianpan Zhou](https://openaccess.thecvf.com/CVPR2023#), [Xuewei Li](https://openaccess.thecvf.com/CVPR2023#), [Zhongang Qi](https://openaccess.thecvf.com/CVPR2023#), [Ying Shan](https://openaccess.thecvf.com/CVPR2023#), [Xi Li](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_LayoutDiffusion_Controllable_Diffusion_Model_for_Layout-to-Image_Generation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zheng_LayoutDiffusion_Controllable_Diffusion_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.17189)] 

[bibtex]


[BBDM: Image-to-Image Translation With Brownian Bridge Diffusion Models](https://openaccess.thecvf.com/content/CVPR2023/html/Li_BBDM_Image-to-Image_Translation_With_Brownian_Bridge_Diffusion_Models_CVPR_2023_paper.html)

[Bo Li](https://openaccess.thecvf.com/CVPR2023#), [Kaitao Xue](https://openaccess.thecvf.com/CVPR2023#), [Bin Liu](https://openaccess.thecvf.com/CVPR2023#), [Yu-Kun Lai](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_BBDM_Image-to-Image_Translation_With_Brownian_Bridge_Diffusion_Models_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_BBDM_Image-to-Image_Translation_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2205.07680)] 

[bibtex]


[Imagen Editor and EditBench: Advancing and Evaluating Text-Guided Image Inpainting](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Imagen_Editor_and_EditBench_Advancing_and_Evaluating_Text-Guided_Image_Inpainting_CVPR_2023_paper.html)

[Su Wang](https://openaccess.thecvf.com/CVPR2023#), [Chitwan Saharia](https://openaccess.thecvf.com/CVPR2023#), [Ceslee Montgomery](https://openaccess.thecvf.com/CVPR2023#), [Jordi Pont-Tuset](https://openaccess.thecvf.com/CVPR2023#), [Shai Noy](https://openaccess.thecvf.com/CVPR2023#), [Stefano Pellegrini](https://openaccess.thecvf.com/CVPR2023#), [Yasumasa Onoe](https://openaccess.thecvf.com/CVPR2023#), [Sarah Laszlo](https://openaccess.thecvf.com/CVPR2023#), [David J. Fleet](https://openaccess.thecvf.com/CVPR2023#), [Radu Soricut](https://openaccess.thecvf.com/CVPR2023#), [Jason Baldridge](https://openaccess.thecvf.com/CVPR2023#), [Mohammad Norouzi](https://openaccess.thecvf.com/CVPR2023#), [Peter Anderson](https://openaccess.thecvf.com/CVPR2023#), [William Chan](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Imagen_Editor_and_EditBench_Advancing_and_Evaluating_Text-Guided_Image_Inpainting_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Imagen_Editor_and_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.06909)] 

[bibtex]


[OSRT: Omnidirectional Image Super-Resolution With Distortion-Aware Transformer](https://openaccess.thecvf.com/content/CVPR2023/html/Yu_OSRT_Omnidirectional_Image_Super-Resolution_With_Distortion-Aware_Transformer_CVPR_2023_paper.html)

[Fanghua Yu](https://openaccess.thecvf.com/CVPR2023#), [Xintao Wang](https://openaccess.thecvf.com/CVPR2023#), [Mingdeng Cao](https://openaccess.thecvf.com/CVPR2023#), [Gen Li](https://openaccess.thecvf.com/CVPR2023#), [Ying Shan](https://openaccess.thecvf.com/CVPR2023#), [Chao Dong](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_OSRT_Omnidirectional_Image_Super-Resolution_With_Distortion-Aware_Transformer_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yu_OSRT_Omnidirectional_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.03453)] 

[bibtex]


[Devil Is in the Queries: Advancing Mask Transformers for Real-World Medical Image Segmentation and Out-of-Distribution Localization](https://openaccess.thecvf.com/content/CVPR2023/html/Yuan_Devil_Is_in_the_Queries_Advancing_Mask_Transformers_for_Real-World_CVPR_2023_paper.html)

[Mingze Yuan](https://openaccess.thecvf.com/CVPR2023#), [Yingda Xia](https://openaccess.thecvf.com/CVPR2023#), [Hexin Dong](https://openaccess.thecvf.com/CVPR2023#), [Zifan Chen](https://openaccess.thecvf.com/CVPR2023#), [Jiawen Yao](https://openaccess.thecvf.com/CVPR2023#), [Mingyan Qiu](https://openaccess.thecvf.com/CVPR2023#), [Ke Yan](https://openaccess.thecvf.com/CVPR2023#), [Xiaoli Yin](https://openaccess.thecvf.com/CVPR2023#), [Yu Shi](https://openaccess.thecvf.com/CVPR2023#), [Xin Chen](https://openaccess.thecvf.com/CVPR2023#), [Zaiyi Liu](https://openaccess.thecvf.com/CVPR2023#), [Bin Dong](https://openaccess.thecvf.com/CVPR2023#), [Jingren Zhou](https://openaccess.thecvf.com/CVPR2023#), [Le Lu](https://openaccess.thecvf.com/CVPR2023#), [Ling Zhang](https://openaccess.thecvf.com/CVPR2023#), [Li Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yuan_Devil_Is_in_the_Queries_Advancing_Mask_Transformers_for_Real-World_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yuan_Devil_Is_in_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.00212)] 

[bibtex]


[KD-DLGAN: Data Limited Image Generation via Knowledge Distillation](https://openaccess.thecvf.com/content/CVPR2023/html/Cui_KD-DLGAN_Data_Limited_Image_Generation_via_Knowledge_Distillation_CVPR_2023_paper.html)

[Kaiwen Cui](https://openaccess.thecvf.com/CVPR2023#), [Yingchen Yu](https://openaccess.thecvf.com/CVPR2023#), [Fangneng Zhan](https://openaccess.thecvf.com/CVPR2023#), [Shengcai Liao](https://openaccess.thecvf.com/CVPR2023#), [Shijian Lu](https://openaccess.thecvf.com/CVPR2023#), [Eric P. Xing](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Cui_KD-DLGAN_Data_Limited_Image_Generation_via_Knowledge_Distillation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Cui_KD-DLGAN_Data_Limited_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Uncertainty-Aware Unsupervised Image Deblurring With Deep Residual Prior](https://openaccess.thecvf.com/content/CVPR2023/html/Tang_Uncertainty-Aware_Unsupervised_Image_Deblurring_With_Deep_Residual_Prior_CVPR_2023_paper.html)

[Xiaole Tang](https://openaccess.thecvf.com/CVPR2023#), [Xile Zhao](https://openaccess.thecvf.com/CVPR2023#), [Jun Liu](https://openaccess.thecvf.com/CVPR2023#), [Jianli Wang](https://openaccess.thecvf.com/CVPR2023#), [Yuchun Miao](https://openaccess.thecvf.com/CVPR2023#), [Tieyong Zeng](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_Uncertainty-Aware_Unsupervised_Image_Deblurring_With_Deep_Residual_Prior_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Tang_Uncertainty-Aware_Unsupervised_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2210.05361)] 

[bibtex]


[HouseDiffusion: Vector Floorplan Generation via a Diffusion Model With Discrete and Continuous Denoising](https://openaccess.thecvf.com/content/CVPR2023/html/Shabani_HouseDiffusion_Vector_Floorplan_Generation_via_a_Diffusion_Model_With_Discrete_CVPR_2023_paper.html)

[Mohammad Amin Shabani](https://openaccess.thecvf.com/CVPR2023#), [Sepidehsadat Hosseini](https://openaccess.thecvf.com/CVPR2023#), [Yasutaka Furukawa](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Shabani_HouseDiffusion_Vector_Floorplan_Generation_via_a_Diffusion_Model_With_Discrete_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Shabani_HouseDiffusion_Vector_Floorplan_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.13287)] 

[bibtex]


[MIC: Masked Image Consistency for Context-Enhanced Domain Adaptation](https://openaccess.thecvf.com/content/CVPR2023/html/Hoyer_MIC_Masked_Image_Consistency_for_Context-Enhanced_Domain_Adaptation_CVPR_2023_paper.html)

[Lukas Hoyer](https://openaccess.thecvf.com/CVPR2023#), [Dengxin Dai](https://openaccess.thecvf.com/CVPR2023#), [Haoran Wang](https://openaccess.thecvf.com/CVPR2023#), [Luc Van Gool](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Hoyer_MIC_Masked_Image_Consistency_for_Context-Enhanced_Domain_Adaptation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Hoyer_MIC_Masked_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.01322)] 

[bibtex]


[Focused and Collaborative Feedback Integration for Interactive Image Segmentation](https://openaccess.thecvf.com/content/CVPR2023/html/Wei_Focused_and_Collaborative_Feedback_Integration_for_Interactive_Image_Segmentation_CVPR_2023_paper.html)

[Qiaoqiao Wei](https://openaccess.thecvf.com/CVPR2023#), [Hui Zhang](https://openaccess.thecvf.com/CVPR2023#), [Jun-Hai Yong](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_Focused_and_Collaborative_Feedback_Integration_for_Interactive_Image_Segmentation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wei_Focused_and_Collaborative_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.11880)] 

[bibtex]


[SmallCap: Lightweight Image Captioning Prompted With Retrieval Augmentation](https://openaccess.thecvf.com/content/CVPR2023/html/Ramos_SmallCap_Lightweight_Image_Captioning_Prompted_With_Retrieval_Augmentation_CVPR_2023_paper.html)

[Rita Ramos](https://openaccess.thecvf.com/CVPR2023#), [Bruno Martins](https://openaccess.thecvf.com/CVPR2023#), [Desmond Elliott](https://openaccess.thecvf.com/CVPR2023#), [Yova Kementchedjhieva](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Ramos_SmallCap_Lightweight_Image_Captioning_Prompted_With_Retrieval_Augmentation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Ramos_SmallCap_Lightweight_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2209.15323)] 

[bibtex]


[Where We Are and What We're Looking At: Query Based Worldwide Image Geo-Localization Using Hierarchies and Scenes](https://openaccess.thecvf.com/content/CVPR2023/html/Clark_Where_We_Are_and_What_Were_Looking_At_Query_Based_CVPR_2023_paper.html)

[Brandon Clark](https://openaccess.thecvf.com/CVPR2023#), [Alec Kerrigan](https://openaccess.thecvf.com/CVPR2023#), [Parth Parag Kulkarni](https://openaccess.thecvf.com/CVPR2023#), [Vicente Vivanco Cepeda](https://openaccess.thecvf.com/CVPR2023#), [Mubarak Shah](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Clark_Where_We_Are_and_What_Were_Looking_At_Query_Based_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Clark_Where_We_Are_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Human Guided Ground-Truth Generation for Realistic Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Human_Guided_Ground-Truth_Generation_for_Realistic_Image_Super-Resolution_CVPR_2023_paper.html)

[Du Chen](https://openaccess.thecvf.com/CVPR2023#), [Jie Liang](https://openaccess.thecvf.com/CVPR2023#), [Xindong Zhang](https://openaccess.thecvf.com/CVPR2023#), [Ming Liu](https://openaccess.thecvf.com/CVPR2023#), [Hui Zeng](https://openaccess.thecvf.com/CVPR2023#), [Lei Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Human_Guided_Ground-Truth_Generation_for_Realistic_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chen_Human_Guided_Ground-Truth_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.13069)] 

[bibtex]


[RenderDiffusion: Image Diffusion for 3D Reconstruction, Inpainting and Generation](https://openaccess.thecvf.com/content/CVPR2023/html/Anciukevicius_RenderDiffusion_Image_Diffusion_for_3D_Reconstruction_Inpainting_and_Generation_CVPR_2023_paper.html)

[Titas Anciukevičius](https://openaccess.thecvf.com/CVPR2023#), [Zexiang Xu](https://openaccess.thecvf.com/CVPR2023#), [Matthew Fisher](https://openaccess.thecvf.com/CVPR2023#), [Paul Henderson](https://openaccess.thecvf.com/CVPR2023#), [Hakan Bilen](https://openaccess.thecvf.com/CVPR2023#), [Niloy J. Mitra](https://openaccess.thecvf.com/CVPR2023#), [Paul Guerrero](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Anciukevicius_RenderDiffusion_Image_Diffusion_for_3D_Reconstruction_Inpainting_and_Generation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Anciukevicius_RenderDiffusion_Image_Diffusion_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Learning Generative Structure Prior for Blind Text Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Learning_Generative_Structure_Prior_for_Blind_Text_Image_Super-Resolution_CVPR_2023_paper.html)

[Xiaoming Li](https://openaccess.thecvf.com/CVPR2023#), [Wangmeng Zuo](https://openaccess.thecvf.com/CVPR2023#), [Chen Change Loy](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Learning_Generative_Structure_Prior_for_Blind_Text_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_Learning_Generative_Structure_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.14726)] 

[bibtex]


[PEFAT: Boosting Semi-Supervised Medical Image Classification via Pseudo-Loss Estimation and Feature Adversarial Training](https://openaccess.thecvf.com/content/CVPR2023/html/Zeng_PEFAT_Boosting_Semi-Supervised_Medical_Image_Classification_via_Pseudo-Loss_Estimation_and_CVPR_2023_paper.html)

[Qingjie Zeng](https://openaccess.thecvf.com/CVPR2023#), [Yutong Xie](https://openaccess.thecvf.com/CVPR2023#), [Zilin Lu](https://openaccess.thecvf.com/CVPR2023#), [Yong Xia](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zeng_PEFAT_Boosting_Semi-Supervised_Medical_Image_Classification_via_Pseudo-Loss_Estimation_and_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zeng_PEFAT_Boosting_Semi-Supervised_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Masked Image Modeling With Local Multi-Scale Reconstruction](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Masked_Image_Modeling_With_Local_Multi-Scale_Reconstruction_CVPR_2023_paper.html)

[Haoqing Wang](https://openaccess.thecvf.com/CVPR2023#), [Yehui Tang](https://openaccess.thecvf.com/CVPR2023#), [Yunhe Wang](https://openaccess.thecvf.com/CVPR2023#), [Jianyuan Guo](https://openaccess.thecvf.com/CVPR2023#), [Zhi-Hong Deng](https://openaccess.thecvf.com/CVPR2023#), [Kai Han](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Masked_Image_Modeling_With_Local_Multi-Scale_Reconstruction_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Masked_Image_Modeling_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.05251)] 

[bibtex]


[Explaining Image Classifiers With Multiscale Directional Image Representation](https://openaccess.thecvf.com/content/CVPR2023/html/Kolek_Explaining_Image_Classifiers_With_Multiscale_Directional_Image_Representation_CVPR_2023_paper.html)

[Stefan Kolek](https://openaccess.thecvf.com/CVPR2023#), [Robert Windesheim](https://openaccess.thecvf.com/CVPR2023#), [Hector Andrade-Loarca](https://openaccess.thecvf.com/CVPR2023#), [Gitta Kutyniok](https://openaccess.thecvf.com/CVPR2023#), [Ron Levie](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Kolek_Explaining_Image_Classifiers_With_Multiscale_Directional_Image_Representation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Kolek_Explaining_Image_Classifiers_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Parallel Diffusion Models of Operator and Image for Blind Inverse Problems](https://openaccess.thecvf.com/content/CVPR2023/html/Chung_Parallel_Diffusion_Models_of_Operator_and_Image_for_Blind_Inverse_CVPR_2023_paper.html)

[Hyungjin Chung](https://openaccess.thecvf.com/CVPR2023#), [Jeongsol Kim](https://openaccess.thecvf.com/CVPR2023#), [Sehui Kim](https://openaccess.thecvf.com/CVPR2023#), [Jong Chul Ye](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chung_Parallel_Diffusion_Models_of_Operator_and_Image_for_Blind_Inverse_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chung_Parallel_Diffusion_Models_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.10656)] 

[bibtex]


[RealFusion: 360deg Reconstruction of Any Object From a Single Image](https://openaccess.thecvf.com/content/CVPR2023/html/Melas-Kyriazi_RealFusion_360deg_Reconstruction_of_Any_Object_From_a_Single_Image_CVPR_2023_paper.html)

[Luke Melas-Kyriazi](https://openaccess.thecvf.com/CVPR2023#), [Iro Laina](https://openaccess.thecvf.com/CVPR2023#), [Christian Rupprecht](https://openaccess.thecvf.com/CVPR2023#), [Andrea Vedaldi](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Melas-Kyriazi_RealFusion_360deg_Reconstruction_of_Any_Object_From_a_Single_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Melas-Kyriazi_RealFusion_360deg_Reconstruction_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Soft Augmentation for Image Classification](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Soft_Augmentation_for_Image_Classification_CVPR_2023_paper.html)

[Yang Liu](https://openaccess.thecvf.com/CVPR2023#), [Shen Yan](https://openaccess.thecvf.com/CVPR2023#), [Laura Leal-Taixé](https://openaccess.thecvf.com/CVPR2023#), [James Hays](https://openaccess.thecvf.com/CVPR2023#), [Deva Ramanan](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Soft_Augmentation_for_Image_Classification_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Liu_Soft_Augmentation_for_CVPR_2023_supplemental.pdf)] 

[bibtex]


[PREIM3D: 3D Consistent Precise Image Attribute Editing From a Single Image](https://openaccess.thecvf.com/content/CVPR2023/html/Li_PREIM3D_3D_Consistent_Precise_Image_Attribute_Editing_From_a_Single_CVPR_2023_paper.html)

[Jianhui Li](https://openaccess.thecvf.com/CVPR2023#), [Jianmin Li](https://openaccess.thecvf.com/CVPR2023#), [Haoji Zhang](https://openaccess.thecvf.com/CVPR2023#), [Shilong Liu](https://openaccess.thecvf.com/CVPR2023#), [Zhengyi Wang](https://openaccess.thecvf.com/CVPR2023#), [Zihao Xiao](https://openaccess.thecvf.com/CVPR2023#), [Kaiwen Zheng](https://openaccess.thecvf.com/CVPR2023#), [Jun Zhu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_PREIM3D_3D_Consistent_Precise_Image_Attribute_Editing_From_a_Single_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_PREIM3D_3D_Consistent_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2304.10263)] 

[bibtex]


[MaskSketch: Unpaired Structure-Guided Masked Image Generation](https://openaccess.thecvf.com/content/CVPR2023/html/Bashkirova_MaskSketch_Unpaired_Structure-Guided_Masked_Image_Generation_CVPR_2023_paper.html)

[Dina Bashkirova](https://openaccess.thecvf.com/CVPR2023#), [José Lezama](https://openaccess.thecvf.com/CVPR2023#), [Kihyuk Sohn](https://openaccess.thecvf.com/CVPR2023#), [Kate Saenko](https://openaccess.thecvf.com/CVPR2023#), [Irfan Essa](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Bashkirova_MaskSketch_Unpaired_Structure-Guided_Masked_Image_Generation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Bashkirova_MaskSketch_Unpaired_Structure-Guided_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.05496)] 

[bibtex]


[MeMaHand: Exploiting Mesh-Mano Interaction for Single Image Two-Hand Reconstruction](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_MeMaHand_Exploiting_Mesh-Mano_Interaction_for_Single_Image_Two-Hand_Reconstruction_CVPR_2023_paper.html)

[Congyi Wang](https://openaccess.thecvf.com/CVPR2023#), [Feida Zhu](https://openaccess.thecvf.com/CVPR2023#), [Shilei Wen](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_MeMaHand_Exploiting_Mesh-Mano_Interaction_for_Single_Image_Two-Hand_Reconstruction_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_MeMaHand_Exploiting_Mesh-Mano_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.15718)] 

[bibtex]


[Asymmetric Feature Fusion for Image Retrieval](https://openaccess.thecvf.com/content/CVPR2023/html/Wu_Asymmetric_Feature_Fusion_for_Image_Retrieval_CVPR_2023_paper.html)

[Hui Wu](https://openaccess.thecvf.com/CVPR2023#), [Min Wang](https://openaccess.thecvf.com/CVPR2023#), [Wengang Zhou](https://openaccess.thecvf.com/CVPR2023#), [Zhenbo Lu](https://openaccess.thecvf.com/CVPR2023#), [Houqiang Li](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Asymmetric_Feature_Fusion_for_Image_Retrieval_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wu_Asymmetric_Feature_Fusion_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Image as a Foreign Language: BEiT Pretraining for Vision and Vision-Language Tasks](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Image_as_a_Foreign_Language_BEiT_Pretraining_for_Vision_and_CVPR_2023_paper.html)

[Wenhui Wang](https://openaccess.thecvf.com/CVPR2023#), [Hangbo Bao](https://openaccess.thecvf.com/CVPR2023#), [Li Dong](https://openaccess.thecvf.com/CVPR2023#), [Johan Bjorck](https://openaccess.thecvf.com/CVPR2023#), [Zhiliang Peng](https://openaccess.thecvf.com/CVPR2023#), [Qiang Liu](https://openaccess.thecvf.com/CVPR2023#), [Kriti Aggarwal](https://openaccess.thecvf.com/CVPR2023#), [Owais Khan Mohammed](https://openaccess.thecvf.com/CVPR2023#), [Saksham Singhal](https://openaccess.thecvf.com/CVPR2023#), [Subhojit Som](https://openaccess.thecvf.com/CVPR2023#), [Furu Wei](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Image_as_a_Foreign_Language_BEiT_Pretraining_for_Vision_and_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Image_as_a_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Context-Aware Pretraining for Efficient Blind Image Decomposition](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Context-Aware_Pretraining_for_Efficient_Blind_Image_Decomposition_CVPR_2023_paper.html)

[Chao Wang](https://openaccess.thecvf.com/CVPR2023#), [Zhedong Zheng](https://openaccess.thecvf.com/CVPR2023#), [Ruijie Quan](https://openaccess.thecvf.com/CVPR2023#), [Yifan Sun](https://openaccess.thecvf.com/CVPR2023#), [Yi Yang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Context-Aware_Pretraining_for_Efficient_Blind_Image_Decomposition_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Context-Aware_Pretraining_for_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Shifted Diffusion for Text-to-Image Generation](https://openaccess.thecvf.com/content/CVPR2023/html/Zhou_Shifted_Diffusion_for_Text-to-Image_Generation_CVPR_2023_paper.html)

[Yufan Zhou](https://openaccess.thecvf.com/CVPR2023#), [Bingchen Liu](https://openaccess.thecvf.com/CVPR2023#), [Yizhe Zhu](https://openaccess.thecvf.com/CVPR2023#), [Xiao Yang](https://openaccess.thecvf.com/CVPR2023#), [Changyou Chen](https://openaccess.thecvf.com/CVPR2023#), [Jinhui Xu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Shifted_Diffusion_for_Text-to-Image_Generation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhou_Shifted_Diffusion_for_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.15388)] 

[bibtex]


[Robust Unsupervised StyleGAN Image Restoration](https://openaccess.thecvf.com/content/CVPR2023/html/Poirier-Ginter_Robust_Unsupervised_StyleGAN_Image_Restoration_CVPR_2023_paper.html)

[Yohan Poirier-Ginter](https://openaccess.thecvf.com/CVPR2023#), [Jean-François Lalonde](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Poirier-Ginter_Robust_Unsupervised_StyleGAN_Image_Restoration_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2302.06733)] 

[bibtex]


[Efficient and Explicit Modelling of Image Hierarchies for Image Restoration](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Efficient_and_Explicit_Modelling_of_Image_Hierarchies_for_Image_Restoration_CVPR_2023_paper.html)

[Yawei Li](https://openaccess.thecvf.com/CVPR2023#), [Yuchen Fan](https://openaccess.thecvf.com/CVPR2023#), [Xiaoyu Xiang](https://openaccess.thecvf.com/CVPR2023#), [Denis Demandolx](https://openaccess.thecvf.com/CVPR2023#), [Rakesh Ranjan](https://openaccess.thecvf.com/CVPR2023#), [Radu Timofte](https://openaccess.thecvf.com/CVPR2023#), [Luc Van Gool](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Efficient_and_Explicit_Modelling_of_Image_Hierarchies_for_Image_Restoration_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.00748)] 

[bibtex]


[OPE-SR: Orthogonal Position Encoding for Designing a Parameter-Free Upsampling Module in Arbitrary-Scale Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Song_OPE-SR_Orthogonal_Position_Encoding_for_Designing_a_Parameter-Free_Upsampling_Module_CVPR_2023_paper.html)

[Gaochao Song](https://openaccess.thecvf.com/CVPR2023#), [Qian Sun](https://openaccess.thecvf.com/CVPR2023#), [Luo Zhang](https://openaccess.thecvf.com/CVPR2023#), [Ran Su](https://openaccess.thecvf.com/CVPR2023#), [Jianfeng Shi](https://openaccess.thecvf.com/CVPR2023#), [Ying He](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Song_OPE-SR_Orthogonal_Position_Encoding_for_Designing_a_Parameter-Free_Upsampling_Module_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Song_OPE-SR_Orthogonal_Position_CVPR_2023_supplemental.pdf)] 

[bibtex]


[I2MVFormer: Large Language Model Generated Multi-View Document Supervision for Zero-Shot Image Classification](https://openaccess.thecvf.com/content/CVPR2023/html/Naeem_I2MVFormer_Large_Language_Model_Generated_Multi-View_Document_Supervision_for_Zero-Shot_CVPR_2023_paper.html)

[Muhammad Ferjad Naeem](https://openaccess.thecvf.com/CVPR2023#), [Muhammad Gul Zain Ali Khan](https://openaccess.thecvf.com/CVPR2023#), [Yongqin Xian](https://openaccess.thecvf.com/CVPR2023#), [Muhammad Zeshan Afzal](https://openaccess.thecvf.com/CVPR2023#), [Didier Stricker](https://openaccess.thecvf.com/CVPR2023#), [Luc Van Gool](https://openaccess.thecvf.com/CVPR2023#), [Federico Tombari](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Naeem_I2MVFormer_Large_Language_Model_Generated_Multi-View_Document_Supervision_for_Zero-Shot_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Naeem_I2MVFormer_Large_Language_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.02291)] 

[bibtex]


[Generalized Decoding for Pixel, Image, and Language](https://openaccess.thecvf.com/content/CVPR2023/html/Zou_Generalized_Decoding_for_Pixel_Image_and_Language_CVPR_2023_paper.html)

[Xueyan Zou](https://openaccess.thecvf.com/CVPR2023#), [Zi-Yi Dou](https://openaccess.thecvf.com/CVPR2023#), [Jianwei Yang](https://openaccess.thecvf.com/CVPR2023#), [Zhe Gan](https://openaccess.thecvf.com/CVPR2023#), [Linjie Li](https://openaccess.thecvf.com/CVPR2023#), [Chunyuan Li](https://openaccess.thecvf.com/CVPR2023#), [Xiyang Dai](https://openaccess.thecvf.com/CVPR2023#), [Harkirat Behl](https://openaccess.thecvf.com/CVPR2023#), [Jianfeng Wang](https://openaccess.thecvf.com/CVPR2023#), [Lu Yuan](https://openaccess.thecvf.com/CVPR2023#), [Nanyun Peng](https://openaccess.thecvf.com/CVPR2023#), [Lijuan Wang](https://openaccess.thecvf.com/CVPR2023#), [Yong Jae Lee](https://openaccess.thecvf.com/CVPR2023#), [Jianfeng Gao](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zou_Generalized_Decoding_for_Pixel_Image_and_Language_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zou_Generalized_Decoding_for_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.11270)] 

[bibtex]


[SpaText: Spatio-Textual Representation for Controllable Image Generation](https://openaccess.thecvf.com/content/CVPR2023/html/Avrahami_SpaText_Spatio-Textual_Representation_for_Controllable_Image_Generation_CVPR_2023_paper.html)

[Omri Avrahami](https://openaccess.thecvf.com/CVPR2023#), [Thomas Hayes](https://openaccess.thecvf.com/CVPR2023#), [Oran Gafni](https://openaccess.thecvf.com/CVPR2023#), [Sonal Gupta](https://openaccess.thecvf.com/CVPR2023#), [Yaniv Taigman](https://openaccess.thecvf.com/CVPR2023#), [Devi Parikh](https://openaccess.thecvf.com/CVPR2023#), [Dani Lischinski](https://openaccess.thecvf.com/CVPR2023#), [Ohad Fried](https://openaccess.thecvf.com/CVPR2023#), [Xi Yin](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Avrahami_SpaText_Spatio-Textual_Representation_for_Controllable_Image_Generation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Avrahami_SpaText_Spatio-Textual_Representation_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.14305)] 

[bibtex]


[PCT-Net: Full Resolution Image Harmonization Using Pixel-Wise Color Transformations](https://openaccess.thecvf.com/content/CVPR2023/html/Guerreiro_PCT-Net_Full_Resolution_Image_Harmonization_Using_Pixel-Wise_Color_Transformations_CVPR_2023_paper.html)

[Julian Jorge Andrade Guerreiro](https://openaccess.thecvf.com/CVPR2023#), [Mitsuru Nakazawa](https://openaccess.thecvf.com/CVPR2023#), [Björn Stenger](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Guerreiro_PCT-Net_Full_Resolution_Image_Harmonization_Using_Pixel-Wise_Color_Transformations_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Guerreiro_PCT-Net_Full_Resolution_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Leveraging per Image-Token Consistency for Vision-Language Pre-Training](https://openaccess.thecvf.com/content/CVPR2023/html/Gou_Leveraging_per_Image-Token_Consistency_for_Vision-Language_Pre-Training_CVPR_2023_paper.html)

[Yunhao Gou](https://openaccess.thecvf.com/CVPR2023#), [Tom Ko](https://openaccess.thecvf.com/CVPR2023#), [Hansi Yang](https://openaccess.thecvf.com/CVPR2023#), [James Kwok](https://openaccess.thecvf.com/CVPR2023#), [Yu Zhang](https://openaccess.thecvf.com/CVPR2023#), [Mingxuan Wang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Gou_Leveraging_per_Image-Token_Consistency_for_Vision-Language_Pre-Training_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Gou_Leveraging_per_Image-Token_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.15398)] 

[bibtex]


[Equivalent Transformation and Dual Stream Network Construction for Mobile Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Chao_Equivalent_Transformation_and_Dual_Stream_Network_Construction_for_Mobile_Image_CVPR_2023_paper.html)

[Jiahao Chao](https://openaccess.thecvf.com/CVPR2023#), [Zhou Zhou](https://openaccess.thecvf.com/CVPR2023#), [Hongfan Gao](https://openaccess.thecvf.com/CVPR2023#), [Jiali Gong](https://openaccess.thecvf.com/CVPR2023#), [Zhengfeng Yang](https://openaccess.thecvf.com/CVPR2023#), [Zhenbing Zeng](https://openaccess.thecvf.com/CVPR2023#), [Lydia Dehbi](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chao_Equivalent_Transformation_and_Dual_Stream_Network_Construction_for_Mobile_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chao_Equivalent_Transformation_and_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Gaussian Label Distribution Learning for Spherical Image Object Detection](https://openaccess.thecvf.com/content/CVPR2023/html/Xu_Gaussian_Label_Distribution_Learning_for_Spherical_Image_Object_Detection_CVPR_2023_paper.html)

[Hang Xu](https://openaccess.thecvf.com/CVPR2023#), [Xinyuan Liu](https://openaccess.thecvf.com/CVPR2023#), [Qiang Zhao](https://openaccess.thecvf.com/CVPR2023#), [Yike Ma](https://openaccess.thecvf.com/CVPR2023#), [Chenggang Yan](https://openaccess.thecvf.com/CVPR2023#), [Feng Dai](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Gaussian_Label_Distribution_Learning_for_Spherical_Image_Object_Detection_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xu_Gaussian_Label_Distribution_CVPR_2023_supplemental.pdf)] 

[bibtex]


[High-Resolution Image Reconstruction With Latent Diffusion Models From Human Brain Activity](https://openaccess.thecvf.com/content/CVPR2023/html/Takagi_High-Resolution_Image_Reconstruction_With_Latent_Diffusion_Models_From_Human_Brain_CVPR_2023_paper.html)

[Yu Takagi](https://openaccess.thecvf.com/CVPR2023#), [Shinji Nishimoto](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Takagi_High-Resolution_Image_Reconstruction_With_Latent_Diffusion_Models_From_Human_Brain_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Takagi_High-Resolution_Image_Reconstruction_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Activating More Pixels in Image Super-Resolution Transformer](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Activating_More_Pixels_in_Image_Super-Resolution_Transformer_CVPR_2023_paper.html)

[Xiangyu Chen](https://openaccess.thecvf.com/CVPR2023#), [Xintao Wang](https://openaccess.thecvf.com/CVPR2023#), [Jiantao Zhou](https://openaccess.thecvf.com/CVPR2023#), [Yu Qiao](https://openaccess.thecvf.com/CVPR2023#), [Chao Dong](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Activating_More_Pixels_in_Image_Super-Resolution_Transformer_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chen_Activating_More_Pixels_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2205.04437)] 

[bibtex]


[Better "CMOS" Produces Clearer Images: Learning Space-Variant Blur Estimation for Blind Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Better_CMOS_Produces_Clearer_Images_Learning_Space-Variant_Blur_Estimation_for_CVPR_2023_paper.html)

[Xuhai Chen](https://openaccess.thecvf.com/CVPR2023#), [Jiangning Zhang](https://openaccess.thecvf.com/CVPR2023#), [Chao Xu](https://openaccess.thecvf.com/CVPR2023#), [Yabiao Wang](https://openaccess.thecvf.com/CVPR2023#), [Chengjie Wang](https://openaccess.thecvf.com/CVPR2023#), [Yong Liu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Better_CMOS_Produces_Clearer_Images_Learning_Space-Variant_Blur_Estimation_for_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chen_Better_CMOS_Produces_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.03542)] 

[bibtex]


[Bidirectional Copy-Paste for Semi-Supervised Medical Image Segmentation](https://openaccess.thecvf.com/content/CVPR2023/html/Bai_Bidirectional_Copy-Paste_for_Semi-Supervised_Medical_Image_Segmentation_CVPR_2023_paper.html)

[Yunhao Bai](https://openaccess.thecvf.com/CVPR2023#), [Duowen Chen](https://openaccess.thecvf.com/CVPR2023#), [Qingli Li](https://openaccess.thecvf.com/CVPR2023#), [Wei Shen](https://openaccess.thecvf.com/CVPR2023#), [Yan Wang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Bai_Bidirectional_Copy-Paste_for_Semi-Supervised_Medical_Image_Segmentation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Bai_Bidirectional_Copy-Paste_for_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2305.00673)] 

[bibtex]


[Deep Depth Estimation From Thermal Image](https://openaccess.thecvf.com/content/CVPR2023/html/Shin_Deep_Depth_Estimation_From_Thermal_Image_CVPR_2023_paper.html)

[Ukcheol Shin](https://openaccess.thecvf.com/CVPR2023#), [Jinsun Park](https://openaccess.thecvf.com/CVPR2023#), [In So Kweon](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Shin_Deep_Depth_Estimation_From_Thermal_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Shin_Deep_Depth_Estimation_CVPR_2023_supplemental.pdf)] 

[bibtex]


[SINE: SINgle Image Editing With Text-to-Image Diffusion Models](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_SINE_SINgle_Image_Editing_With_Text-to-Image_Diffusion_Models_CVPR_2023_paper.html)

[Zhixing Zhang](https://openaccess.thecvf.com/CVPR2023#), [Ligong Han](https://openaccess.thecvf.com/CVPR2023#), [Arnab Ghosh](https://openaccess.thecvf.com/CVPR2023#), [Dimitris N. Metaxas](https://openaccess.thecvf.com/CVPR2023#), [Jian Ren](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_SINE_SINgle_Image_Editing_With_Text-to-Image_Diffusion_Models_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhang_SINE_SINgle_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.04489)] 

[bibtex]


[Depth Estimation From Camera Image and mmWave Radar Point Cloud](https://openaccess.thecvf.com/content/CVPR2023/html/Singh_Depth_Estimation_From_Camera_Image_and_mmWave_Radar_Point_Cloud_CVPR_2023_paper.html)

[Akash Deep Singh](https://openaccess.thecvf.com/CVPR2023#), [Yunhao Ba](https://openaccess.thecvf.com/CVPR2023#), [Ankur Sarker](https://openaccess.thecvf.com/CVPR2023#), [Howard Zhang](https://openaccess.thecvf.com/CVPR2023#), [Achuta Kadambi](https://openaccess.thecvf.com/CVPR2023#), [Stefano Soatto](https://openaccess.thecvf.com/CVPR2023#), [Mani Srivastava](https://openaccess.thecvf.com/CVPR2023#), [Alex Wong](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Singh_Depth_Estimation_From_Camera_Image_and_mmWave_Radar_Point_Cloud_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Singh_Depth_Estimation_From_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Ultrahigh Resolution Image/Video Matting With Spatio-Temporal Sparsity](https://openaccess.thecvf.com/content/CVPR2023/html/Sun_Ultrahigh_Resolution_ImageVideo_Matting_With_Spatio-Temporal_Sparsity_CVPR_2023_paper.html)

[Yanan Sun](https://openaccess.thecvf.com/CVPR2023#), [Chi-Keung Tang](https://openaccess.thecvf.com/CVPR2023#), [Yu-Wing Tai](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Ultrahigh_Resolution_ImageVideo_Matting_With_Spatio-Temporal_Sparsity_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Sun_Ultrahigh_Resolution_ImageVideo_CVPR_2023_supplemental.zip)] 

[bibtex]


[Zero-Shot Noise2Noise: Efficient Image Denoising Without Any Data](https://openaccess.thecvf.com/content/CVPR2023/html/Mansour_Zero-Shot_Noise2Noise_Efficient_Image_Denoising_Without_Any_Data_CVPR_2023_paper.html)

[Youssef Mansour](https://openaccess.thecvf.com/CVPR2023#), [Reinhard Heckel](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Mansour_Zero-Shot_Noise2Noise_Efficient_Image_Denoising_Without_Any_Data_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Mansour_Zero-Shot_Noise2Noise_Efficient_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.11253)] 

[bibtex]


[Learning To Generate Text-Grounded Mask for Open-World Semantic Segmentation From Only Image-Text Pairs](https://openaccess.thecvf.com/content/CVPR2023/html/Cha_Learning_To_Generate_Text-Grounded_Mask_for_Open-World_Semantic_Segmentation_From_CVPR_2023_paper.html)

[Junbum Cha](https://openaccess.thecvf.com/CVPR2023#), [Jonghwan Mun](https://openaccess.thecvf.com/CVPR2023#), [Byungseok Roh](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Cha_Learning_To_Generate_Text-Grounded_Mask_for_Open-World_Semantic_Segmentation_From_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Cha_Learning_To_Generate_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.00785)] 

[bibtex]


[DreamBooth: Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation](https://openaccess.thecvf.com/content/CVPR2023/html/Ruiz_DreamBooth_Fine_Tuning_Text-to-Image_Diffusion_Models_for_Subject-Driven_Generation_CVPR_2023_paper.html)

[Nataniel Ruiz](https://openaccess.thecvf.com/CVPR2023#), [Yuanzhen Li](https://openaccess.thecvf.com/CVPR2023#), [Varun Jampani](https://openaccess.thecvf.com/CVPR2023#), [Yael Pritch](https://openaccess.thecvf.com/CVPR2023#), [Michael Rubinstein](https://openaccess.thecvf.com/CVPR2023#), [Kfir Aberman](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Ruiz_DreamBooth_Fine_Tuning_Text-to-Image_Diffusion_Models_for_Subject-Driven_Generation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Ruiz_DreamBooth_Fine_Tuning_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2208.12242)] 

[bibtex]


[MaskCLIP: Masked Self-Distillation Advances Contrastive Language-Image Pretraining](https://openaccess.thecvf.com/content/CVPR2023/html/Dong_MaskCLIP_Masked_Self-Distillation_Advances_Contrastive_Language-Image_Pretraining_CVPR_2023_paper.html)

[Xiaoyi Dong](https://openaccess.thecvf.com/CVPR2023#), [Jianmin Bao](https://openaccess.thecvf.com/CVPR2023#), [Yinglin Zheng](https://openaccess.thecvf.com/CVPR2023#), [Ting Zhang](https://openaccess.thecvf.com/CVPR2023#), [Dongdong Chen](https://openaccess.thecvf.com/CVPR2023#), [Hao Yang](https://openaccess.thecvf.com/CVPR2023#), [Ming Zeng](https://openaccess.thecvf.com/CVPR2023#), [Weiming Zhang](https://openaccess.thecvf.com/CVPR2023#), [Lu Yuan](https://openaccess.thecvf.com/CVPR2023#), [Dong Chen](https://openaccess.thecvf.com/CVPR2023#), [Fang Wen](https://openaccess.thecvf.com/CVPR2023#), [Nenghai Yu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Dong_MaskCLIP_Masked_Self-Distillation_Advances_Contrastive_Language-Image_Pretraining_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Dong_MaskCLIP_Masked_Self-Distillation_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2208.12262)] 

[bibtex]


[Inferring and Leveraging Parts From Object Shape for Improving Semantic Image Synthesis](https://openaccess.thecvf.com/content/CVPR2023/html/Wei_Inferring_and_Leveraging_Parts_From_Object_Shape_for_Improving_Semantic_CVPR_2023_paper.html)

[Yuxiang Wei](https://openaccess.thecvf.com/CVPR2023#), [Zhilong Ji](https://openaccess.thecvf.com/CVPR2023#), [Xiaohe Wu](https://openaccess.thecvf.com/CVPR2023#), [Jinfeng Bai](https://openaccess.thecvf.com/CVPR2023#), [Lei Zhang](https://openaccess.thecvf.com/CVPR2023#), [Wangmeng Zuo](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_Inferring_and_Leveraging_Parts_From_Object_Shape_for_Improving_Semantic_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wei_Inferring_and_Leveraging_CVPR_2023_supplemental.pdf)] 

[bibtex]


[RIDCP: Revitalizing Real Image Dehazing via High-Quality Codebook Priors](https://openaccess.thecvf.com/content/CVPR2023/html/Wu_RIDCP_Revitalizing_Real_Image_Dehazing_via_High-Quality_Codebook_Priors_CVPR_2023_paper.html)

[Rui-Qi Wu](https://openaccess.thecvf.com/CVPR2023#), [Zheng-Peng Duan](https://openaccess.thecvf.com/CVPR2023#), [Chun-Le Guo](https://openaccess.thecvf.com/CVPR2023#), [Zhi Chai](https://openaccess.thecvf.com/CVPR2023#), [Chongyi Li](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_RIDCP_Revitalizing_Real_Image_Dehazing_via_High-Quality_Codebook_Priors_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wu_RIDCP_Revitalizing_Real_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.03994)] 

[bibtex]


[Backdoor Attacks Against Deep Image Compression via Adaptive Frequency Trigger](https://openaccess.thecvf.com/content/CVPR2023/html/Tan_Backdoor_Attacks_Against_Deep_Image_Compression_via_Adaptive_Frequency_Trigger_CVPR_2023_paper.html)

[Yi Yu](https://openaccess.thecvf.com/CVPR2023#), [Yufei Wang](https://openaccess.thecvf.com/CVPR2023#), [Wenhan Yang](https://openaccess.thecvf.com/CVPR2023#), [Shijian Lu](https://openaccess.thecvf.com/CVPR2023#), [Yap-Peng Tan](https://openaccess.thecvf.com/CVPR2023#), [Alex C. Kot](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Tan_Backdoor_Attacks_Against_Deep_Image_Compression_via_Adaptive_Frequency_Trigger_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Tan_Backdoor_Attacks_Against_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2302.14677)] 

[bibtex]


[A Probabilistic Attention Model With Occlusion-Aware Texture Regression for 3D Hand Reconstruction From a Single RGB Image](https://openaccess.thecvf.com/content/CVPR2023/html/Jiang_A_Probabilistic_Attention_Model_With_Occlusion-Aware_Texture_Regression_for_3D_CVPR_2023_paper.html)

[Zheheng Jiang](https://openaccess.thecvf.com/CVPR2023#), [Hossein Rahmani](https://openaccess.thecvf.com/CVPR2023#), [Sue Black](https://openaccess.thecvf.com/CVPR2023#), [Bryan M. Williams](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_A_Probabilistic_Attention_Model_With_Occlusion-Aware_Texture_Regression_for_3D_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Jiang_A_Probabilistic_Attention_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.14299)] 

[bibtex]


[Ambiguous Medical Image Segmentation Using Diffusion Models](https://openaccess.thecvf.com/content/CVPR2023/html/Rahman_Ambiguous_Medical_Image_Segmentation_Using_Diffusion_Models_CVPR_2023_paper.html)

[Aimon Rahman](https://openaccess.thecvf.com/CVPR2023#), [Jeya Maria Jose Valanarasu](https://openaccess.thecvf.com/CVPR2023#), [Ilker Hacihaliloglu](https://openaccess.thecvf.com/CVPR2023#), [Vishal M. Patel](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Rahman_Ambiguous_Medical_Image_Segmentation_Using_Diffusion_Models_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Rahman_Ambiguous_Medical_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.04745)] 

[bibtex]


[Joint HDR Denoising and Fusion: A Real-World Mobile HDR Image Dataset](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Joint_HDR_Denoising_and_Fusion_A_Real-World_Mobile_HDR_Image_CVPR_2023_paper.html)

[Shuaizheng Liu](https://openaccess.thecvf.com/CVPR2023#), [Xindong Zhang](https://openaccess.thecvf.com/CVPR2023#), [Lingchen Sun](https://openaccess.thecvf.com/CVPR2023#), [Zhetong Liang](https://openaccess.thecvf.com/CVPR2023#), [Hui Zeng](https://openaccess.thecvf.com/CVPR2023#), [Lei Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Joint_HDR_Denoising_and_Fusion_A_Real-World_Mobile_HDR_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Liu_Joint_HDR_Denoising_CVPR_2023_supplemental.pdf)] 

[bibtex]


[A New Dataset Based on Images Taken by Blind People for Testing the Robustness of Image Classification Models Trained for ImageNet Categories](https://openaccess.thecvf.com/content/CVPR2023/html/Bafghi_A_New_Dataset_Based_on_Images_Taken_by_Blind_People_CVPR_2023_paper.html)

[Reza Akbarian Bafghi](https://openaccess.thecvf.com/CVPR2023#), [Danna Gurari](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Bafghi_A_New_Dataset_Based_on_Images_Taken_by_Blind_People_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Bafghi_A_New_Dataset_CVPR_2023_supplemental.pdf)] 

[bibtex]


[MP-Former: Mask-Piloted Transformer for Image Segmentation](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_MP-Former_Mask-Piloted_Transformer_for_Image_Segmentation_CVPR_2023_paper.html)

[Hao Zhang](https://openaccess.thecvf.com/CVPR2023#), [Feng Li](https://openaccess.thecvf.com/CVPR2023#), [Huaizhe Xu](https://openaccess.thecvf.com/CVPR2023#), [Shijia Huang](https://openaccess.thecvf.com/CVPR2023#), [Shilong Liu](https://openaccess.thecvf.com/CVPR2023#), [Lionel M. Ni](https://openaccess.thecvf.com/CVPR2023#), [Lei Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_MP-Former_Mask-Piloted_Transformer_for_Image_Segmentation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhang_MP-Former_Mask-Piloted_Transformer_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Stare at What You See: Masked Image Modeling Without Reconstruction](https://openaccess.thecvf.com/content/CVPR2023/html/Xue_Stare_at_What_You_See_Masked_Image_Modeling_Without_Reconstruction_CVPR_2023_paper.html)

[Hongwei Xue](https://openaccess.thecvf.com/CVPR2023#), [Peng Gao](https://openaccess.thecvf.com/CVPR2023#), [Hongyang Li](https://openaccess.thecvf.com/CVPR2023#), [Yu Qiao](https://openaccess.thecvf.com/CVPR2023#), [Hao Sun](https://openaccess.thecvf.com/CVPR2023#), [Houqiang Li](https://openaccess.thecvf.com/CVPR2023#), [Jiebo Luo](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xue_Stare_at_What_You_See_Masked_Image_Modeling_Without_Reconstruction_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xue_Stare_at_What_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.08887)] 

[bibtex]


[Few-Shot Semantic Image Synthesis With Class Affinity Transfer](https://openaccess.thecvf.com/content/CVPR2023/html/Careil_Few-Shot_Semantic_Image_Synthesis_With_Class_Affinity_Transfer_CVPR_2023_paper.html)

[Marlène Careil](https://openaccess.thecvf.com/CVPR2023#), [Jakob Verbeek](https://openaccess.thecvf.com/CVPR2023#), [Stéphane Lathuilière](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Careil_Few-Shot_Semantic_Image_Synthesis_With_Class_Affinity_Transfer_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Careil_Few-Shot_Semantic_Image_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Unsupervised Intrinsic Image Decomposition With LiDAR Intensity](https://openaccess.thecvf.com/content/CVPR2023/html/Sato_Unsupervised_Intrinsic_Image_Decomposition_With_LiDAR_Intensity_CVPR_2023_paper.html)

[Shogo Sato](https://openaccess.thecvf.com/CVPR2023#), [Yasuhiro Yao](https://openaccess.thecvf.com/CVPR2023#), [Taiga Yoshida](https://openaccess.thecvf.com/CVPR2023#), [Takuhiro Kaneko](https://openaccess.thecvf.com/CVPR2023#), [Shingo Ando](https://openaccess.thecvf.com/CVPR2023#), [Jun Shimamura](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Sato_Unsupervised_Intrinsic_Image_Decomposition_With_LiDAR_Intensity_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Sato_Unsupervised_Intrinsic_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.10820)] 

[bibtex]


[Specialist Diffusion: Plug-and-Play Sample-Efficient Fine-Tuning of Text-to-Image Diffusion Models To Learn Any Unseen Style](https://openaccess.thecvf.com/content/CVPR2023/html/Lu_Specialist_Diffusion_Plug-and-Play_Sample-Efficient_Fine-Tuning_of_Text-to-Image_Diffusion_Models_To_CVPR_2023_paper.html)

[Haoming Lu](https://openaccess.thecvf.com/CVPR2023#), [Hazarapet Tunanyan](https://openaccess.thecvf.com/CVPR2023#), [Kai Wang](https://openaccess.thecvf.com/CVPR2023#), [Shant Navasardyan](https://openaccess.thecvf.com/CVPR2023#), [Zhangyang Wang](https://openaccess.thecvf.com/CVPR2023#), [Humphrey Shi](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Lu_Specialist_Diffusion_Plug-and-Play_Sample-Efficient_Fine-Tuning_of_Text-to-Image_Diffusion_Models_To_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Lu_Specialist_Diffusion_Plug-and-Play_CVPR_2023_supplemental.pdf)] 

[bibtex]


[HyperCUT: Video Sequence From a Single Blurry Image Using Unsupervised Ordering](https://openaccess.thecvf.com/content/CVPR2023/html/Pham_HyperCUT_Video_Sequence_From_a_Single_Blurry_Image_Using_Unsupervised_CVPR_2023_paper.html)

[Bang-Dang Pham](https://openaccess.thecvf.com/CVPR2023#), [Phong Tran](https://openaccess.thecvf.com/CVPR2023#), [Anh Tran](https://openaccess.thecvf.com/CVPR2023#), [Cuong Pham](https://openaccess.thecvf.com/CVPR2023#), [Rang Nguyen](https://openaccess.thecvf.com/CVPR2023#), [Minh Hoai](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Pham_HyperCUT_Video_Sequence_From_a_Single_Blurry_Image_Using_Unsupervised_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Pham_HyperCUT_Video_Sequence_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.01686)] 

[bibtex]


[Can't Steal? Cont-Steal! Contrastive Stealing Attacks Against Image Encoders](https://openaccess.thecvf.com/content/CVPR2023/html/Sha_Cant_Steal_Cont-Steal_Contrastive_Stealing_Attacks_Against_Image_Encoders_CVPR_2023_paper.html)

[Zeyang Sha](https://openaccess.thecvf.com/CVPR2023#), [Xinlei He](https://openaccess.thecvf.com/CVPR2023#), [Ning Yu](https://openaccess.thecvf.com/CVPR2023#), [Michael Backes](https://openaccess.thecvf.com/CVPR2023#), [Yang Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Sha_Cant_Steal_Cont-Steal_Contrastive_Stealing_Attacks_Against_Image_Encoders_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Sha_Cant_Steal_Cont-Steal_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Document Image Shadow Removal Guided by Color-Aware Background](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Document_Image_Shadow_Removal_Guided_by_Color-Aware_Background_CVPR_2023_paper.html)

[Ling Zhang](https://openaccess.thecvf.com/CVPR2023#), [Yinghao He](https://openaccess.thecvf.com/CVPR2023#), [Qing Zhang](https://openaccess.thecvf.com/CVPR2023#), [Zheng Liu](https://openaccess.thecvf.com/CVPR2023#), [Xiaolong Zhang](https://openaccess.thecvf.com/CVPR2023#), [Chunxia Xiao](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Document_Image_Shadow_Removal_Guided_by_Color-Aware_Background_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhang_Document_Image_Shadow_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Spatially Adaptive Self-Supervised Learning for Real-World Image Denoising](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Spatially_Adaptive_Self-Supervised_Learning_for_Real-World_Image_Denoising_CVPR_2023_paper.html)

[Junyi Li](https://openaccess.thecvf.com/CVPR2023#), [Zhilu Zhang](https://openaccess.thecvf.com/CVPR2023#), [Xiaoyu Liu](https://openaccess.thecvf.com/CVPR2023#), [Chaoyu Feng](https://openaccess.thecvf.com/CVPR2023#), [Xiaotao Wang](https://openaccess.thecvf.com/CVPR2023#), [Lei Lei](https://openaccess.thecvf.com/CVPR2023#), [Wangmeng Zuo](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Spatially_Adaptive_Self-Supervised_Learning_for_Real-World_Image_Denoising_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_Spatially_Adaptive_Self-Supervised_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.14934)] 

[bibtex]


[Quantum-Inspired Spectral-Spatial Pyramid Network for Hyperspectral Image Classification](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Quantum-Inspired_Spectral-Spatial_Pyramid_Network_for_Hyperspectral_Image_Classification_CVPR_2023_paper.html)

[Jie Zhang](https://openaccess.thecvf.com/CVPR2023#), [Yongshan Zhang](https://openaccess.thecvf.com/CVPR2023#), [Yicong Zhou](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Quantum-Inspired_Spectral-Spatial_Pyramid_Network_for_Hyperspectral_Image_Classification_CVPR_2023_paper.pdf)] 

[bibtex]


[Crowd3D: Towards Hundreds of People Reconstruction From a Single Image](https://openaccess.thecvf.com/content/CVPR2023/html/Wen_Crowd3D_Towards_Hundreds_of_People_Reconstruction_From_a_Single_Image_CVPR_2023_paper.html)

[Hao Wen](https://openaccess.thecvf.com/CVPR2023#), [Jing Huang](https://openaccess.thecvf.com/CVPR2023#), [Huili Cui](https://openaccess.thecvf.com/CVPR2023#), [Haozhe Lin](https://openaccess.thecvf.com/CVPR2023#), [Yu-Kun Lai](https://openaccess.thecvf.com/CVPR2023#), [Lu Fang](https://openaccess.thecvf.com/CVPR2023#), [Kun Li](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wen_Crowd3D_Towards_Hundreds_of_People_Reconstruction_From_a_Single_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wen_Crowd3D_Towards_Hundreds_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2301.09376)] 

[bibtex]


[ProD: Prompting-To-Disentangle Domain Knowledge for Cross-Domain Few-Shot Image Classification](https://openaccess.thecvf.com/content/CVPR2023/html/Ma_ProD_Prompting-To-Disentangle_Domain_Knowledge_for_Cross-Domain_Few-Shot_Image_Classification_CVPR_2023_paper.html)

[Tianyi Ma](https://openaccess.thecvf.com/CVPR2023#), [Yifan Sun](https://openaccess.thecvf.com/CVPR2023#), [Zongxin Yang](https://openaccess.thecvf.com/CVPR2023#), [Yi Yang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Ma_ProD_Prompting-To-Disentangle_Domain_Knowledge_for_Cross-Domain_Few-Shot_Image_Classification_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Ma_ProD_Prompting-To-Disentangle_Domain_CVPR_2023_supplemental.pdf)] 

[bibtex]


[ViLEM: Visual-Language Error Modeling for Image-Text Retrieval](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_ViLEM_Visual-Language_Error_Modeling_for_Image-Text_Retrieval_CVPR_2023_paper.html)

[Yuxin Chen](https://openaccess.thecvf.com/CVPR2023#), [Zongyang Ma](https://openaccess.thecvf.com/CVPR2023#), [Ziqi Zhang](https://openaccess.thecvf.com/CVPR2023#), [Zhongang Qi](https://openaccess.thecvf.com/CVPR2023#), [Chunfeng Yuan](https://openaccess.thecvf.com/CVPR2023#), [Ying Shan](https://openaccess.thecvf.com/CVPR2023#), [Bing Li](https://openaccess.thecvf.com/CVPR2023#), [Weiming Hu](https://openaccess.thecvf.com/CVPR2023#), [Xiaohu Qie](https://openaccess.thecvf.com/CVPR2023#), [Jianping Wu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_ViLEM_Visual-Language_Error_Modeling_for_Image-Text_Retrieval_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chen_ViLEM_Visual-Language_Error_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Learning Partial Correlation Based Deep Visual Representation for Image Classification](https://openaccess.thecvf.com/content/CVPR2023/html/Rahman_Learning_Partial_Correlation_Based_Deep_Visual_Representation_for_Image_Classification_CVPR_2023_paper.html)

[Saimunur Rahman](https://openaccess.thecvf.com/CVPR2023#), [Piotr Koniusz](https://openaccess.thecvf.com/CVPR2023#), [Lei Wang](https://openaccess.thecvf.com/CVPR2023#), [Luping Zhou](https://openaccess.thecvf.com/CVPR2023#), [Peyman Moghadam](https://openaccess.thecvf.com/CVPR2023#), [Changming Sun](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Rahman_Learning_Partial_Correlation_Based_Deep_Visual_Representation_for_Image_Classification_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Rahman_Learning_Partial_Correlation_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.11597)] 

[bibtex]


[Generative Diffusion Prior for Unified Image Restoration and Enhancement](https://openaccess.thecvf.com/content/CVPR2023/html/Fei_Generative_Diffusion_Prior_for_Unified_Image_Restoration_and_Enhancement_CVPR_2023_paper.html)

[Ben Fei](https://openaccess.thecvf.com/CVPR2023#), [Zhaoyang Lyu](https://openaccess.thecvf.com/CVPR2023#), [Liang Pan](https://openaccess.thecvf.com/CVPR2023#), [Junzhe Zhang](https://openaccess.thecvf.com/CVPR2023#), [Weidong Yang](https://openaccess.thecvf.com/CVPR2023#), [Tianyue Luo](https://openaccess.thecvf.com/CVPR2023#), [Bo Zhang](https://openaccess.thecvf.com/CVPR2023#), [Bo Dai](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Fei_Generative_Diffusion_Prior_for_Unified_Image_Restoration_and_Enhancement_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Fei_Generative_Diffusion_Prior_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.01247)] 

[bibtex]


[Real-Time Controllable Denoising for Image and Video](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Real-Time_Controllable_Denoising_for_Image_and_Video_CVPR_2023_paper.html)

[Zhaoyang Zhang](https://openaccess.thecvf.com/CVPR2023#), [Yitong Jiang](https://openaccess.thecvf.com/CVPR2023#), [Wenqi Shao](https://openaccess.thecvf.com/CVPR2023#), [Xiaogang Wang](https://openaccess.thecvf.com/CVPR2023#), [Ping Luo](https://openaccess.thecvf.com/CVPR2023#), [Kaimo Lin](https://openaccess.thecvf.com/CVPR2023#), [Jinwei Gu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Real-Time_Controllable_Denoising_for_Image_and_Video_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhang_Real-Time_Controllable_Denoising_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2303.16425)] 

[bibtex]


[Hi-LASSIE: High-Fidelity Articulated Shape and Skeleton Discovery From Sparse Image Ensemble](https://openaccess.thecvf.com/content/CVPR2023/html/Yao_Hi-LASSIE_High-Fidelity_Articulated_Shape_and_Skeleton_Discovery_From_Sparse_Image_CVPR_2023_paper.html)

[Chun-Han Yao](https://openaccess.thecvf.com/CVPR2023#), [Wei-Chih Hung](https://openaccess.thecvf.com/CVPR2023#), [Yuanzhen Li](https://openaccess.thecvf.com/CVPR2023#), [Michael Rubinstein](https://openaccess.thecvf.com/CVPR2023#), [Ming-Hsuan Yang](https://openaccess.thecvf.com/CVPR2023#), [Varun Jampani](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yao_Hi-LASSIE_High-Fidelity_Articulated_Shape_and_Skeleton_Discovery_From_Sparse_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yao_Hi-LASSIE_High-Fidelity_Articulated_CVPR_2023_supplemental.pdf)] 

[bibtex]


[3D-Aware Multi-Class Image-to-Image Translation With NeRFs](https://openaccess.thecvf.com/content/CVPR2023/html/Li_3D-Aware_Multi-Class_Image-to-Image_Translation_With_NeRFs_CVPR_2023_paper.html)

[Senmao Li](https://openaccess.thecvf.com/CVPR2023#), [Joost van de Weijer](https://openaccess.thecvf.com/CVPR2023#), [Yaxing Wang](https://openaccess.thecvf.com/CVPR2023#), [Fahad Shahbaz Khan](https://openaccess.thecvf.com/CVPR2023#), [Meiqin Liu](https://openaccess.thecvf.com/CVPR2023#), [Jian Yang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_3D-Aware_Multi-Class_Image-to-Image_Translation_With_NeRFs_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_3D-Aware_Multi-Class_Image-to-Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.15012)] 

[bibtex]


[PMatch: Paired Masked Image Modeling for Dense Geometric Matching](https://openaccess.thecvf.com/content/CVPR2023/html/Zhu_PMatch_Paired_Masked_Image_Modeling_for_Dense_Geometric_Matching_CVPR_2023_paper.html)

[Shengjie Zhu](https://openaccess.thecvf.com/CVPR2023#), [Xiaoming Liu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_PMatch_Paired_Masked_Image_Modeling_for_Dense_Geometric_Matching_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhu_PMatch_Paired_Masked_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.17342)] 

[bibtex]


[Visual Recognition-Driven Image Restoration for Multiple Degradation With Intrinsic Semantics Recovery](https://openaccess.thecvf.com/content/CVPR2023/html/Yang_Visual_Recognition-Driven_Image_Restoration_for_Multiple_Degradation_With_Intrinsic_Semantics_CVPR_2023_paper.html)

[Zizheng Yang](https://openaccess.thecvf.com/CVPR2023#), [Jie Huang](https://openaccess.thecvf.com/CVPR2023#), [Jiahao Chang](https://openaccess.thecvf.com/CVPR2023#), [Man Zhou](https://openaccess.thecvf.com/CVPR2023#), [Hu Yu](https://openaccess.thecvf.com/CVPR2023#), [Jinghao Zhang](https://openaccess.thecvf.com/CVPR2023#), [Feng Zhao](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yang_Visual_Recognition-Driven_Image_Restoration_for_Multiple_Degradation_With_Intrinsic_Semantics_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yang_Visual_Recognition-Driven_Image_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Masked and Adaptive Transformer for Exemplar Based Image Translation](https://openaccess.thecvf.com/content/CVPR2023/html/Jiang_Masked_and_Adaptive_Transformer_for_Exemplar_Based_Image_Translation_CVPR_2023_paper.html)

[Chang Jiang](https://openaccess.thecvf.com/CVPR2023#), [Fei Gao](https://openaccess.thecvf.com/CVPR2023#), [Biao Ma](https://openaccess.thecvf.com/CVPR2023#), [Yuhao Lin](https://openaccess.thecvf.com/CVPR2023#), [Nannan Wang](https://openaccess.thecvf.com/CVPR2023#), [Gang Xu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_Masked_and_Adaptive_Transformer_for_Exemplar_Based_Image_Translation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Jiang_Masked_and_Adaptive_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.17123)] 

[bibtex]


[Imagic: Text-Based Real Image Editing With Diffusion Models](https://openaccess.thecvf.com/content/CVPR2023/html/Kawar_Imagic_Text-Based_Real_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.html)

[Bahjat Kawar](https://openaccess.thecvf.com/CVPR2023#), [Shiran Zada](https://openaccess.thecvf.com/CVPR2023#), [Oran Lang](https://openaccess.thecvf.com/CVPR2023#), [Omer Tov](https://openaccess.thecvf.com/CVPR2023#), [Huiwen Chang](https://openaccess.thecvf.com/CVPR2023#), [Tali Dekel](https://openaccess.thecvf.com/CVPR2023#), [Inbar Mosseri](https://openaccess.thecvf.com/CVPR2023#), [Michal Irani](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Kawar_Imagic_Text-Based_Real_Image_Editing_With_Diffusion_Models_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Kawar_Imagic_Text-Based_Real_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2210.09276)] 

[bibtex]


[Contrastive Grouping With Transformer for Referring Image Segmentation](https://openaccess.thecvf.com/content/CVPR2023/html/Tang_Contrastive_Grouping_With_Transformer_for_Referring_Image_Segmentation_CVPR_2023_paper.html)

[Jiajin Tang](https://openaccess.thecvf.com/CVPR2023#), [Ge Zheng](https://openaccess.thecvf.com/CVPR2023#), [Cheng Shi](https://openaccess.thecvf.com/CVPR2023#), [Sibei Yang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Tang_Contrastive_Grouping_With_Transformer_for_Referring_Image_Segmentation_CVPR_2023_paper.pdf)] 

[bibtex]


[Deep Curvilinear Editing: Commutative and Nonlinear Image Manipulation for Pretrained Deep Generative Model](https://openaccess.thecvf.com/content/CVPR2023/html/Aoshima_Deep_Curvilinear_Editing_Commutative_and_Nonlinear_Image_Manipulation_for_Pretrained_CVPR_2023_paper.html)

[Takehiro Aoshima](https://openaccess.thecvf.com/CVPR2023#), [Takashi Matsubara](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Aoshima_Deep_Curvilinear_Editing_Commutative_and_Nonlinear_Image_Manipulation_for_Pretrained_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Aoshima_Deep_Curvilinear_Editing_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2211.14573)] 

[bibtex]


[Learning Semantic-Aware Knowledge Guidance for Low-Light Image Enhancement](https://openaccess.thecvf.com/content/CVPR2023/html/Wu_Learning_Semantic-Aware_Knowledge_Guidance_for_Low-Light_Image_Enhancement_CVPR_2023_paper.html)

[Yuhui Wu](https://openaccess.thecvf.com/CVPR2023#), [Chen Pan](https://openaccess.thecvf.com/CVPR2023#), [Guoqing Wang](https://openaccess.thecvf.com/CVPR2023#), [Yang Yang](https://openaccess.thecvf.com/CVPR2023#), [Jiwei Wei](https://openaccess.thecvf.com/CVPR2023#), [Chongyi Li](https://openaccess.thecvf.com/CVPR2023#), [Heng Tao Shen](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wu_Learning_Semantic-Aware_Knowledge_Guidance_for_Low-Light_Image_Enhancement_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wu_Learning_Semantic-Aware_Knowledge_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.07039)] 

[bibtex]


[Deep Arbitrary-Scale Image Super-Resolution via Scale-Equivariance Pursuit](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Deep_Arbitrary-Scale_Image_Super-Resolution_via_Scale-Equivariance_Pursuit_CVPR_2023_paper.html)

[Xiaohang Wang](https://openaccess.thecvf.com/CVPR2023#), [Xuanhong Chen](https://openaccess.thecvf.com/CVPR2023#), [Bingbing Ni](https://openaccess.thecvf.com/CVPR2023#), [Hang Wang](https://openaccess.thecvf.com/CVPR2023#), [Zhengyan Tong](https://openaccess.thecvf.com/CVPR2023#), [Yutian Liu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Deep_Arbitrary-Scale_Image_Super-Resolution_via_Scale-Equivariance_Pursuit_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Deep_Arbitrary-Scale_Image_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Toward Verifiable and Reproducible Human Evaluation for Text-to-Image Generation](https://openaccess.thecvf.com/content/CVPR2023/html/Otani_Toward_Verifiable_and_Reproducible_Human_Evaluation_for_Text-to-Image_Generation_CVPR_2023_paper.html)

[Mayu Otani](https://openaccess.thecvf.com/CVPR2023#), [Riku Togashi](https://openaccess.thecvf.com/CVPR2023#), [Yu Sawai](https://openaccess.thecvf.com/CVPR2023#), [Ryosuke Ishigami](https://openaccess.thecvf.com/CVPR2023#), [Yuta Nakashima](https://openaccess.thecvf.com/CVPR2023#), [Esa Rahtu](https://openaccess.thecvf.com/CVPR2023#), [Janne Heikkilä](https://openaccess.thecvf.com/CVPR2023#), [Shin’ichi Satoh](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Otani_Toward_Verifiable_and_Reproducible_Human_Evaluation_for_Text-to-Image_Generation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Otani_Toward_Verifiable_and_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.01816)] 

[bibtex]


[Learning Weather-General and Weather-Specific Features for Image Restoration Under Multiple Adverse Weather Conditions](https://openaccess.thecvf.com/content/CVPR2023/html/Zhu_Learning_Weather-General_and_Weather-Specific_Features_for_Image_Restoration_Under_Multiple_CVPR_2023_paper.html)

[Yurui Zhu](https://openaccess.thecvf.com/CVPR2023#), [Tianyu Wang](https://openaccess.thecvf.com/CVPR2023#), [Xueyang Fu](https://openaccess.thecvf.com/CVPR2023#), [Xuanyu Yang](https://openaccess.thecvf.com/CVPR2023#), [Xin Guo](https://openaccess.thecvf.com/CVPR2023#), [Jifeng Dai](https://openaccess.thecvf.com/CVPR2023#), [Yu Qiao](https://openaccess.thecvf.com/CVPR2023#), [Xiaowei Hu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhu_Learning_Weather-General_and_Weather-Specific_Features_for_Image_Restoration_Under_Multiple_CVPR_2023_paper.pdf)] 

[bibtex]


[Recurrent Homography Estimation Using Homography-Guided Image Warping and Focus Transformer](https://openaccess.thecvf.com/content/CVPR2023/html/Cao_Recurrent_Homography_Estimation_Using_Homography-Guided_Image_Warping_and_Focus_Transformer_CVPR_2023_paper.html)

[Si-Yuan Cao](https://openaccess.thecvf.com/CVPR2023#), [Runmin Zhang](https://openaccess.thecvf.com/CVPR2023#), [Lun Luo](https://openaccess.thecvf.com/CVPR2023#), [Beinan Yu](https://openaccess.thecvf.com/CVPR2023#), [Zehua Sheng](https://openaccess.thecvf.com/CVPR2023#), [Junwei Li](https://openaccess.thecvf.com/CVPR2023#), [Hui-Liang Shen](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_Recurrent_Homography_Estimation_Using_Homography-Guided_Image_Warping_and_Focus_Transformer_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Cao_Recurrent_Homography_Estimation_CVPR_2023_supplemental.zip)] 

[bibtex]


[AutoFocusFormer: Image Segmentation off the Grid](https://openaccess.thecvf.com/content/CVPR2023/html/Ziwen_AutoFocusFormer_Image_Segmentation_off_the_Grid_CVPR_2023_paper.html)

[Chen Ziwen](https://openaccess.thecvf.com/CVPR2023#), [Kaushik Patnaik](https://openaccess.thecvf.com/CVPR2023#), [Shuangfei Zhai](https://openaccess.thecvf.com/CVPR2023#), [Alvin Wan](https://openaccess.thecvf.com/CVPR2023#), [Zhile Ren](https://openaccess.thecvf.com/CVPR2023#), [Alexander G. Schwing](https://openaccess.thecvf.com/CVPR2023#), [Alex Colburn](https://openaccess.thecvf.com/CVPR2023#), [Li Fuxin](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Ziwen_AutoFocusFormer_Image_Segmentation_off_the_Grid_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Ziwen_AutoFocusFormer_Image_Segmentation_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2304.12406)] 

[bibtex]


[PRISE: Demystifying Deep Lucas-Kanade With Strongly Star-Convex Constraints for Multimodel Image Alignment](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_PRISE_Demystifying_Deep_Lucas-Kanade_With_Strongly_Star-Convex_Constraints_for_Multimodel_CVPR_2023_paper.html)

[Yiqing Zhang](https://openaccess.thecvf.com/CVPR2023#), [Xinming Huang](https://openaccess.thecvf.com/CVPR2023#), [Ziming Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_PRISE_Demystifying_Deep_Lucas-Kanade_With_Strongly_Star-Convex_Constraints_for_Multimodel_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.11526)] 

[bibtex]


[CDDFuse: Correlation-Driven Dual-Branch Feature Decomposition for Multi-Modality Image Fusion](https://openaccess.thecvf.com/content/CVPR2023/html/Zhao_CDDFuse_Correlation-Driven_Dual-Branch_Feature_Decomposition_for_Multi-Modality_Image_Fusion_CVPR_2023_paper.html)

[Zixiang Zhao](https://openaccess.thecvf.com/CVPR2023#), [Haowen Bai](https://openaccess.thecvf.com/CVPR2023#), [Jiangshe Zhang](https://openaccess.thecvf.com/CVPR2023#), [Yulun Zhang](https://openaccess.thecvf.com/CVPR2023#), [Shuang Xu](https://openaccess.thecvf.com/CVPR2023#), [Zudi Lin](https://openaccess.thecvf.com/CVPR2023#), [Radu Timofte](https://openaccess.thecvf.com/CVPR2023#), [Luc Van Gool](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_CDDFuse_Correlation-Driven_Dual-Branch_Feature_Decomposition_for_Multi-Modality_Image_Fusion_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhao_CDDFuse_Correlation-Driven_Dual-Branch_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.14461)] 

[bibtex]


[Cross-Modal Implicit Relation Reasoning and Aligning for Text-to-Image Person Retrieval](https://openaccess.thecvf.com/content/CVPR2023/html/Jiang_Cross-Modal_Implicit_Relation_Reasoning_and_Aligning_for_Text-to-Image_Person_Retrieval_CVPR_2023_paper.html)

[Ding Jiang](https://openaccess.thecvf.com/CVPR2023#), [Mang Ye](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_Cross-Modal_Implicit_Relation_Reasoning_and_Aligning_for_Text-to-Image_Person_Retrieval_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.12501)] 

[bibtex]


[Private Image Generation With Dual-Purpose Auxiliary Classifier](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Private_Image_Generation_With_Dual-Purpose_Auxiliary_Classifier_CVPR_2023_paper.html)

[Chen Chen](https://openaccess.thecvf.com/CVPR2023#), [Daochang Liu](https://openaccess.thecvf.com/CVPR2023#), [Siqi Ma](https://openaccess.thecvf.com/CVPR2023#), [Surya Nepal](https://openaccess.thecvf.com/CVPR2023#), [Chang Xu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Private_Image_Generation_With_Dual-Purpose_Auxiliary_Classifier_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chen_Private_Image_Generation_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Generating Aligned Pseudo-Supervision From Non-Aligned Data for Image Restoration in Under-Display Camera](https://openaccess.thecvf.com/content/CVPR2023/html/Feng_Generating_Aligned_Pseudo-Supervision_From_Non-Aligned_Data_for_Image_Restoration_in_CVPR_2023_paper.html)

[Ruicheng Feng](https://openaccess.thecvf.com/CVPR2023#), [Chongyi Li](https://openaccess.thecvf.com/CVPR2023#), [Huaijin Chen](https://openaccess.thecvf.com/CVPR2023#), [Shuai Li](https://openaccess.thecvf.com/CVPR2023#), [Jinwei Gu](https://openaccess.thecvf.com/CVPR2023#), [Chen Change Loy](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Feng_Generating_Aligned_Pseudo-Supervision_From_Non-Aligned_Data_for_Image_Restoration_in_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Feng_Generating_Aligned_Pseudo-Supervision_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.06019)] 

[bibtex]


[N-Gram in Swin Transformers for Efficient Lightweight Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Choi_N-Gram_in_Swin_Transformers_for_Efficient_Lightweight_Image_Super-Resolution_CVPR_2023_paper.html)

[Haram Choi](https://openaccess.thecvf.com/CVPR2023#), [Jeongmin Lee](https://openaccess.thecvf.com/CVPR2023#), [Jihoon Yang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Choi_N-Gram_in_Swin_Transformers_for_Efficient_Lightweight_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Choi_N-Gram_in_Swin_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Perception-Oriented Single Image Super-Resolution Using Optimal Objective Estimation](https://openaccess.thecvf.com/content/CVPR2023/html/Park_Perception-Oriented_Single_Image_Super-Resolution_Using_Optimal_Objective_Estimation_CVPR_2023_paper.html)

[Seung Ho Park](https://openaccess.thecvf.com/CVPR2023#), [Young Su Moon](https://openaccess.thecvf.com/CVPR2023#), [Nam Ik Cho](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Park_Perception-Oriented_Single_Image_Super-Resolution_Using_Optimal_Objective_Estimation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Park_Perception-Oriented_Single_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.13676)] 

[bibtex]


[Uncurated Image-Text Datasets: Shedding Light on Demographic Bias](https://openaccess.thecvf.com/content/CVPR2023/html/Garcia_Uncurated_Image-Text_Datasets_Shedding_Light_on_Demographic_Bias_CVPR_2023_paper.html)

[Noa Garcia](https://openaccess.thecvf.com/CVPR2023#), [Yusuke Hirota](https://openaccess.thecvf.com/CVPR2023#), [Yankun Wu](https://openaccess.thecvf.com/CVPR2023#), [Yuta Nakashima](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Garcia_Uncurated_Image-Text_Datasets_Shedding_Light_on_Demographic_Bias_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Garcia_Uncurated_Image-Text_Datasets_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.02828)] 

[bibtex]


[FreeSeg: Unified, Universal and Open-Vocabulary Image Segmentation](https://openaccess.thecvf.com/content/CVPR2023/html/Qin_FreeSeg_Unified_Universal_and_Open-Vocabulary_Image_Segmentation_CVPR_2023_paper.html)

[Jie Qin](https://openaccess.thecvf.com/CVPR2023#), [Jie Wu](https://openaccess.thecvf.com/CVPR2023#), [Pengxiang Yan](https://openaccess.thecvf.com/CVPR2023#), [Ming Li](https://openaccess.thecvf.com/CVPR2023#), [Ren Yuxi](https://openaccess.thecvf.com/CVPR2023#), [Xuefeng Xiao](https://openaccess.thecvf.com/CVPR2023#), [Yitong Wang](https://openaccess.thecvf.com/CVPR2023#), [Rui Wang](https://openaccess.thecvf.com/CVPR2023#), [Shilei Wen](https://openaccess.thecvf.com/CVPR2023#), [Xin Pan](https://openaccess.thecvf.com/CVPR2023#), [Xingang Wang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Qin_FreeSeg_Unified_Universal_and_Open-Vocabulary_Image_Segmentation_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.17225)] 

[bibtex]


[CLIP2: Contrastive Language-Image-Point Pretraining From Real-World Point Cloud Data](https://openaccess.thecvf.com/content/CVPR2023/html/Zeng_CLIP2_Contrastive_Language-Image-Point_Pretraining_From_Real-World_Point_Cloud_Data_CVPR_2023_paper.html)

[Yihan Zeng](https://openaccess.thecvf.com/CVPR2023#), [Chenhan Jiang](https://openaccess.thecvf.com/CVPR2023#), [Jiageng Mao](https://openaccess.thecvf.com/CVPR2023#), [Jianhua Han](https://openaccess.thecvf.com/CVPR2023#), [Chaoqiang Ye](https://openaccess.thecvf.com/CVPR2023#), [Qingqiu Huang](https://openaccess.thecvf.com/CVPR2023#), [Dit-Yan Yeung](https://openaccess.thecvf.com/CVPR2023#), [Zhen Yang](https://openaccess.thecvf.com/CVPR2023#), [Xiaodan Liang](https://openaccess.thecvf.com/CVPR2023#), [Hang Xu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zeng_CLIP2_Contrastive_Language-Image-Point_Pretraining_From_Real-World_Point_Cloud_Data_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zeng_CLIP2_Contrastive_Language-Image-Point_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Model-Agnostic Gender Debiased Image Captioning](https://openaccess.thecvf.com/content/CVPR2023/html/Hirota_Model-Agnostic_Gender_Debiased_Image_Captioning_CVPR_2023_paper.html)

[Yusuke Hirota](https://openaccess.thecvf.com/CVPR2023#), [Yuta Nakashima](https://openaccess.thecvf.com/CVPR2023#), [Noa Garcia](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Hirota_Model-Agnostic_Gender_Debiased_Image_Captioning_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Hirota_Model-Agnostic_Gender_Debiased_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.03693)] 

[bibtex]


[CLIPPO: Image-and-Language Understanding From Pixels Only](https://openaccess.thecvf.com/content/CVPR2023/html/Tschannen_CLIPPO_Image-and-Language_Understanding_From_Pixels_Only_CVPR_2023_paper.html)

[Michael Tschannen](https://openaccess.thecvf.com/CVPR2023#), [Basil Mustafa](https://openaccess.thecvf.com/CVPR2023#), [Neil Houlsby](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Tschannen_CLIPPO_Image-and-Language_Understanding_From_Pixels_Only_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Tschannen_CLIPPO_Image-and-Language_Understanding_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.08045)] 

[bibtex]


[Conditional Image-to-Video Generation With Latent Flow Diffusion Models](https://openaccess.thecvf.com/content/CVPR2023/html/Ni_Conditional_Image-to-Video_Generation_With_Latent_Flow_Diffusion_Models_CVPR_2023_paper.html)

[Haomiao Ni](https://openaccess.thecvf.com/CVPR2023#), [Changhao Shi](https://openaccess.thecvf.com/CVPR2023#), [Kai Li](https://openaccess.thecvf.com/CVPR2023#), [Sharon X. Huang](https://openaccess.thecvf.com/CVPR2023#), [Martin Renqiang Min](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Ni_Conditional_Image-to-Video_Generation_With_Latent_Flow_Diffusion_Models_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Ni_Conditional_Image-to-Video_Generation_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2303.13744)] 

[bibtex]


[Towards Universal Fake Image Detectors That Generalize Across Generative Models](https://openaccess.thecvf.com/content/CVPR2023/html/Ojha_Towards_Universal_Fake_Image_Detectors_That_Generalize_Across_Generative_Models_CVPR_2023_paper.html)

[Utkarsh Ojha](https://openaccess.thecvf.com/CVPR2023#), [Yuheng Li](https://openaccess.thecvf.com/CVPR2023#), [Yong Jae Lee](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Ojha_Towards_Universal_Fake_Image_Detectors_That_Generalize_Across_Generative_Models_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2302.10174)] 

[bibtex]


[DATID-3D: Diversity-Preserved Domain Adaptation Using Text-to-Image Diffusion for 3D Generative Model](https://openaccess.thecvf.com/content/CVPR2023/html/Kim_DATID-3D_Diversity-Preserved_Domain_Adaptation_Using_Text-to-Image_Diffusion_for_3D_Generative_CVPR_2023_paper.html)

[Gwanghyun Kim](https://openaccess.thecvf.com/CVPR2023#), [Se Young Chun](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_DATID-3D_Diversity-Preserved_Domain_Adaptation_Using_Text-to-Image_Diffusion_for_3D_Generative_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Kim_DATID-3D_Diversity-Preserved_Domain_CVPR_2023_supplemental.pdf)] 

[bibtex]


[iCLIP: Bridging Image Classification and Contrastive Language-Image Pre-Training for Visual Recognition](https://openaccess.thecvf.com/content/CVPR2023/html/Wei_iCLIP_Bridging_Image_Classification_and_Contrastive_Language-Image_Pre-Training_for_Visual_CVPR_2023_paper.html)

[Yixuan Wei](https://openaccess.thecvf.com/CVPR2023#), [Yue Cao](https://openaccess.thecvf.com/CVPR2023#), [Zheng Zhang](https://openaccess.thecvf.com/CVPR2023#), [Houwen Peng](https://openaccess.thecvf.com/CVPR2023#), [Zhuliang Yao](https://openaccess.thecvf.com/CVPR2023#), [Zhenda Xie](https://openaccess.thecvf.com/CVPR2023#), [Han Hu](https://openaccess.thecvf.com/CVPR2023#), [Baining Guo](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_iCLIP_Bridging_Image_Classification_and_Contrastive_Language-Image_Pre-Training_for_Visual_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wei_iCLIP_Bridging_Image_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Comprehensive and Delicate: An Efficient Transformer for Image Restoration](https://openaccess.thecvf.com/content/CVPR2023/html/Zhao_Comprehensive_and_Delicate_An_Efficient_Transformer_for_Image_Restoration_CVPR_2023_paper.html)

[Haiyu Zhao](https://openaccess.thecvf.com/CVPR2023#), [Yuanbiao Gou](https://openaccess.thecvf.com/CVPR2023#), [Boyun Li](https://openaccess.thecvf.com/CVPR2023#), [Dezhong Peng](https://openaccess.thecvf.com/CVPR2023#), [Jiancheng Lv](https://openaccess.thecvf.com/CVPR2023#), [Xi Peng](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhao_Comprehensive_and_Delicate_An_Efficient_Transformer_for_Image_Restoration_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhao_Comprehensive_and_Delicate_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Geometric Visual Similarity Learning in 3D Medical Image Self-Supervised Pre-Training](https://openaccess.thecvf.com/content/CVPR2023/html/He_Geometric_Visual_Similarity_Learning_in_3D_Medical_Image_Self-Supervised_Pre-Training_CVPR_2023_paper.html)

[Yuting He](https://openaccess.thecvf.com/CVPR2023#), [Guanyu Yang](https://openaccess.thecvf.com/CVPR2023#), [Rongjun Ge](https://openaccess.thecvf.com/CVPR2023#), [Yang Chen](https://openaccess.thecvf.com/CVPR2023#), [Jean-Louis Coatrieux](https://openaccess.thecvf.com/CVPR2023#), [Boyu Wang](https://openaccess.thecvf.com/CVPR2023#), [Shuo Li](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/He_Geometric_Visual_Similarity_Learning_in_3D_Medical_Image_Self-Supervised_Pre-Training_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/He_Geometric_Visual_Similarity_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.00874)] 

[bibtex]


[Towards Artistic Image Aesthetics Assessment: A Large-Scale Dataset and a New Method](https://openaccess.thecvf.com/content/CVPR2023/html/Yi_Towards_Artistic_Image_Aesthetics_Assessment_A_Large-Scale_Dataset_and_a_CVPR_2023_paper.html)

[Ran Yi](https://openaccess.thecvf.com/CVPR2023#), [Haoyuan Tian](https://openaccess.thecvf.com/CVPR2023#), [Zhihao Gu](https://openaccess.thecvf.com/CVPR2023#), [Yu-Kun Lai](https://openaccess.thecvf.com/CVPR2023#), [Paul L. Rosin](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yi_Towards_Artistic_Image_Aesthetics_Assessment_A_Large-Scale_Dataset_and_a_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yi_Towards_Artistic_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.15166)] 

[bibtex]


[Plug-and-Play Diffusion Features for Text-Driven Image-to-Image Translation](https://openaccess.thecvf.com/content/CVPR2023/html/Tumanyan_Plug-and-Play_Diffusion_Features_for_Text-Driven_Image-to-Image_Translation_CVPR_2023_paper.html)

[Narek Tumanyan](https://openaccess.thecvf.com/CVPR2023#), [Michal Geyer](https://openaccess.thecvf.com/CVPR2023#), [Shai Bagon](https://openaccess.thecvf.com/CVPR2023#), [Tali Dekel](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Tumanyan_Plug-and-Play_Diffusion_Features_for_Text-Driven_Image-to-Image_Translation_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2211.12572)] 

[bibtex]


[CiaoSR: Continuous Implicit Attention-in-Attention Network for Arbitrary-Scale Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Cao_CiaoSR_Continuous_Implicit_Attention-in-Attention_Network_for_Arbitrary-Scale_Image_Super-Resolution_CVPR_2023_paper.html)

[Jiezhang Cao](https://openaccess.thecvf.com/CVPR2023#), [Qin Wang](https://openaccess.thecvf.com/CVPR2023#), [Yongqin Xian](https://openaccess.thecvf.com/CVPR2023#), [Yawei Li](https://openaccess.thecvf.com/CVPR2023#), [Bingbing Ni](https://openaccess.thecvf.com/CVPR2023#), [Zhiming Pi](https://openaccess.thecvf.com/CVPR2023#), [Kai Zhang](https://openaccess.thecvf.com/CVPR2023#), [Yulun Zhang](https://openaccess.thecvf.com/CVPR2023#), [Radu Timofte](https://openaccess.thecvf.com/CVPR2023#), [Luc Van Gool](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Cao_CiaoSR_Continuous_Implicit_Attention-in-Attention_Network_for_Arbitrary-Scale_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Cao_CiaoSR_Continuous_Implicit_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.04362)] 

[bibtex]


[3D-Aware Conditional Image Synthesis](https://openaccess.thecvf.com/content/CVPR2023/html/Deng_3D-Aware_Conditional_Image_Synthesis_CVPR_2023_paper.html)

[Kangle Deng](https://openaccess.thecvf.com/CVPR2023#), [Gengshan Yang](https://openaccess.thecvf.com/CVPR2023#), [Deva Ramanan](https://openaccess.thecvf.com/CVPR2023#), [Jun-Yan Zhu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Deng_3D-Aware_Conditional_Image_Synthesis_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2302.08509)] 

[bibtex]


[SceneComposer: Any-Level Semantic Image Synthesis](https://openaccess.thecvf.com/content/CVPR2023/html/Zeng_SceneComposer_Any-Level_Semantic_Image_Synthesis_CVPR_2023_paper.html)

[Yu Zeng](https://openaccess.thecvf.com/CVPR2023#), [Zhe Lin](https://openaccess.thecvf.com/CVPR2023#), [Jianming Zhang](https://openaccess.thecvf.com/CVPR2023#), [Qing Liu](https://openaccess.thecvf.com/CVPR2023#), [John Collomosse](https://openaccess.thecvf.com/CVPR2023#), [Jason Kuen](https://openaccess.thecvf.com/CVPR2023#), [Vishal M. Patel](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zeng_SceneComposer_Any-Level_Semantic_Image_Synthesis_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zeng_SceneComposer_Any-Level_Semantic_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.11742)] 

[bibtex]


[Unsupervised Domain Adaption With Pixel-Level Discriminator for Image-Aware Layout Generation](https://openaccess.thecvf.com/content/CVPR2023/html/Xu_Unsupervised_Domain_Adaption_With_Pixel-Level_Discriminator_for_Image-Aware_Layout_Generation_CVPR_2023_paper.html)

[Chenchen Xu](https://openaccess.thecvf.com/CVPR2023#), [Min Zhou](https://openaccess.thecvf.com/CVPR2023#), [Tiezheng Ge](https://openaccess.thecvf.com/CVPR2023#), [Yuning Jiang](https://openaccess.thecvf.com/CVPR2023#), [Weiwei Xu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Unsupervised_Domain_Adaption_With_Pixel-Level_Discriminator_for_Image-Aware_Layout_Generation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xu_Unsupervised_Domain_Adaption_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2303.14377)] 

[bibtex]


[Real-Time 6K Image Rescaling With Rate-Distortion Optimization](https://openaccess.thecvf.com/content/CVPR2023/html/Qi_Real-Time_6K_Image_Rescaling_With_Rate-Distortion_Optimization_CVPR_2023_paper.html)

[Chenyang Qi](https://openaccess.thecvf.com/CVPR2023#), [Xin Yang](https://openaccess.thecvf.com/CVPR2023#), [Ka Leong Cheng](https://openaccess.thecvf.com/CVPR2023#), [Ying-Cong Chen](https://openaccess.thecvf.com/CVPR2023#), [Qifeng Chen](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Qi_Real-Time_6K_Image_Rescaling_With_Rate-Distortion_Optimization_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Qi_Real-Time_6K_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.01064)] 

[bibtex]


[Scaling Language-Image Pre-Training via Masking](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Scaling_Language-Image_Pre-Training_via_Masking_CVPR_2023_paper.html)

[Yanghao Li](https://openaccess.thecvf.com/CVPR2023#), [Haoqi Fan](https://openaccess.thecvf.com/CVPR2023#), [Ronghang Hu](https://openaccess.thecvf.com/CVPR2023#), [Christoph Feichtenhofer](https://openaccess.thecvf.com/CVPR2023#), [Kaiming He](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Scaling_Language-Image_Pre-Training_via_Masking_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_Scaling_Language-Image_Pre-Training_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.00794)] 

[bibtex]


[Ingredient-Oriented Multi-Degradation Learning for Image Restoration](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Ingredient-Oriented_Multi-Degradation_Learning_for_Image_Restoration_CVPR_2023_paper.html)

[Jinghao Zhang](https://openaccess.thecvf.com/CVPR2023#), [Jie Huang](https://openaccess.thecvf.com/CVPR2023#), [Mingde Yao](https://openaccess.thecvf.com/CVPR2023#), [Zizheng Yang](https://openaccess.thecvf.com/CVPR2023#), [Hu Yu](https://openaccess.thecvf.com/CVPR2023#), [Man Zhou](https://openaccess.thecvf.com/CVPR2023#), [Feng Zhao](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Ingredient-Oriented_Multi-Degradation_Learning_for_Image_Restoration_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhang_Ingredient-Oriented_Multi-Degradation_Learning_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Weakly-Supervised Single-View Image Relighting](https://openaccess.thecvf.com/content/CVPR2023/html/Yi_Weakly-Supervised_Single-View_Image_Relighting_CVPR_2023_paper.html)

[Renjiao Yi](https://openaccess.thecvf.com/CVPR2023#), [Chenyang Zhu](https://openaccess.thecvf.com/CVPR2023#), [Kai Xu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yi_Weakly-Supervised_Single-View_Image_Relighting_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yi_Weakly-Supervised_Single-View_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.13852)] 

[bibtex]


[Realistic Saliency Guided Image Enhancement](https://openaccess.thecvf.com/content/CVPR2023/html/Miangoleh_Realistic_Saliency_Guided_Image_Enhancement_CVPR_2023_paper.html)

[S. Mahdi H. Miangoleh](https://openaccess.thecvf.com/CVPR2023#), [Zoya Bylinskii](https://openaccess.thecvf.com/CVPR2023#), [Eric Kee](https://openaccess.thecvf.com/CVPR2023#), [Eli Shechtman](https://openaccess.thecvf.com/CVPR2023#), [Yağiz Aksoy](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Miangoleh_Realistic_Saliency_Guided_Image_Enhancement_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Miangoleh_Realistic_Saliency_Guided_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Image Cropping With Spatial-Aware Feature and Rank Consistency](https://openaccess.thecvf.com/content/CVPR2023/html/Wang_Image_Cropping_With_Spatial-Aware_Feature_and_Rank_Consistency_CVPR_2023_paper.html)

[Chao Wang](https://openaccess.thecvf.com/CVPR2023#), [Li Niu](https://openaccess.thecvf.com/CVPR2023#), [Bo Zhang](https://openaccess.thecvf.com/CVPR2023#), [Liqing Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Wang_Image_Cropping_With_Spatial-Aware_Feature_and_Rank_Consistency_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Wang_Image_Cropping_With_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Neumann Network With Recursive Kernels for Single Image Defocus Deblurring](https://openaccess.thecvf.com/content/CVPR2023/html/Quan_Neumann_Network_With_Recursive_Kernels_for_Single_Image_Defocus_Deblurring_CVPR_2023_paper.html)

[Yuhui Quan](https://openaccess.thecvf.com/CVPR2023#), [Zicong Wu](https://openaccess.thecvf.com/CVPR2023#), [Hui Ji](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Quan_Neumann_Network_With_Recursive_Kernels_for_Single_Image_Defocus_Deblurring_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Quan_Neumann_Network_With_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Masked Image Training for Generalizable Deep Image Denoising](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_Masked_Image_Training_for_Generalizable_Deep_Image_Denoising_CVPR_2023_paper.html)

[Haoyu Chen](https://openaccess.thecvf.com/CVPR2023#), [Jinjin Gu](https://openaccess.thecvf.com/CVPR2023#), [Yihao Liu](https://openaccess.thecvf.com/CVPR2023#), [Salma Abdel Magid](https://openaccess.thecvf.com/CVPR2023#), [Chao Dong](https://openaccess.thecvf.com/CVPR2023#), [Qiong Wang](https://openaccess.thecvf.com/CVPR2023#), [Hanspeter Pfister](https://openaccess.thecvf.com/CVPR2023#), [Lei Zhu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_Masked_Image_Training_for_Generalizable_Deep_Image_Denoising_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chen_Masked_Image_Training_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.13132)] 

[bibtex]


[Zero-Shot Referring Image Segmentation With Global-Local Context Features](https://openaccess.thecvf.com/content/CVPR2023/html/Yu_Zero-Shot_Referring_Image_Segmentation_With_Global-Local_Context_Features_CVPR_2023_paper.html)

[Seonghoon Yu](https://openaccess.thecvf.com/CVPR2023#), [Paul Hongsuck Seo](https://openaccess.thecvf.com/CVPR2023#), [Jeany Son](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yu_Zero-Shot_Referring_Image_Segmentation_With_Global-Local_Context_Features_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Yu_Zero-Shot_Referring_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.17811)] 

[bibtex]


[RWSC-Fusion: Region-Wise Style-Controlled Fusion Network for the Prohibited X-Ray Security Image Synthesis](https://openaccess.thecvf.com/content/CVPR2023/html/Duan_RWSC-Fusion_Region-Wise_Style-Controlled_Fusion_Network_for_the_Prohibited_X-Ray_Security_CVPR_2023_paper.html)

[Luwen Duan](https://openaccess.thecvf.com/CVPR2023#), [Min Wu](https://openaccess.thecvf.com/CVPR2023#), [Lijian Mao](https://openaccess.thecvf.com/CVPR2023#), [Jun Yin](https://openaccess.thecvf.com/CVPR2023#), [Jianping Xiong](https://openaccess.thecvf.com/CVPR2023#), [Xi Li](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Duan_RWSC-Fusion_Region-Wise_Style-Controlled_Fusion_Network_for_the_Prohibited_X-Ray_Security_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Duan_RWSC-Fusion_Region-Wise_Style-Controlled_CVPR_2023_supplemental.pdf)] 

[bibtex]


[A2J-Transformer: Anchor-to-Joint Transformer Network for 3D Interacting Hand Pose Estimation From a Single RGB Image](https://openaccess.thecvf.com/content/CVPR2023/html/Jiang_A2J-Transformer_Anchor-to-Joint_Transformer_Network_for_3D_Interacting_Hand_Pose_Estimation_CVPR_2023_paper.html)

[Changlong Jiang](https://openaccess.thecvf.com/CVPR2023#), [Yang Xiao](https://openaccess.thecvf.com/CVPR2023#), [Cunlin Wu](https://openaccess.thecvf.com/CVPR2023#), [Mingyang Zhang](https://openaccess.thecvf.com/CVPR2023#), [Jinghong Zheng](https://openaccess.thecvf.com/CVPR2023#), [Zhiguo Cao](https://openaccess.thecvf.com/CVPR2023#), [Joey Tianyi Zhou](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_A2J-Transformer_Anchor-to-Joint_Transformer_Network_for_3D_Interacting_Hand_Pose_Estimation_CVPR_2023_paper.pdf)] 

[bibtex]


[Understanding Masked Image Modeling via Learning Occlusion Invariant Feature](https://openaccess.thecvf.com/content/CVPR2023/html/Kong_Understanding_Masked_Image_Modeling_via_Learning_Occlusion_Invariant_Feature_CVPR_2023_paper.html)

[Xiangwen Kong](https://openaccess.thecvf.com/CVPR2023#), [Xiangyu Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Kong_Understanding_Masked_Image_Modeling_via_Learning_Occlusion_Invariant_Feature_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Kong_Understanding_Masked_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2208.04164)] 

[bibtex]


[Grounding Counterfactual Explanation of Image Classifiers to Textual Concept Space](https://openaccess.thecvf.com/content/CVPR2023/html/Kim_Grounding_Counterfactual_Explanation_of_Image_Classifiers_to_Textual_Concept_Space_CVPR_2023_paper.html)

[Siwon Kim](https://openaccess.thecvf.com/CVPR2023#), [Jinoh Oh](https://openaccess.thecvf.com/CVPR2023#), [Sungjin Lee](https://openaccess.thecvf.com/CVPR2023#), [Seunghak Yu](https://openaccess.thecvf.com/CVPR2023#), [Jaeyoung Do](https://openaccess.thecvf.com/CVPR2023#), [Tara Taghavi](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Grounding_Counterfactual_Explanation_of_Image_Classifiers_to_Textual_Concept_Space_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Kim_Grounding_Counterfactual_Explanation_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Fair Federated Medical Image Segmentation via Client Contribution Estimation](https://openaccess.thecvf.com/content/CVPR2023/html/Jiang_Fair_Federated_Medical_Image_Segmentation_via_Client_Contribution_Estimation_CVPR_2023_paper.html)

[Meirui Jiang](https://openaccess.thecvf.com/CVPR2023#), [Holger R. Roth](https://openaccess.thecvf.com/CVPR2023#), [Wenqi Li](https://openaccess.thecvf.com/CVPR2023#), [Dong Yang](https://openaccess.thecvf.com/CVPR2023#), [Can Zhao](https://openaccess.thecvf.com/CVPR2023#), [Vishwesh Nath](https://openaccess.thecvf.com/CVPR2023#), [Daguang Xu](https://openaccess.thecvf.com/CVPR2023#), [Qi Dou](https://openaccess.thecvf.com/CVPR2023#), [Ziyue Xu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Jiang_Fair_Federated_Medical_Image_Segmentation_via_Client_Contribution_Estimation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Jiang_Fair_Federated_Medical_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.16520)] 

[bibtex]


[Spatio-Focal Bidirectional Disparity Estimation From a Dual-Pixel Image](https://openaccess.thecvf.com/content/CVPR2023/html/Kim_Spatio-Focal_Bidirectional_Disparity_Estimation_From_a_Dual-Pixel_Image_CVPR_2023_paper.html)

[Donggun Kim](https://openaccess.thecvf.com/CVPR2023#), [Hyeonjoong Jang](https://openaccess.thecvf.com/CVPR2023#), [Inchul Kim](https://openaccess.thecvf.com/CVPR2023#), [Min H. Kim](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Kim_Spatio-Focal_Bidirectional_Disparity_Estimation_From_a_Dual-Pixel_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Kim_Spatio-Focal_Bidirectional_Disparity_CVPR_2023_supplemental.pdf)] 

[bibtex]


[LEMaRT: Label-Efficient Masked Region Transform for Image Harmonization](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_LEMaRT_Label-Efficient_Masked_Region_Transform_for_Image_Harmonization_CVPR_2023_paper.html)

[Sheng Liu](https://openaccess.thecvf.com/CVPR2023#), [Cong Phuoc Huynh](https://openaccess.thecvf.com/CVPR2023#), [Cong Chen](https://openaccess.thecvf.com/CVPR2023#), [Maxim Arap](https://openaccess.thecvf.com/CVPR2023#), [Raffay Hamid](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_LEMaRT_Label-Efficient_Masked_Region_Transform_for_Image_Harmonization_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Liu_LEMaRT_Label-Efficient_Masked_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.13166)] 

[bibtex]


[Multi-Concept Customization of Text-to-Image Diffusion](https://openaccess.thecvf.com/content/CVPR2023/html/Kumari_Multi-Concept_Customization_of_Text-to-Image_Diffusion_CVPR_2023_paper.html)

[Nupur Kumari](https://openaccess.thecvf.com/CVPR2023#), [Bingliang Zhang](https://openaccess.thecvf.com/CVPR2023#), [Richard Zhang](https://openaccess.thecvf.com/CVPR2023#), [Eli Shechtman](https://openaccess.thecvf.com/CVPR2023#), [Jun-Yan Zhu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Kumari_Multi-Concept_Customization_of_Text-to-Image_Diffusion_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2212.04488)] 

[bibtex]


[InstructPix2Pix: Learning To Follow Image Editing Instructions](https://openaccess.thecvf.com/content/CVPR2023/html/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.html)

[Tim Brooks](https://openaccess.thecvf.com/CVPR2023#), [Aleksander Holynski](https://openaccess.thecvf.com/CVPR2023#), [Alexei A. Efros](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Brooks_InstructPix2Pix_Learning_To_Follow_Image_Editing_Instructions_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Brooks_InstructPix2Pix_Learning_To_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.09800)] 

[bibtex]


[Rethinking Video ViTs: Sparse Video Tubes for Joint Image and Video Learning](https://openaccess.thecvf.com/content/CVPR2023/html/Piergiovanni_Rethinking_Video_ViTs_Sparse_Video_Tubes_for_Joint_Image_and_CVPR_2023_paper.html)

[AJ Piergiovanni](https://openaccess.thecvf.com/CVPR2023#), [Weicheng Kuo](https://openaccess.thecvf.com/CVPR2023#), [Anelia Angelova](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Piergiovanni_Rethinking_Video_ViTs_Sparse_Video_Tubes_for_Joint_Image_and_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Piergiovanni_Rethinking_Video_ViTs_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.03229)] 

[bibtex]


[Crossing the Gap: Domain Generalization for Image Captioning](https://openaccess.thecvf.com/content/CVPR2023/html/Ren_Crossing_the_Gap_Domain_Generalization_for_Image_Captioning_CVPR_2023_paper.html)

[Yuchen Ren](https://openaccess.thecvf.com/CVPR2023#), [Zhendong Mao](https://openaccess.thecvf.com/CVPR2023#), [Shancheng Fang](https://openaccess.thecvf.com/CVPR2023#), [Yan Lu](https://openaccess.thecvf.com/CVPR2023#), [Tong He](https://openaccess.thecvf.com/CVPR2023#), [Hao Du](https://openaccess.thecvf.com/CVPR2023#), [Yongdong Zhang](https://openaccess.thecvf.com/CVPR2023#), [Wanli Ouyang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Ren_Crossing_the_Gap_Domain_Generalization_for_Image_Captioning_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Ren_Crossing_the_Gap_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Learned Image Compression With Mixed Transformer-CNN Architectures](https://openaccess.thecvf.com/content/CVPR2023/html/Liu_Learned_Image_Compression_With_Mixed_Transformer-CNN_Architectures_CVPR_2023_paper.html)

[Jinming Liu](https://openaccess.thecvf.com/CVPR2023#), [Heming Sun](https://openaccess.thecvf.com/CVPR2023#), [Jiro Katto](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_Learned_Image_Compression_With_Mixed_Transformer-CNN_Architectures_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Liu_Learned_Image_Compression_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.14978)] 

[bibtex]


[Exploring Intra-Class Variation Factors With Learnable Cluster Prompts for Semi-Supervised Image Synthesis](https://openaccess.thecvf.com/content/CVPR2023/html/Zhang_Exploring_Intra-Class_Variation_Factors_With_Learnable_Cluster_Prompts_for_Semi-Supervised_CVPR_2023_paper.html)

[Yunfei Zhang](https://openaccess.thecvf.com/CVPR2023#), [Xiaoyang Huo](https://openaccess.thecvf.com/CVPR2023#), [Tianyi Chen](https://openaccess.thecvf.com/CVPR2023#), [Si Wu](https://openaccess.thecvf.com/CVPR2023#), [Hau San Wong](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Exploring_Intra-Class_Variation_Factors_With_Learnable_Cluster_Prompts_for_Semi-Supervised_CVPR_2023_paper.pdf)] 

[bibtex]


[Local Implicit Normalizing Flow for Arbitrary-Scale Image Super-Resolution](https://openaccess.thecvf.com/content/CVPR2023/html/Yao_Local_Implicit_Normalizing_Flow_for_Arbitrary-Scale_Image_Super-Resolution_CVPR_2023_paper.html)

[Jie-En Yao](https://openaccess.thecvf.com/CVPR2023#), [Li-Yuan Tsao](https://openaccess.thecvf.com/CVPR2023#), [Yi-Chen Lo](https://openaccess.thecvf.com/CVPR2023#), [Roy Tseng](https://openaccess.thecvf.com/CVPR2023#), [Chia-Che Chang](https://openaccess.thecvf.com/CVPR2023#), [Chun-Yi Lee](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Yao_Local_Implicit_Normalizing_Flow_for_Arbitrary-Scale_Image_Super-Resolution_CVPR_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.05156)] 

[bibtex]


[Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and Text-to-Image Diffusion Models](https://openaccess.thecvf.com/content/CVPR2023/html/Xu_Dream3D_Zero-Shot_Text-to-3D_Synthesis_Using_3D_Shape_Prior_and_Text-to-Image_CVPR_2023_paper.html)

[Jiale Xu](https://openaccess.thecvf.com/CVPR2023#), [Xintao Wang](https://openaccess.thecvf.com/CVPR2023#), [Weihao Cheng](https://openaccess.thecvf.com/CVPR2023#), [Yan-Pei Cao](https://openaccess.thecvf.com/CVPR2023#), [Ying Shan](https://openaccess.thecvf.com/CVPR2023#), [Xiaohu Qie](https://openaccess.thecvf.com/CVPR2023#), [Shenghua Gao](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_Dream3D_Zero-Shot_Text-to-3D_Synthesis_Using_3D_Shape_Prior_and_Text-to-Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xu_Dream3D_Zero-Shot_Text-to-3D_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.14704)] 

[bibtex]


[DINN360: Deformable Invertible Neural Network for Latitude-Aware 360deg Image Rescaling](https://openaccess.thecvf.com/content/CVPR2023/html/Guo_DINN360_Deformable_Invertible_Neural_Network_for_Latitude-Aware_360deg_Image_Rescaling_CVPR_2023_paper.html)

[Yichen Guo](https://openaccess.thecvf.com/CVPR2023#), [Mai Xu](https://openaccess.thecvf.com/CVPR2023#), [Lai Jiang](https://openaccess.thecvf.com/CVPR2023#), [Leonid Sigal](https://openaccess.thecvf.com/CVPR2023#), [Yunjin Chen](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Guo_DINN360_Deformable_Invertible_Neural_Network_for_Latitude-Aware_360deg_Image_Rescaling_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Guo_DINN360_Deformable_Invertible_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Texts as Images in Prompt Tuning for Multi-Label Image Recognition](https://openaccess.thecvf.com/content/CVPR2023/html/Guo_Texts_as_Images_in_Prompt_Tuning_for_Multi-Label_Image_Recognition_CVPR_2023_paper.html)

[Zixian Guo](https://openaccess.thecvf.com/CVPR2023#), [Bowen Dong](https://openaccess.thecvf.com/CVPR2023#), [Zhilong Ji](https://openaccess.thecvf.com/CVPR2023#), [Jinfeng Bai](https://openaccess.thecvf.com/CVPR2023#), [Yiwen Guo](https://openaccess.thecvf.com/CVPR2023#), [Wangmeng Zuo](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Guo_Texts_as_Images_in_Prompt_Tuning_for_Multi-Label_Image_Recognition_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Guo_Texts_as_Images_CVPR_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2211.12739)] 

[bibtex]


[Learning Detailed Radiance Manifolds for High-Fidelity and 3D-Consistent Portrait Synthesis From Monocular Image](https://openaccess.thecvf.com/content/CVPR2023/html/Deng_Learning_Detailed_Radiance_Manifolds_for_High-Fidelity_and_3D-Consistent_Portrait_Synthesis_CVPR_2023_paper.html)

[Yu Deng](https://openaccess.thecvf.com/CVPR2023#), [Baoyuan Wang](https://openaccess.thecvf.com/CVPR2023#), [Heung-Yeung Shum](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Deng_Learning_Detailed_Radiance_Manifolds_for_High-Fidelity_and_3D-Consistent_Portrait_Synthesis_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Deng_Learning_Detailed_Radiance_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.13901)] 

[bibtex]


[Patch-Craft Self-Supervised Training for Correlated Image Denoising](https://openaccess.thecvf.com/content/CVPR2023/html/Vaksman_Patch-Craft_Self-Supervised_Training_for_Correlated_Image_Denoising_CVPR_2023_paper.html)

[Gregory Vaksman](https://openaccess.thecvf.com/CVPR2023#), [Michael Elad](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Vaksman_Patch-Craft_Self-Supervised_Training_for_Correlated_Image_Denoising_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Vaksman_Patch-Craft_Self-Supervised_Training_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.09919)] 

[bibtex]


[Quantitative Manipulation of Custom Attributes on 3D-Aware Image Synthesis](https://openaccess.thecvf.com/content/CVPR2023/html/Do_Quantitative_Manipulation_of_Custom_Attributes_on_3D-Aware_Image_Synthesis_CVPR_2023_paper.html)

[Hoseok Do](https://openaccess.thecvf.com/CVPR2023#), [EunKyung Yoo](https://openaccess.thecvf.com/CVPR2023#), [Taehyeong Kim](https://openaccess.thecvf.com/CVPR2023#), [Chul Lee](https://openaccess.thecvf.com/CVPR2023#), [Jin Young Choi](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Do_Quantitative_Manipulation_of_Custom_Attributes_on_3D-Aware_Image_Synthesis_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Do_Quantitative_Manipulation_of_CVPR_2023_supplemental.zip)] 

[bibtex]


[Cross-Image-Attention for Conditional Embeddings in Deep Metric Learning](https://openaccess.thecvf.com/content/CVPR2023/html/Kotovenko_Cross-Image-Attention_for_Conditional_Embeddings_in_Deep_Metric_Learning_CVPR_2023_paper.html)

[Dmytro Kotovenko](https://openaccess.thecvf.com/CVPR2023#), [Pingchuan Ma](https://openaccess.thecvf.com/CVPR2023#), [Timo Milbich](https://openaccess.thecvf.com/CVPR2023#), [Björn Ommer](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Kotovenko_Cross-Image-Attention_for_Conditional_Embeddings_in_Deep_Metric_Learning_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Kotovenko_Cross-Image-Attention_for_Conditional_CVPR_2023_supplemental.pdf)] 

[bibtex]


[PiMAE: Point Cloud and Image Interactive Masked Autoencoders for 3D Object Detection](https://openaccess.thecvf.com/content/CVPR2023/html/Chen_PiMAE_Point_Cloud_and_Image_Interactive_Masked_Autoencoders_for_3D_CVPR_2023_paper.html)

[Anthony Chen](https://openaccess.thecvf.com/CVPR2023#), [Kevin Zhang](https://openaccess.thecvf.com/CVPR2023#), [Renrui Zhang](https://openaccess.thecvf.com/CVPR2023#), [Zihan Wang](https://openaccess.thecvf.com/CVPR2023#), [Yuheng Lu](https://openaccess.thecvf.com/CVPR2023#), [Yandong Guo](https://openaccess.thecvf.com/CVPR2023#), [Shanghang Zhang](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_PiMAE_Point_Cloud_and_Image_Interactive_Masked_Autoencoders_for_3D_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Chen_PiMAE_Point_Cloud_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.08129)] 

[bibtex]


[Single Image Backdoor Inversion via Robust Smoothed Classifiers](https://openaccess.thecvf.com/content/CVPR2023/html/Sun_Single_Image_Backdoor_Inversion_via_Robust_Smoothed_Classifiers_CVPR_2023_paper.html)

[Mingjie Sun](https://openaccess.thecvf.com/CVPR2023#), [Zico Kolter](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Sun_Single_Image_Backdoor_Inversion_via_Robust_Smoothed_Classifiers_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Sun_Single_Image_Backdoor_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.00215)] 

[bibtex]


[Parameter Efficient Local Implicit Image Function Network for Face Segmentation](https://openaccess.thecvf.com/content/CVPR2023/html/Sarkar_Parameter_Efficient_Local_Implicit_Image_Function_Network_for_Face_Segmentation_CVPR_2023_paper.html)

[Mausoom Sarkar](https://openaccess.thecvf.com/CVPR2023#), [Nikitha SR](https://openaccess.thecvf.com/CVPR2023#), [Mayur Hemani](https://openaccess.thecvf.com/CVPR2023#), [Rishabh Jain](https://openaccess.thecvf.com/CVPR2023#), [Balaji Krishnamurthy](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Sarkar_Parameter_Efficient_Local_Implicit_Image_Function_Network_for_Face_Segmentation_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Sarkar_Parameter_Efficient_Local_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.15122)] 

[bibtex]


[Referring Image Matting](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Referring_Image_Matting_CVPR_2023_paper.html)

[Jizhizi Li](https://openaccess.thecvf.com/CVPR2023#), [Jing Zhang](https://openaccess.thecvf.com/CVPR2023#), [Dacheng Tao](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Referring_Image_Matting_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_Referring_Image_Matting_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2206.05149)] 

[bibtex]


[Towards a Smaller Student: Capacity Dynamic Distillation for Efficient Image Retrieval](https://openaccess.thecvf.com/content/CVPR2023/html/Xie_Towards_a_Smaller_Student_Capacity_Dynamic_Distillation_for_Efficient_Image_CVPR_2023_paper.html)

[Yi Xie](https://openaccess.thecvf.com/CVPR2023#), [Huaidong Zhang](https://openaccess.thecvf.com/CVPR2023#), [Xuemiao Xu](https://openaccess.thecvf.com/CVPR2023#), [Jianqing Zhu](https://openaccess.thecvf.com/CVPR2023#), [Shengfeng He](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Xie_Towards_a_Smaller_Student_Capacity_Dynamic_Distillation_for_Efficient_Image_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Xie_Towards_a_Smaller_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.09230)] 

[bibtex]


[Pseudo-Label Guided Contrastive Learning for Semi-Supervised Medical Image Segmentation](https://openaccess.thecvf.com/content/CVPR2023/html/Basak_Pseudo-Label_Guided_Contrastive_Learning_for_Semi-Supervised_Medical_Image_Segmentation_CVPR_2023_paper.html)

[Hritam Basak](https://openaccess.thecvf.com/CVPR2023#), [Zhaozheng Yin](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Basak_Pseudo-Label_Guided_Contrastive_Learning_for_Semi-Supervised_Medical_Image_Segmentation_CVPR_2023_paper.pdf)] 

[bibtex]


[PC2: Projection-Conditioned Point Cloud Diffusion for Single-Image 3D Reconstruction](https://openaccess.thecvf.com/content/CVPR2023/html/Melas-Kyriazi_PC2_Projection-Conditioned_Point_Cloud_Diffusion_for_Single-Image_3D_Reconstruction_CVPR_2023_paper.html)

[Luke Melas-Kyriazi](https://openaccess.thecvf.com/CVPR2023#), [Christian Rupprecht](https://openaccess.thecvf.com/CVPR2023#), [Andrea Vedaldi](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Melas-Kyriazi_PC2_Projection-Conditioned_Point_Cloud_Diffusion_for_Single-Image_3D_Reconstruction_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Melas-Kyriazi_PC2_Projection-Conditioned_Point_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Polarized Color Image Denoising](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Polarized_Color_Image_Denoising_CVPR_2023_paper.html)

[Zhuoxiao Li](https://openaccess.thecvf.com/CVPR2023#), [Haiyang Jiang](https://openaccess.thecvf.com/CVPR2023#), [Mingdeng Cao](https://openaccess.thecvf.com/CVPR2023#), [Yinqiang Zheng](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Polarized_Color_Image_Denoising_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_Polarized_Color_Image_CVPR_2023_supplemental.pdf)] 

[bibtex]


[Non-Contrastive Learning Meets Language-Image Pre-Training](https://openaccess.thecvf.com/content/CVPR2023/html/Zhou_Non-Contrastive_Learning_Meets_Language-Image_Pre-Training_CVPR_2023_paper.html)

[Jinghao Zhou](https://openaccess.thecvf.com/CVPR2023#), [Li Dong](https://openaccess.thecvf.com/CVPR2023#), [Zhe Gan](https://openaccess.thecvf.com/CVPR2023#), [Lijuan Wang](https://openaccess.thecvf.com/CVPR2023#), [Furu Wei](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Zhou_Non-Contrastive_Learning_Meets_Language-Image_Pre-Training_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zhou_Non-Contrastive_Learning_Meets_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2210.09304)] 

[bibtex]


[Improving Vision-and-Language Navigation by Generating Future-View Image Semantics](https://openaccess.thecvf.com/content/CVPR2023/html/Li_Improving_Vision-and-Language_Navigation_by_Generating_Future-View_Image_Semantics_CVPR_2023_paper.html)

[Jialu Li](https://openaccess.thecvf.com/CVPR2023#), [Mohit Bansal](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Li_Improving_Vision-and-Language_Navigation_by_Generating_Future-View_Image_Semantics_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Li_Improving_Vision-and-Language_Navigation_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.04907)] 

[bibtex]

[Hierarchical Fine-Grained Image Forgery Detection and Localization](https://openaccess.thecvf.com/content/CVPR2023/html/Guo_Hierarchical_Fine-Grained_Image_Forgery_Detection_and_Localization_CVPR_2023_paper.html)

[Xiao Guo](https://openaccess.thecvf.com/CVPR2023#), [Xiaohong Liu](https://openaccess.thecvf.com/CVPR2023#), [Zhiyuan Ren](https://openaccess.thecvf.com/CVPR2023#), [Steven Grosz](https://openaccess.thecvf.com/CVPR2023#), [Iacopo Masi](https://openaccess.thecvf.com/CVPR2023#), [Xiaoming Liu](https://openaccess.thecvf.com/CVPR2023#)

[[pdf](https://openaccess.thecvf.com/content/CVPR2023/papers/Guo_Hierarchical_Fine-Grained_Image_Forgery_Detection_and_Localization_CVPR_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/CVPR2023/supplemental/Guo_Hierarchical_Fine-Grained_Image_CVPR_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.17111)] 

[bibtex]

#####计算机视觉国际大会

ICCV

[Diff-Retinex: Rethinking Low-light Image Enhancement with A Generative Diffusion Model](https://openaccess.thecvf.com/content/ICCV2023/html/Yi_Diff-Retinex_Rethinking_Low-light_Image_Enhancement_with_A_Generative_Diffusion_Model_ICCV_2023_paper.html)

[Xunpeng Yi](https://openaccess.thecvf.com/ICCV2023#), [Han Xu](https://openaccess.thecvf.com/ICCV2023#), [Hao Zhang](https://openaccess.thecvf.com/ICCV2023#), [Linfeng Tang](https://openaccess.thecvf.com/ICCV2023#), [Jiayi Ma](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yi_Diff-Retinex_Rethinking_Low-light_Image_Enhancement_with_A_Generative_Diffusion_Model_ICCV_2023_paper.pdf)] 

[bibtex]


[ExposureDiffusion: Learning to Expose for Low-light Image Enhancement](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_ExposureDiffusion_Learning_to_Expose_for_Low-light_Image_Enhancement_ICCV_2023_paper.html)

[Yufei Wang](https://openaccess.thecvf.com/ICCV2023#), [Yi Yu](https://openaccess.thecvf.com/ICCV2023#), [Wenhan Yang](https://openaccess.thecvf.com/ICCV2023#), [Lanqing Guo](https://openaccess.thecvf.com/ICCV2023#), [Lap-Pui Chau](https://openaccess.thecvf.com/ICCV2023#), [Alex C. Kot](https://openaccess.thecvf.com/ICCV2023#), [Bihan Wen](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_ExposureDiffusion_Learning_to_Expose_for_Low-light_Image_Enhancement_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_ExposureDiffusion_Learning_to_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.07710)] 

[bibtex]


[Occ^2Net: Robust Image Matching Based on 3D Occupancy Estimation for Occluded Regions](https://openaccess.thecvf.com/content/ICCV2023/html/Fan_Occ2Net_Robust_Image_Matching_Based_on_3D_Occupancy_Estimation_for_ICCV_2023_paper.html)

[Miao Fan](https://openaccess.thecvf.com/ICCV2023#), [Mingrui Chen](https://openaccess.thecvf.com/ICCV2023#), [Chen Hu](https://openaccess.thecvf.com/ICCV2023#), [Shuchang Zhou](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fan_Occ2Net_Robust_Image_Matching_Based_on_3D_Occupancy_Estimation_for_ICCV_2023_paper.pdf)] 

[bibtex]


[Rickrolling the Artist: Injecting Backdoors into Text Encoders for Text-to-Image Synthesis](https://openaccess.thecvf.com/content/ICCV2023/html/Struppek_Rickrolling_the_Artist_Injecting_Backdoors_into_Text_Encoders_for_Text-to-Image_ICCV_2023_paper.html)

[Lukas Struppek](https://openaccess.thecvf.com/ICCV2023#), [Dominik Hintersdorf](https://openaccess.thecvf.com/ICCV2023#), [Kristian Kersting](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Struppek_Rickrolling_the_Artist_Injecting_Backdoors_into_Text_Encoders_for_Text-to-Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Struppek_Rickrolling_the_Artist_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.02408)] 

[bibtex]


[LD-ZNet: A Latent Diffusion Approach for Text-Based Image Segmentation](https://openaccess.thecvf.com/content/ICCV2023/html/PNVR_LD-ZNet_A_Latent_Diffusion_Approach_for_Text-Based_Image_Segmentation_ICCV_2023_paper.html)

[Koutilya PNVR](https://openaccess.thecvf.com/ICCV2023#), [Bharat Singh](https://openaccess.thecvf.com/ICCV2023#), [Pallabi Ghosh](https://openaccess.thecvf.com/ICCV2023#), [Behjat Siddiquie](https://openaccess.thecvf.com/ICCV2023#), [David Jacobs](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/PNVR_LD-ZNet_A_Latent_Diffusion_Approach_for_Text-Based_Image_Segmentation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/PNVR_LD-ZNet_A_Latent_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Effective Real Image Editing with Accelerated Iterative Diffusion Inversion](https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.html)

[Zhihong Pan](https://openaccess.thecvf.com/ICCV2023#), [Riccardo Gherardi](https://openaccess.thecvf.com/ICCV2023#), [Xiufeng Xie](https://openaccess.thecvf.com/ICCV2023#), [Stephen Huang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Effective_Real_Image_Editing_with_Accelerated_Iterative_Diffusion_Inversion_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pan_Effective_Real_Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.04907)] 

[bibtex]


[Chinese Text Recognition with A Pre-Trained CLIP-Like Model Through Image-IDS Aligning](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Chinese_Text_Recognition_with_A_Pre-Trained_CLIP-Like_Model_Through_Image-IDS_ICCV_2023_paper.html)

[Haiyang Yu](https://openaccess.thecvf.com/ICCV2023#), [Xiaocong Wang](https://openaccess.thecvf.com/ICCV2023#), [Bin Li](https://openaccess.thecvf.com/ICCV2023#), [Xiangyang Xue](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Chinese_Text_Recognition_with_A_Pre-Trained_CLIP-Like_Model_Through_Image-IDS_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yu_Chinese_Text_Recognition_with_A_Pre-Trained_CLIP-Like_Model_Through_Image-IDS_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.01083)] 

[bibtex]


[LinkGAN: Linking GAN Latents to Pixels for Controllable Image Synthesis](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_LinkGAN_Linking_GAN_Latents_to_Pixels_for_Controllable_Image_Synthesis_ICCV_2023_paper.html)

[Jiapeng Zhu](https://openaccess.thecvf.com/ICCV2023#), [Ceyuan Yang](https://openaccess.thecvf.com/ICCV2023#), [Yujun Shen](https://openaccess.thecvf.com/ICCV2023#), [Zifan Shi](https://openaccess.thecvf.com/ICCV2023#), [Bo Dai](https://openaccess.thecvf.com/ICCV2023#), [Deli Zhao](https://openaccess.thecvf.com/ICCV2023#), [Qifeng Chen](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_LinkGAN_Linking_GAN_Latents_to_Pixels_for_Controllable_Image_Synthesis_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_LinkGAN_Linking_GAN_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2301.04604)] 

[bibtex]


[Hierarchical Contrastive Learning for Pattern-Generalizable Image Corruption Detection](https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Hierarchical_Contrastive_Learning_for_Pattern-Generalizable_Image_Corruption_Detection_ICCV_2023_paper.html)

[Xin Feng](https://openaccess.thecvf.com/ICCV2023#), [Yifeng Xu](https://openaccess.thecvf.com/ICCV2023#), [Guangming Lu](https://openaccess.thecvf.com/ICCV2023#), [Wenjie Pei](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Hierarchical_Contrastive_Learning_for_Pattern-Generalizable_Image_Corruption_Detection_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Feng_Hierarchical_Contrastive_Learning_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.14061)] 

[bibtex]


[What do neural networks learn in image classification? A frequency shortcut perspective](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_What_do_neural_networks_learn_in_image_classification_A_frequency_ICCV_2023_paper.html)

[Shunxin Wang](https://openaccess.thecvf.com/ICCV2023#), [Raymond Veldhuis](https://openaccess.thecvf.com/ICCV2023#), [Christoph Brune](https://openaccess.thecvf.com/ICCV2023#), [Nicola Strisciuglio](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_What_do_neural_networks_learn_in_image_classification_A_frequency_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_What_do_neural_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.09829)] 

[bibtex]


[Sigmoid Loss for Language Image Pre-Training](https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Sigmoid_Loss_for_Language_Image_Pre-Training_ICCV_2023_paper.html)

[Xiaohua Zhai](https://openaccess.thecvf.com/ICCV2023#), [Basil Mustafa](https://openaccess.thecvf.com/ICCV2023#), [Alexander Kolesnikov](https://openaccess.thecvf.com/ICCV2023#), [Lucas Beyer](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Sigmoid_Loss_for_Language_Image_Pre-Training_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhai_Sigmoid_Loss_for_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.15343)] 

[bibtex]


[PromptCap: Prompt-Guided Image Captioning for VQA with GPT-3](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_PromptCap_Prompt-Guided_Image_Captioning_for_VQA_with_GPT-3_ICCV_2023_paper.html)

[Yushi Hu](https://openaccess.thecvf.com/ICCV2023#), [Hang Hua](https://openaccess.thecvf.com/ICCV2023#), [Zhengyuan Yang](https://openaccess.thecvf.com/ICCV2023#), [Weijia Shi](https://openaccess.thecvf.com/ICCV2023#), [Noah A. Smith](https://openaccess.thecvf.com/ICCV2023#), [Jiebo Luo](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_PromptCap_Prompt-Guided_Image_Captioning_for_VQA_with_GPT-3_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_PromptCap_Prompt-Guided_Image_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Towards Generic Image Manipulation Detection with Weakly-Supervised Self-Consistency Learning](https://openaccess.thecvf.com/content/ICCV2023/html/Zhai_Towards_Generic_Image_Manipulation_Detection_with_Weakly-Supervised_Self-Consistency_Learning_ICCV_2023_paper.html)

[Yuanhao Zhai](https://openaccess.thecvf.com/ICCV2023#), [Tianyu Luan](https://openaccess.thecvf.com/ICCV2023#), [David Doermann](https://openaccess.thecvf.com/ICCV2023#), [Junsong Yuan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhai_Towards_Generic_Image_Manipulation_Detection_with_Weakly-Supervised_Self-Consistency_Learning_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhai_Towards_Generic_Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.01246)] 

[bibtex]


[Multiple Instance Learning Framework with Masked Hard Instance Mining for Whole Slide Image Classification](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_ICCV_2023_paper.html)

[Wenhao Tang](https://openaccess.thecvf.com/ICCV2023#), [Sheng Huang](https://openaccess.thecvf.com/ICCV2023#), [Xiaoxian Zhang](https://openaccess.thecvf.com/ICCV2023#), [Fengtao Zhou](https://openaccess.thecvf.com/ICCV2023#), [Yi Zhang](https://openaccess.thecvf.com/ICCV2023#), [Bo Liu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Multiple_Instance_Learning_Framework_with_Masked_Hard_Instance_Mining_for_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tang_Multiple_Instance_Learning_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.15254)] 

[bibtex]


[Unsupervised Compositional Concepts Discovery with Text-to-Image Generative Models](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Unsupervised_Compositional_Concepts_Discovery_with_Text-to-Image_Generative_Models_ICCV_2023_paper.html)

[Nan Liu](https://openaccess.thecvf.com/ICCV2023#), [Yilun Du](https://openaccess.thecvf.com/ICCV2023#), [Shuang Li](https://openaccess.thecvf.com/ICCV2023#), [Joshua B. Tenenbaum](https://openaccess.thecvf.com/ICCV2023#), [Antonio Torralba](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Unsupervised_Compositional_Concepts_Discovery_with_Text-to-Image_Generative_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Unsupervised_Compositional_Concepts_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2306.05357)] 

[bibtex]


[Learning Spatial-context-aware Global Visual Feature Representation for Instance Image Retrieval](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Learning_Spatial-context-aware_Global_Visual_Feature_Representation_for_Instance_Image_Retrieval_ICCV_2023_paper.html)

[Zhongyan Zhang](https://openaccess.thecvf.com/ICCV2023#), [Lei Wang](https://openaccess.thecvf.com/ICCV2023#), [Luping Zhou](https://openaccess.thecvf.com/ICCV2023#), [Piotr Koniusz](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Learning_Spatial-context-aware_Global_Visual_Feature_Representation_for_Instance_Image_Retrieval_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Learning_Spatial-context-aware_Global_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Cross-modal Latent Space Alignment for Image to Avatar Translation](https://openaccess.thecvf.com/content/ICCV2023/html/de_Guevara_Cross-modal_Latent_Space_Alignment_for_Image_to_Avatar_Translation_ICCV_2023_paper.html)

[Manuel Ladron de Guevara](https://openaccess.thecvf.com/ICCV2023#), [Jose Echevarria](https://openaccess.thecvf.com/ICCV2023#), [Yijun Li](https://openaccess.thecvf.com/ICCV2023#), [Yannick Hold-Geoffroy](https://openaccess.thecvf.com/ICCV2023#), [Cameron Smith](https://openaccess.thecvf.com/ICCV2023#), [Daichi Ito](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/de_Guevara_Cross-modal_Latent_Space_Alignment_for_Image_to_Avatar_Translation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/de_Guevara_Cross-modal_Latent_Space_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Inspecting the Geographical Representativeness of Images from Text-to-Image Models](https://openaccess.thecvf.com/content/ICCV2023/html/Basu_Inspecting_the_Geographical_Representativeness_of_Images_from_Text-to-Image_Models_ICCV_2023_paper.html)

[Abhipsa Basu](https://openaccess.thecvf.com/ICCV2023#), [R. Venkatesh Babu](https://openaccess.thecvf.com/ICCV2023#), [Danish Pruthi](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Basu_Inspecting_the_Geographical_Representativeness_of_Images_from_Text-to-Image_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Basu_Inspecting_the_Geographical_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2305.11080)] 

[bibtex]


[Multimodal Garment Designer: Human-Centric Latent Diffusion Models for Fashion Image Editing](https://openaccess.thecvf.com/content/ICCV2023/html/Baldrati_Multimodal_Garment_Designer_Human-Centric_Latent_Diffusion_Models_for_Fashion_Image_ICCV_2023_paper.html)

[Alberto Baldrati](https://openaccess.thecvf.com/ICCV2023#), [Davide Morelli](https://openaccess.thecvf.com/ICCV2023#), [Giuseppe Cartella](https://openaccess.thecvf.com/ICCV2023#), [Marcella Cornia](https://openaccess.thecvf.com/ICCV2023#), [Marco Bertini](https://openaccess.thecvf.com/ICCV2023#), [Rita Cucchiara](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Baldrati_Multimodal_Garment_Designer_Human-Centric_Latent_Diffusion_Models_for_Fashion_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Baldrati_Multimodal_Garment_Designer_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.02051)] 

[bibtex]


[A Benchmark for Chinese-English Scene Text Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_A_Benchmark_for_Chinese-English_Scene_Text_Image_Super-Resolution_ICCV_2023_paper.html)

[Jianqi Ma](https://openaccess.thecvf.com/ICCV2023#), [Zhetong Liang](https://openaccess.thecvf.com/ICCV2023#), [Wangmeng Xiang](https://openaccess.thecvf.com/ICCV2023#), [Xi Yang](https://openaccess.thecvf.com/ICCV2023#), [Lei Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_A_Benchmark_for_Chinese-English_Scene_Text_Image_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ma_A_Benchmark_for_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.03262)] 

[bibtex]


[HSR-Diff: Hyperspectral Image Super-Resolution via Conditional Diffusion Models](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_HSR-Diff_Hyperspectral_Image_Super-Resolution_via_Conditional_Diffusion_Models_ICCV_2023_paper.html)

[Chanyue Wu](https://openaccess.thecvf.com/ICCV2023#), [Dong Wang](https://openaccess.thecvf.com/ICCV2023#), [Yunpeng Bai](https://openaccess.thecvf.com/ICCV2023#), [Hanyu Mao](https://openaccess.thecvf.com/ICCV2023#), [Ying Li](https://openaccess.thecvf.com/ICCV2023#), [Qiang Shen](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_HSR-Diff_Hyperspectral_Image_Super-Resolution_via_Conditional_Diffusion_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_HSR-Diff_Hyperspectral_Image_ICCV_2023_supplemental.pdf)] 

[bibtex]


[LexLIP: Lexicon-Bottlenecked Language-Image Pre-Training for Large-Scale Image-Text Sparse Retrieval](https://openaccess.thecvf.com/content/ICCV2023/html/Luo_LexLIP_Lexicon-Bottlenecked_Language-Image_Pre-Training_for_Large-Scale_Image-Text_Sparse_Retrieval_ICCV_2023_paper.html)

[Ziyang Luo](https://openaccess.thecvf.com/ICCV2023#), [Pu Zhao](https://openaccess.thecvf.com/ICCV2023#), [Can Xu](https://openaccess.thecvf.com/ICCV2023#), [Xiubo Geng](https://openaccess.thecvf.com/ICCV2023#), [Tao Shen](https://openaccess.thecvf.com/ICCV2023#), [Chongyang Tao](https://openaccess.thecvf.com/ICCV2023#), [Jing Ma](https://openaccess.thecvf.com/ICCV2023#), [Qingwei Lin](https://openaccess.thecvf.com/ICCV2023#), [Daxin Jiang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Luo_LexLIP_Lexicon-Bottlenecked_Language-Image_Pre-Training_for_Large-Scale_Image-Text_Sparse_Retrieval_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Luo_LexLIP_Lexicon-Bottlenecked_Language-Image_ICCV_2023_supplemental.pdf)] 

[bibtex]


[LFS-GAN: Lifelong Few-Shot Image Generation](https://openaccess.thecvf.com/content/ICCV2023/html/Seo_LFS-GAN_Lifelong_Few-Shot_Image_Generation_ICCV_2023_paper.html)

[Juwon Seo](https://openaccess.thecvf.com/ICCV2023#), [Ji-Su Kang](https://openaccess.thecvf.com/ICCV2023#), [Gyeong-Moon Park](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Seo_LFS-GAN_Lifelong_Few-Shot_Image_Generation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Seo_LFS-GAN_Lifelong_Few-Shot_ICCV_2023_supplemental.pdf)] 

[bibtex]


[MedKLIP: Medical Knowledge Enhanced Language-Image Pre-Training for X-ray Diagnosis](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_MedKLIP_Medical_Knowledge_Enhanced_Language-Image_Pre-Training_for_X-ray_Diagnosis_ICCV_2023_paper.html)

[Chaoyi Wu](https://openaccess.thecvf.com/ICCV2023#), [Xiaoman Zhang](https://openaccess.thecvf.com/ICCV2023#), [Ya Zhang](https://openaccess.thecvf.com/ICCV2023#), [Yanfeng Wang](https://openaccess.thecvf.com/ICCV2023#), [Weidi Xie](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_MedKLIP_Medical_Knowledge_Enhanced_Language-Image_Pre-Training_for_X-ray_Diagnosis_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_MedKLIP_Medical_Knowledge_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Text-Conditioned Sampling Framework for Text-to-Image Generation with Masked Generative Models](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Text-Conditioned_Sampling_Framework_for_Text-to-Image_Generation_with_Masked_Generative_Models_ICCV_2023_paper.html)

[Jaewoong Lee](https://openaccess.thecvf.com/ICCV2023#), [Sangwon Jang](https://openaccess.thecvf.com/ICCV2023#), [Jaehyeong Jo](https://openaccess.thecvf.com/ICCV2023#), [Jaehong Yoon](https://openaccess.thecvf.com/ICCV2023#), [Yunji Kim](https://openaccess.thecvf.com/ICCV2023#), [Jin-Hwa Kim](https://openaccess.thecvf.com/ICCV2023#), [Jung-Woo Ha](https://openaccess.thecvf.com/ICCV2023#), [Sung Ju Hwang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Text-Conditioned_Sampling_Framework_for_Text-to-Image_Generation_with_Masked_Generative_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Text-Conditioned_Sampling_Framework_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.01515)] 

[bibtex]


[Learning Image-Adaptive Codebooks for Class-Agnostic Image Restoration](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Learning_Image-Adaptive_Codebooks_for_Class-Agnostic_Image_Restoration_ICCV_2023_paper.html)

[Kechun Liu](https://openaccess.thecvf.com/ICCV2023#), [Yitong Jiang](https://openaccess.thecvf.com/ICCV2023#), [Inchang Choi](https://openaccess.thecvf.com/ICCV2023#), [Jinwei Gu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Learning_Image-Adaptive_Codebooks_for_Class-Agnostic_Image_Restoration_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Learning_Image-Adaptive_Codebooks_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2306.06513)] 

[bibtex]


[Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Zero-Shot_Contrastive_Loss_for_Text-Guided_Diffusion_Image_Style_Transfer_ICCV_2023_paper.html)

[Serin Yang](https://openaccess.thecvf.com/ICCV2023#), [Hyunmin Hwang](https://openaccess.thecvf.com/ICCV2023#), [Jong Chul Ye](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Zero-Shot_Contrastive_Loss_for_Text-Guided_Diffusion_Image_Style_Transfer_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Zero-Shot_Contrastive_Loss_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.08622)] 

[bibtex]


[Low-Light Image Enhancement with Illumination-Aware Gamma Correction and Complete Image Modelling Network](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Low-Light_Image_Enhancement_with_Illumination-Aware_Gamma_Correction_and_Complete_Image_ICCV_2023_paper.html)

[Yinglong Wang](https://openaccess.thecvf.com/ICCV2023#), [Zhen Liu](https://openaccess.thecvf.com/ICCV2023#), [Jianzhuang Liu](https://openaccess.thecvf.com/ICCV2023#), [Songcen Xu](https://openaccess.thecvf.com/ICCV2023#), [Shuaicheng Liu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Low-Light_Image_Enhancement_with_Illumination-Aware_Gamma_Correction_and_Complete_Image_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2308.08220)] 

[bibtex]


[Both Diverse and Realism Matter: Physical Attribute and Style Alignment for Rainy Image Generation](https://openaccess.thecvf.com/content/ICCV2023/html/Yu_Both_Diverse_and_Realism_Matter_Physical_Attribute_and_Style_Alignment_ICCV_2023_paper.html)

[Changfeng Yu](https://openaccess.thecvf.com/ICCV2023#), [Shiming Chen](https://openaccess.thecvf.com/ICCV2023#), [Yi Chang](https://openaccess.thecvf.com/ICCV2023#), [Yibing Song](https://openaccess.thecvf.com/ICCV2023#), [Luxin Yan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yu_Both_Diverse_and_Realism_Matter_Physical_Attribute_and_Style_Alignment_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yu_Both_Diverse_and_ICCV_2023_supplemental.zip)] 

[bibtex]


[Single Image Reflection Separation via Component Synergy](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Single_Image_Reflection_Separation_via_Component_Synergy_ICCV_2023_paper.html)

[Qiming Hu](https://openaccess.thecvf.com/ICCV2023#), [Xiaojie Guo](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Single_Image_Reflection_Separation_via_Component_Synergy_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_Single_Image_Reflection_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.10027)] 

[bibtex]


[3D-Aware Generative Model for Improved Side-View Image Synthesis](https://openaccess.thecvf.com/content/ICCV2023/html/Jo_3D-Aware_Generative_Model_for_Improved_Side-View_Image_Synthesis_ICCV_2023_paper.html)

[Kyungmin Jo](https://openaccess.thecvf.com/ICCV2023#), [Wonjoon Jin](https://openaccess.thecvf.com/ICCV2023#), [Jaegul Choo](https://openaccess.thecvf.com/ICCV2023#), [Hyunjoon Lee](https://openaccess.thecvf.com/ICCV2023#), [Sunghyun Cho](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jo_3D-Aware_Generative_Model_for_Improved_Side-View_Image_Synthesis_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jo_3D-Aware_Generative_Model_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2309.10388)] 

[bibtex]


[Parallax-Tolerant Unsupervised Deep Image Stitching](https://openaccess.thecvf.com/content/ICCV2023/html/Nie_Parallax-Tolerant_Unsupervised_Deep_Image_Stitching_ICCV_2023_paper.html)

[Lang Nie](https://openaccess.thecvf.com/ICCV2023#), [Chunyu Lin](https://openaccess.thecvf.com/ICCV2023#), [Kang Liao](https://openaccess.thecvf.com/ICCV2023#), [Shuaicheng Liu](https://openaccess.thecvf.com/ICCV2023#), [Yao Zhao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nie_Parallax-Tolerant_Unsupervised_Deep_Image_Stitching_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nie_Parallax-Tolerant_Unsupervised_Deep_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.08207)] 

[bibtex]


[Rethinking Fast Fourier Convolution in Image Inpainting](https://openaccess.thecvf.com/content/ICCV2023/html/Chu_Rethinking_Fast_Fourier_Convolution_in_Image_Inpainting_ICCV_2023_paper.html)

[Tianyi Chu](https://openaccess.thecvf.com/ICCV2023#), [Jiafu Chen](https://openaccess.thecvf.com/ICCV2023#), [Jiakai Sun](https://openaccess.thecvf.com/ICCV2023#), [Shuobin Lian](https://openaccess.thecvf.com/ICCV2023#), [Zhizhong Wang](https://openaccess.thecvf.com/ICCV2023#), [Zhiwen Zuo](https://openaccess.thecvf.com/ICCV2023#), [Lei Zhao](https://openaccess.thecvf.com/ICCV2023#), [Wei Xing](https://openaccess.thecvf.com/ICCV2023#), [Dongming Lu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chu_Rethinking_Fast_Fourier_Convolution_in_Image_Inpainting_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chu_Rethinking_Fast_Fourier_ICCV_2023_supplemental.pdf)] 

[bibtex]


[RED-PSM: Regularization by Denoising of Partially Separable Models for Dynamic Imaging](https://openaccess.thecvf.com/content/ICCV2023/html/Iskender_RED-PSM_Regularization_by_Denoising_of_Partially_Separable_Models_for_Dynamic_ICCV_2023_paper.html)

[Berk Iskender](https://openaccess.thecvf.com/ICCV2023#), [Marc L. Klasky](https://openaccess.thecvf.com/ICCV2023#), [Yoram Bresler](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Iskender_RED-PSM_Regularization_by_Denoising_of_Partially_Separable_Models_for_Dynamic_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Iskender_RED-PSM_Regularization_by_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Human Preference Score: Better Aligning Text-to-Image Models with Human Preference](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Human_Preference_Score_Better_Aligning_Text-to-Image_Models_with_Human_Preference_ICCV_2023_paper.html)

[Xiaoshi Wu](https://openaccess.thecvf.com/ICCV2023#), [Keqiang Sun](https://openaccess.thecvf.com/ICCV2023#), [Feng Zhu](https://openaccess.thecvf.com/ICCV2023#), [Rui Zhao](https://openaccess.thecvf.com/ICCV2023#), [Hongsheng Li](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Human_Preference_Score_Better_Aligning_Text-to-Image_Models_with_Human_Preference_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Human_Preference_Score_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.14420)] 

[bibtex]


[Learning to Generate Semantic Layouts for Higher Text-Image Correspondence in Text-to-Image Synthesis](https://openaccess.thecvf.com/content/ICCV2023/html/Park_Learning_to_Generate_Semantic_Layouts_for_Higher_Text-Image_Correspondence_in_ICCV_2023_paper.html)

[Minho Park](https://openaccess.thecvf.com/ICCV2023#), [Jooyeol Yun](https://openaccess.thecvf.com/ICCV2023#), [Seunghwan Choi](https://openaccess.thecvf.com/ICCV2023#), [Jaegul Choo](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_Learning_to_Generate_Semantic_Layouts_for_Higher_Text-Image_Correspondence_in_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Park_Learning_to_Generate_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.08157)] 

[bibtex]


[Make-It-3D: High-fidelity 3D Creation from A Single Image with Diffusion Prior](https://openaccess.thecvf.com/content/ICCV2023/html/Tang_Make-It-3D_High-fidelity_3D_Creation_from_A_Single_Image_with_Diffusion_ICCV_2023_paper.html)

[Junshu Tang](https://openaccess.thecvf.com/ICCV2023#), [Tengfei Wang](https://openaccess.thecvf.com/ICCV2023#), [Bo Zhang](https://openaccess.thecvf.com/ICCV2023#), [Ting Zhang](https://openaccess.thecvf.com/ICCV2023#), [Ran Yi](https://openaccess.thecvf.com/ICCV2023#), [Lizhuang Ma](https://openaccess.thecvf.com/ICCV2023#), [Dong Chen](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tang_Make-It-3D_High-fidelity_3D_Creation_from_A_Single_Image_with_Diffusion_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tang_Make-It-3D_High-fidelity_3D_ICCV_2023_supplemental.zip)] 

[bibtex]


[DiffTAD: Temporal Action Detection with Proposal Denoising Diffusion](https://openaccess.thecvf.com/content/ICCV2023/html/Nag_DiffTAD_Temporal_Action_Detection_with_Proposal_Denoising_Diffusion_ICCV_2023_paper.html)

[Sauradip Nag](https://openaccess.thecvf.com/ICCV2023#), [Xiatian Zhu](https://openaccess.thecvf.com/ICCV2023#), [Jiankang Deng](https://openaccess.thecvf.com/ICCV2023#), [Yi-Zhe Song](https://openaccess.thecvf.com/ICCV2023#), [Tao Xiang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nag_DiffTAD_Temporal_Action_Detection_with_Proposal_Denoising_Diffusion_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nag_DiffTAD_Temporal_Action_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.14863)] 

[bibtex]


[Ray Conditioning: Trading Photo-consistency for Photo-realism in Multi-view Image Generation](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Ray_Conditioning_Trading_Photo-consistency_for_Photo-realism_in_Multi-view_Image_Generation_ICCV_2023_paper.html)

[Eric Ming Chen](https://openaccess.thecvf.com/ICCV2023#), [Sidhanth Holalkere](https://openaccess.thecvf.com/ICCV2023#), [Ruyu Yan](https://openaccess.thecvf.com/ICCV2023#), [Kai Zhang](https://openaccess.thecvf.com/ICCV2023#), [Abe Davis](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Ray_Conditioning_Trading_Photo-consistency_for_Photo-realism_in_Multi-view_Image_Generation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Ray_Conditioning_Trading_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2304.13681)] 

[bibtex]


[Dual Aggregation Transformer for Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Dual_Aggregation_Transformer_for_Image_Super-Resolution_ICCV_2023_paper.html)

[Zheng Chen](https://openaccess.thecvf.com/ICCV2023#), [Yulun Zhang](https://openaccess.thecvf.com/ICCV2023#), [Jinjin Gu](https://openaccess.thecvf.com/ICCV2023#), [Linghe Kong](https://openaccess.thecvf.com/ICCV2023#), [Xiaokang Yang](https://openaccess.thecvf.com/ICCV2023#), [Fisher Yu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Dual_Aggregation_Transformer_for_Image_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Dual_Aggregation_Transformer_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.03364)] 

[bibtex]


[Zero-Shot Spatial Layout Conditioning for Text-to-Image Diffusion Models](https://openaccess.thecvf.com/content/ICCV2023/html/Couairon_Zero-Shot_Spatial_Layout_Conditioning_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html)

[Guillaume Couairon](https://openaccess.thecvf.com/ICCV2023#), [Marlène Careil](https://openaccess.thecvf.com/ICCV2023#), [Matthieu Cord](https://openaccess.thecvf.com/ICCV2023#), [Stéphane Lathuilière](https://openaccess.thecvf.com/ICCV2023#), [Jakob Verbeek](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Couairon_Zero-Shot_Spatial_Layout_Conditioning_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Couairon_Zero-Shot_Spatial_Layout_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2306.13754)] 

[bibtex]


[DDColor: Towards Photo-Realistic Image Colorization via Dual Decoders](https://openaccess.thecvf.com/content/ICCV2023/html/Kang_DDColor_Towards_Photo-Realistic_Image_Colorization_via_Dual_Decoders_ICCV_2023_paper.html)

[Xiaoyang Kang](https://openaccess.thecvf.com/ICCV2023#), [Tao Yang](https://openaccess.thecvf.com/ICCV2023#), [Wenqi Ouyang](https://openaccess.thecvf.com/ICCV2023#), [Peiran Ren](https://openaccess.thecvf.com/ICCV2023#), [Lingzhi Li](https://openaccess.thecvf.com/ICCV2023#), [Xuansong Xie](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_DDColor_Towards_Photo-Realistic_Image_Colorization_via_Dual_Decoders_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kang_DDColor_Towards_Photo-Realistic_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.11613)] 

[bibtex]


[VeRi3D: Generative Vertex-based Radiance Fields for 3D Controllable Human Image Synthesis](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_VeRi3D_Generative_Vertex-based_Radiance_Fields_for_3D_Controllable_Human_Image_ICCV_2023_paper.html)

[Xinya Chen](https://openaccess.thecvf.com/ICCV2023#), [Jiaxin Huang](https://openaccess.thecvf.com/ICCV2023#), [Yanrui Bin](https://openaccess.thecvf.com/ICCV2023#), [Lu Yu](https://openaccess.thecvf.com/ICCV2023#), [Yiyi Liao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_VeRi3D_Generative_Vertex-based_Radiance_Fields_for_3D_Controllable_Human_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_VeRi3D_Generative_Vertex-based_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.04800)] 

[bibtex]


[GlueGen: Plug and Play Multi-modal Encoders for X-to-image Generation](https://openaccess.thecvf.com/content/ICCV2023/html/Qin_GlueGen_Plug_and_Play_Multi-modal_Encoders_for_X-to-image_Generation_ICCV_2023_paper.html)

[Can Qin](https://openaccess.thecvf.com/ICCV2023#), [Ning Yu](https://openaccess.thecvf.com/ICCV2023#), [Chen Xing](https://openaccess.thecvf.com/ICCV2023#), [Shu Zhang](https://openaccess.thecvf.com/ICCV2023#), [Zeyuan Chen](https://openaccess.thecvf.com/ICCV2023#), [Stefano Ermon](https://openaccess.thecvf.com/ICCV2023#), [Yun Fu](https://openaccess.thecvf.com/ICCV2023#), [Caiming Xiong](https://openaccess.thecvf.com/ICCV2023#), [Ran Xu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qin_GlueGen_Plug_and_Play_Multi-modal_Encoders_for_X-to-image_Generation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qin_GlueGen_Plug_and_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Score Priors Guided Deep Variational Inference for Unsupervised Real-World Single Image Denoising](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_Score_Priors_Guided_Deep_Variational_Inference_for_Unsupervised_Real-World_Single_ICCV_2023_paper.html)

[Jun Cheng](https://openaccess.thecvf.com/ICCV2023#), [Tao Liu](https://openaccess.thecvf.com/ICCV2023#), [Shan Tan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_Score_Priors_Guided_Deep_Variational_Inference_for_Unsupervised_Real-World_Single_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cheng_Score_Priors_Guided_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.04682)] 

[bibtex]


[Improving Transformer-based Image Matching by Cascaded Capturing Spatially Informative Keypoints](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Improving_Transformer-based_Image_Matching_by_Cascaded_Capturing_Spatially_Informative_Keypoints_ICCV_2023_paper.html)

[Chenjie Cao](https://openaccess.thecvf.com/ICCV2023#), [Yanwei Fu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Improving_Transformer-based_Image_Matching_by_Cascaded_Capturing_Spatially_Informative_Keypoints_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_Improving_Transformer-based_Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.02885)] 

[bibtex]


[MosaiQ: Quantum Generative Adversarial Networks for Image Generation on NISQ Computers](https://openaccess.thecvf.com/content/ICCV2023/html/Silver_MosaiQ_Quantum_Generative_Adversarial_Networks_for_Image_Generation_on_NISQ_ICCV_2023_paper.html)

[Daniel Silver](https://openaccess.thecvf.com/ICCV2023#), [Tirthak Patel](https://openaccess.thecvf.com/ICCV2023#), [William Cutler](https://openaccess.thecvf.com/ICCV2023#), [Aditya Ranjan](https://openaccess.thecvf.com/ICCV2023#), [Harshitta Gandhi](https://openaccess.thecvf.com/ICCV2023#), [Devesh Tiwari](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Silver_MosaiQ_Quantum_Generative_Adversarial_Networks_for_Image_Generation_on_NISQ_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2308.11096)] 

[bibtex]


[TexFusion: Synthesizing 3D Textures with Text-Guided Image Diffusion Models](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_TexFusion_Synthesizing_3D_Textures_with_Text-Guided_Image_Diffusion_Models_ICCV_2023_paper.html)

[Tianshi Cao](https://openaccess.thecvf.com/ICCV2023#), [Karsten Kreis](https://openaccess.thecvf.com/ICCV2023#), [Sanja Fidler](https://openaccess.thecvf.com/ICCV2023#), [Nicholas Sharp](https://openaccess.thecvf.com/ICCV2023#), [Kangxue Yin](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_TexFusion_Synthesizing_3D_Textures_with_Text-Guided_Image_Diffusion_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_TexFusion_Synthesizing_3D_ICCV_2023_supplemental.zip)] 

[bibtex]


[Lighting Every Darkness in Two Pairs: A Calibration-Free Pipeline for RAW Denoising](https://openaccess.thecvf.com/content/ICCV2023/html/Jin_Lighting_Every_Darkness_in_Two_Pairs_A_Calibration-Free_Pipeline_for_ICCV_2023_paper.html)

[Xin Jin](https://openaccess.thecvf.com/ICCV2023#), [Jia-Wen Xiao](https://openaccess.thecvf.com/ICCV2023#), [Ling-Hao Han](https://openaccess.thecvf.com/ICCV2023#), [Chunle Guo](https://openaccess.thecvf.com/ICCV2023#), [Ruixun Zhang](https://openaccess.thecvf.com/ICCV2023#), [Xialei Liu](https://openaccess.thecvf.com/ICCV2023#), [Chongyi Li](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jin_Lighting_Every_Darkness_in_Two_Pairs_A_Calibration-Free_Pipeline_for_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jin_Lighting_Every_Darkness_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.03448)] 

[bibtex]


[Metric3D: Towards Zero-shot Metric 3D Prediction from A Single Image](https://openaccess.thecvf.com/content/ICCV2023/html/Yin_Metric3D_Towards_Zero-shot_Metric_3D_Prediction_from_A_Single_Image_ICCV_2023_paper.html)

[Wei Yin](https://openaccess.thecvf.com/ICCV2023#), [Chi Zhang](https://openaccess.thecvf.com/ICCV2023#), [Hao Chen](https://openaccess.thecvf.com/ICCV2023#), [Zhipeng Cai](https://openaccess.thecvf.com/ICCV2023#), [Gang Yu](https://openaccess.thecvf.com/ICCV2023#), [Kaixuan Wang](https://openaccess.thecvf.com/ICCV2023#), [Xiaozhi Chen](https://openaccess.thecvf.com/ICCV2023#), [Chunhua Shen](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_Metric3D_Towards_Zero-shot_Metric_3D_Prediction_from_A_Single_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yin_Metric3D_Towards_Zero-shot_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.10984)] 

[bibtex]


[Lightweight Image Super-Resolution with Superpixel Token Interaction](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Lightweight_Image_Super-Resolution_with_Superpixel_Token_Interaction_ICCV_2023_paper.html)

[Aiping Zhang](https://openaccess.thecvf.com/ICCV2023#), [Wenqi Ren](https://openaccess.thecvf.com/ICCV2023#), [Yi Liu](https://openaccess.thecvf.com/ICCV2023#), [Xiaochun Cao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Lightweight_Image_Super-Resolution_with_Superpixel_Token_Interaction_ICCV_2023_paper.pdf)] 

[bibtex]


[Iterative Denoiser and Noise Estimator for Self-Supervised Image Denoising](https://openaccess.thecvf.com/content/ICCV2023/html/Zou_Iterative_Denoiser_and_Noise_Estimator_for_Self-Supervised_Image_Denoising_ICCV_2023_paper.html)

[Yunhao Zou](https://openaccess.thecvf.com/ICCV2023#), [Chenggang Yan](https://openaccess.thecvf.com/ICCV2023#), [Ying Fu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_Iterative_Denoiser_and_Noise_Estimator_for_Self-Supervised_Image_Denoising_ICCV_2023_paper.pdf)] 

[bibtex]


[MasQCLIP for Open-Vocabulary Universal Image Segmentation](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_MasQCLIP_for_Open-Vocabulary_Universal_Image_Segmentation_ICCV_2023_paper.html)

[Xin Xu](https://openaccess.thecvf.com/ICCV2023#), [Tianyi Xiong](https://openaccess.thecvf.com/ICCV2023#), [Zheng Ding](https://openaccess.thecvf.com/ICCV2023#), [Zhuowen Tu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MasQCLIP_for_Open-Vocabulary_Universal_Image_Segmentation_ICCV_2023_paper.pdf)] 

[bibtex]


[MetaF2N: Blind Image Super-Resolution by Learning Efficient Model Adaptation from Faces](https://openaccess.thecvf.com/content/ICCV2023/html/Yin_MetaF2N_Blind_Image_Super-Resolution_by_Learning_Efficient_Model_Adaptation_from_ICCV_2023_paper.html)

[Zhicun Yin](https://openaccess.thecvf.com/ICCV2023#), [Ming Liu](https://openaccess.thecvf.com/ICCV2023#), [Xiaoming Li](https://openaccess.thecvf.com/ICCV2023#), [Hui Yang](https://openaccess.thecvf.com/ICCV2023#), [Longan Xiao](https://openaccess.thecvf.com/ICCV2023#), [Wangmeng Zuo](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yin_MetaF2N_Blind_Image_Super-Resolution_by_Learning_Efficient_Model_Adaptation_from_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yin_MetaF2N_Blind_Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.08113)] 

[bibtex]


[DIRE for Diffusion-Generated Image Detection](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_DIRE_for_Diffusion-Generated_Image_Detection_ICCV_2023_paper.html)

[Zhendong Wang](https://openaccess.thecvf.com/ICCV2023#), [Jianmin Bao](https://openaccess.thecvf.com/ICCV2023#), [Wengang Zhou](https://openaccess.thecvf.com/ICCV2023#), [Weilun Wang](https://openaccess.thecvf.com/ICCV2023#), [Hezhen Hu](https://openaccess.thecvf.com/ICCV2023#), [Hong Chen](https://openaccess.thecvf.com/ICCV2023#), [Houqiang Li](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_DIRE_for_Diffusion-Generated_Image_Detection_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.09295)] 

[bibtex]


[Noise2Info: Noisy Image to Information of Noise for Self-Supervised Image Denoising](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Noise2Info_Noisy_Image_to_Information_of_Noise_for_Self-Supervised_Image_ICCV_2023_paper.html)

[Jiachuan Wang](https://openaccess.thecvf.com/ICCV2023#), [Shimin Di](https://openaccess.thecvf.com/ICCV2023#), [Lei Chen](https://openaccess.thecvf.com/ICCV2023#), [Charles Wang Wai Ng](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Noise2Info_Noisy_Image_to_Information_of_Noise_for_Self-Supervised_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Noise2Info_Noisy_Image_ICCV_2023_supplemental.zip)] 

[bibtex]


[Viewset Diffusion: (0-)Image-Conditioned 3D Generative Models from 2D Data](https://openaccess.thecvf.com/content/ICCV2023/html/Szymanowicz_Viewset_Diffusion_0-Image-Conditioned_3D_Generative_Models_from_2D_Data_ICCV_2023_paper.html)

[Stanislaw Szymanowicz](https://openaccess.thecvf.com/ICCV2023#), [Christian Rupprecht](https://openaccess.thecvf.com/ICCV2023#), [Andrea Vedaldi](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Szymanowicz_Viewset_Diffusion_0-Image-Conditioned_3D_Generative_Models_from_2D_Data_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Szymanowicz_Viewset_Diffusion_0-Image-Conditioned_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Iterative Soft Shrinkage Learning for Efficient Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Iterative_Soft_Shrinkage_Learning_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.html)

[Jiamian Wang](https://openaccess.thecvf.com/ICCV2023#), [Huan Wang](https://openaccess.thecvf.com/ICCV2023#), [Yulun Zhang](https://openaccess.thecvf.com/ICCV2023#), [Yun Fu](https://openaccess.thecvf.com/ICCV2023#), [Zhiqiang Tao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Iterative_Soft_Shrinkage_Learning_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Iterative_Soft_Shrinkage_Learning_for_Efficient_Image_Super-Resolution_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.09650)] 

[bibtex]


[UniFormerV2: Unlocking the Potential of Image ViTs for Video Understanding](https://openaccess.thecvf.com/content/ICCV2023/html/Li_UniFormerV2_Unlocking_the_Potential_of_Image_ViTs_for_Video_Understanding_ICCV_2023_paper.html)

[Kunchang Li](https://openaccess.thecvf.com/ICCV2023#), [Yali Wang](https://openaccess.thecvf.com/ICCV2023#), [Yinan He](https://openaccess.thecvf.com/ICCV2023#), [Yizhuo Li](https://openaccess.thecvf.com/ICCV2023#), [Yi Wang](https://openaccess.thecvf.com/ICCV2023#), [Limin Wang](https://openaccess.thecvf.com/ICCV2023#), [Yu Qiao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_UniFormerV2_Unlocking_the_Potential_of_Image_ViTs_for_Video_Understanding_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_UniFormerV2_Unlocking_the_ICCV_2023_supplemental.zip)] 

[bibtex]


[FashionNTM: Multi-turn Fashion Image Retrieval via Cascaded Memory](https://openaccess.thecvf.com/content/ICCV2023/html/Pal_FashionNTM_Multi-turn_Fashion_Image_Retrieval_via_Cascaded_Memory_ICCV_2023_paper.html)

[Anwesan Pal](https://openaccess.thecvf.com/ICCV2023#), [Sahil Wadhwa](https://openaccess.thecvf.com/ICCV2023#), [Ayush Jaiswal](https://openaccess.thecvf.com/ICCV2023#), [Xu Zhang](https://openaccess.thecvf.com/ICCV2023#), [Yue Wu](https://openaccess.thecvf.com/ICCV2023#), [Rakesh Chada](https://openaccess.thecvf.com/ICCV2023#), [Pradeep Natarajan](https://openaccess.thecvf.com/ICCV2023#), [Henrik I. Christensen](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pal_FashionNTM_Multi-turn_Fashion_Image_Retrieval_via_Cascaded_Memory_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pal_FashionNTM_Multi-turn_Fashion_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2308.10170)] 

[bibtex]


[SAMPLING: Scene-adaptive Hierarchical Multiplane Images Representation for Novel View Synthesis from a Single Image](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_SAMPLING_Scene-adaptive_Hierarchical_Multiplane_Images_Representation_for_Novel_View_Synthesis_ICCV_2023_paper.html)

[Xiaoyu Zhou](https://openaccess.thecvf.com/ICCV2023#), [Zhiwei Lin](https://openaccess.thecvf.com/ICCV2023#), [Xiaojun Shan](https://openaccess.thecvf.com/ICCV2023#), [Yongtao Wang](https://openaccess.thecvf.com/ICCV2023#), [Deqing Sun](https://openaccess.thecvf.com/ICCV2023#), [Ming-Hsuan Yang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SAMPLING_Scene-adaptive_Hierarchical_Multiplane_Images_Representation_for_Novel_View_Synthesis_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_SAMPLING_Scene-adaptive_Hierarchical_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2309.06323)] 

[bibtex]


[LNPL-MIL: Learning from Noisy Pseudo Labels for Promoting Multiple Instance Learning in Whole Slide Image](https://openaccess.thecvf.com/content/ICCV2023/html/Shao_LNPL-MIL_Learning_from_Noisy_Pseudo_Labels_for_Promoting_Multiple_Instance_ICCV_2023_paper.html)

[Zhuchen Shao](https://openaccess.thecvf.com/ICCV2023#), [Yifeng Wang](https://openaccess.thecvf.com/ICCV2023#), [Yang Chen](https://openaccess.thecvf.com/ICCV2023#), [Hao Bian](https://openaccess.thecvf.com/ICCV2023#), [Shaohui Liu](https://openaccess.thecvf.com/ICCV2023#), [Haoqian Wang](https://openaccess.thecvf.com/ICCV2023#), [Yongbing Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_LNPL-MIL_Learning_from_Noisy_Pseudo_Labels_for_Promoting_Multiple_Instance_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shao_LNPL-MIL_Learning_from_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Random Sub-Samples Generation for Self-Supervised Real Image Denoising](https://openaccess.thecvf.com/content/ICCV2023/html/Pan_Random_Sub-Samples_Generation_for_Self-Supervised_Real_Image_Denoising_ICCV_2023_paper.html)

[Yizhong Pan](https://openaccess.thecvf.com/ICCV2023#), [Xiao Liu](https://openaccess.thecvf.com/ICCV2023#), [Xiangyu Liao](https://openaccess.thecvf.com/ICCV2023#), [Yuanzhouhan Cao](https://openaccess.thecvf.com/ICCV2023#), [Chao Ren](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pan_Random_Sub-Samples_Generation_for_Self-Supervised_Real_Image_Denoising_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pan_Random_Sub-Samples_Generation_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.16825)] 

[bibtex]


[AG3D: Learning to Generate 3D Avatars from 2D Image Collections](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_AG3D_Learning_to_Generate_3D_Avatars_from_2D_Image_Collections_ICCV_2023_paper.html)

[Zijian Dong](https://openaccess.thecvf.com/ICCV2023#), [Xu Chen](https://openaccess.thecvf.com/ICCV2023#), [Jinlong Yang](https://openaccess.thecvf.com/ICCV2023#), [Michael J. Black](https://openaccess.thecvf.com/ICCV2023#), [Otmar Hilliges](https://openaccess.thecvf.com/ICCV2023#), [Andreas Geiger](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_AG3D_Learning_to_Generate_3D_Avatars_from_2D_Image_Collections_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_AG3D_Learning_to_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2305.02312)] 

[bibtex]


[Learned Image Reasoning Prior Penetrates Deep Unfolding Network for Panchromatic and Multi-spectral Image Fusion](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Learned_Image_Reasoning_Prior_Penetrates_Deep_Unfolding_Network_for_Panchromatic_ICCV_2023_paper.html)

[Man Zhou](https://openaccess.thecvf.com/ICCV2023#), [Jie Huang](https://openaccess.thecvf.com/ICCV2023#), [Naishan Zheng](https://openaccess.thecvf.com/ICCV2023#), [Chongyi Li](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learned_Image_Reasoning_Prior_Penetrates_Deep_Unfolding_Network_for_Panchromatic_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2308.16083)] 

[bibtex]


[3D-aware Image Generation using 2D Diffusion Models](https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_3D-aware_Image_Generation_using_2D_Diffusion_Models_ICCV_2023_paper.html)

[Jianfeng Xiang](https://openaccess.thecvf.com/ICCV2023#), [Jiaolong Yang](https://openaccess.thecvf.com/ICCV2023#), [Binbin Huang](https://openaccess.thecvf.com/ICCV2023#), [Xin Tong](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_3D-aware_Image_Generation_using_2D_Diffusion_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiang_3D-aware_Image_Generation_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.17905)] 

[bibtex]


[Locating Noise is Halfway Denoising for Semi-Supervised Segmentation](https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Locating_Noise_is_Halfway_Denoising_for_Semi-Supervised_Segmentation_ICCV_2023_paper.html)

[Yan Fang](https://openaccess.thecvf.com/ICCV2023#), [Feng Zhu](https://openaccess.thecvf.com/ICCV2023#), [Bowen Cheng](https://openaccess.thecvf.com/ICCV2023#), [Luoqi Liu](https://openaccess.thecvf.com/ICCV2023#), [Yao Zhao](https://openaccess.thecvf.com/ICCV2023#), [Yunchao Wei](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Locating_Noise_is_Halfway_Denoising_for_Semi-Supervised_Segmentation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fang_Locating_Noise_is_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Learning Non-Local Spatial-Angular Correlation for Light Field Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Learning_Non-Local_Spatial-Angular_Correlation_for_Light_Field_Image_Super-Resolution_ICCV_2023_paper.html)

[Zhengyu Liang](https://openaccess.thecvf.com/ICCV2023#), [Yingqian Wang](https://openaccess.thecvf.com/ICCV2023#), [Longguang Wang](https://openaccess.thecvf.com/ICCV2023#), [Jungang Yang](https://openaccess.thecvf.com/ICCV2023#), [Shilin Zhou](https://openaccess.thecvf.com/ICCV2023#), [Yulan Guo](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Learning_Non-Local_Spatial-Angular_Correlation_for_Light_Field_Image_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liang_Learning_Non-Local_Spatial-Angular_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.08058)] 

[bibtex]


[Foreground-Background Separation through Concept Distillation from Generative Image Foundation Models](https://openaccess.thecvf.com/content/ICCV2023/html/Dombrowski_Foreground-Background_Separation_through_Concept_Distillation_from_Generative_Image_Foundation_Models_ICCV_2023_paper.html)

[Mischa Dombrowski](https://openaccess.thecvf.com/ICCV2023#), [Hadrien Reynaud](https://openaccess.thecvf.com/ICCV2023#), [Matthew Baugh](https://openaccess.thecvf.com/ICCV2023#), [Bernhard Kainz](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dombrowski_Foreground-Background_Separation_through_Concept_Distillation_from_Generative_Image_Foundation_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dombrowski_Foreground-Background_Separation_through_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2212.14306)] 

[bibtex]


[Not All Steps are Created Equal: Selective Diffusion Distillation for Image Manipulation](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Not_All_Steps_are_Created_Equal_Selective_Diffusion_Distillation_for_ICCV_2023_paper.html)

[Luozhou Wang](https://openaccess.thecvf.com/ICCV2023#), [Shuai Yang](https://openaccess.thecvf.com/ICCV2023#), [Shu Liu](https://openaccess.thecvf.com/ICCV2023#), [Ying-cong Chen](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Not_All_Steps_are_Created_Equal_Selective_Diffusion_Distillation_for_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Not_All_Steps_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.08448)] 

[bibtex]


[ALIP: Adaptive Language-Image Pre-Training with Synthetic Caption](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_ALIP_Adaptive_Language-Image_Pre-Training_with_Synthetic_Caption_ICCV_2023_paper.html)

[Kaicheng Yang](https://openaccess.thecvf.com/ICCV2023#), [Jiankang Deng](https://openaccess.thecvf.com/ICCV2023#), [Xiang An](https://openaccess.thecvf.com/ICCV2023#), [Jiawei Li](https://openaccess.thecvf.com/ICCV2023#), [Ziyong Feng](https://openaccess.thecvf.com/ICCV2023#), [Jia Guo](https://openaccess.thecvf.com/ICCV2023#), [Jing Yang](https://openaccess.thecvf.com/ICCV2023#), [Tongliang Liu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_ALIP_Adaptive_Language-Image_Pre-Training_with_Synthetic_Caption_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_ALIP_Adaptive_Language-Image_Pre-Training_with_Synthetic_Caption_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.08428)] 

[bibtex]


[CLIP2Point: Transfer CLIP to Point Cloud Classification with Image-Depth Pre-Training](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_CLIP2Point_Transfer_CLIP_to_Point_Cloud_Classification_with_Image-Depth_Pre-Training_ICCV_2023_paper.html)

[Tianyu Huang](https://openaccess.thecvf.com/ICCV2023#), [Bowen Dong](https://openaccess.thecvf.com/ICCV2023#), [Yunhan Yang](https://openaccess.thecvf.com/ICCV2023#), [Xiaoshui Huang](https://openaccess.thecvf.com/ICCV2023#), [Rynson W.H. Lau](https://openaccess.thecvf.com/ICCV2023#), [Wanli Ouyang](https://openaccess.thecvf.com/ICCV2023#), [Wangmeng Zuo](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_CLIP2Point_Transfer_CLIP_to_Point_Cloud_Classification_with_Image-Depth_Pre-Training_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_CLIP2Point_Transfer_CLIP_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2210.01055)] 

[bibtex]


[RawHDR: High Dynamic Range Image Reconstruction from a Single Raw Image](https://openaccess.thecvf.com/content/ICCV2023/html/Zou_RawHDR_High_Dynamic_Range_Image_Reconstruction_from_a_Single_Raw_ICCV_2023_paper.html)

[Yunhao Zou](https://openaccess.thecvf.com/ICCV2023#), [Chenggang Yan](https://openaccess.thecvf.com/ICCV2023#), [Ying Fu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zou_RawHDR_High_Dynamic_Range_Image_Reconstruction_from_a_Single_Raw_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2309.02020)] 

[bibtex]


[Denoising Diffusion Autoencoders are Unified Self-supervised Learners](https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_Denoising_Diffusion_Autoencoders_are_Unified_Self-supervised_Learners_ICCV_2023_paper.html)

[Weilai Xiang](https://openaccess.thecvf.com/ICCV2023#), [Hongyu Yang](https://openaccess.thecvf.com/ICCV2023#), [Di Huang](https://openaccess.thecvf.com/ICCV2023#), [Yunhong Wang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_Denoising_Diffusion_Autoencoders_are_Unified_Self-supervised_Learners_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiang_Denoising_Diffusion_Autoencoders_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.09769)] 

[bibtex]


[FSI: Frequency and Spatial Interactive Learning for Image Restoration in Under-Display Cameras](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_FSI_Frequency_and_Spatial_Interactive_Learning_for_Image_Restoration_in_ICCV_2023_paper.html)

[Chengxu Liu](https://openaccess.thecvf.com/ICCV2023#), [Xuan Wang](https://openaccess.thecvf.com/ICCV2023#), [Shuai Li](https://openaccess.thecvf.com/ICCV2023#), [Yuzhi Wang](https://openaccess.thecvf.com/ICCV2023#), [Xueming Qian](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_FSI_Frequency_and_Spatial_Interactive_Learning_for_Image_Restoration_in_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_FSI_Frequency_and_Spatial_Interactive_Learning_for_Image_Restoration_in_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Variational Degeneration to Structural Refinement: A Unified Framework for Superimposed Image Decomposition](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Variational_Degeneration_to_Structural_Refinement_A_Unified_Framework_for_Superimposed_ICCV_2023_paper.html)

[Wenyu Li](https://openaccess.thecvf.com/ICCV2023#), [Yan Xu](https://openaccess.thecvf.com/ICCV2023#), [Yang Yang](https://openaccess.thecvf.com/ICCV2023#), [Haoran Ji](https://openaccess.thecvf.com/ICCV2023#), [Yue Lang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Variational_Degeneration_to_Structural_Refinement_A_Unified_Framework_for_Superimposed_ICCV_2023_paper.pdf)] 

[bibtex]


[Focal Network for Image Restoration](https://openaccess.thecvf.com/content/ICCV2023/html/Cui_Focal_Network_for_Image_Restoration_ICCV_2023_paper.html)

[Yuning Cui](https://openaccess.thecvf.com/ICCV2023#), [Wenqi Ren](https://openaccess.thecvf.com/ICCV2023#), [Xiaochun Cao](https://openaccess.thecvf.com/ICCV2023#), [Alois Knoll](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cui_Focal_Network_for_Image_Restoration_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cui_Focal_Network_for_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Decoupled Iterative Refinement Framework for Interacting Hands Reconstruction from a Single RGB Image](https://openaccess.thecvf.com/content/ICCV2023/html/Ren_Decoupled_Iterative_Refinement_Framework_for_Interacting_Hands_Reconstruction_from_a_ICCV_2023_paper.html)

[Pengfei Ren](https://openaccess.thecvf.com/ICCV2023#), [Chao Wen](https://openaccess.thecvf.com/ICCV2023#), [Xiaozheng Zheng](https://openaccess.thecvf.com/ICCV2023#), [Zhou Xue](https://openaccess.thecvf.com/ICCV2023#), [Haifeng Sun](https://openaccess.thecvf.com/ICCV2023#), [Qi Qi](https://openaccess.thecvf.com/ICCV2023#), [Jingyu Wang](https://openaccess.thecvf.com/ICCV2023#), [Jianxin Liao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Decoupled_Iterative_Refinement_Framework_for_Interacting_Hands_Reconstruction_from_a_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ren_Decoupled_Iterative_Refinement_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2302.02410)] 

[bibtex]


[Who Are You Referring To? Coreference Resolution In Image Narrations](https://openaccess.thecvf.com/content/ICCV2023/html/Goel_Who_Are_You_Referring_To_Coreference_Resolution_In_Image_Narrations_ICCV_2023_paper.html)

[Arushi Goel](https://openaccess.thecvf.com/ICCV2023#), [Basura Fernando](https://openaccess.thecvf.com/ICCV2023#), [Frank Keller](https://openaccess.thecvf.com/ICCV2023#), [Hakan Bilen](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Goel_Who_Are_You_Referring_To_Coreference_Resolution_In_Image_Narrations_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Goel_Who_Are_You_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.14563)] 

[bibtex]


[A-STAR: Test-time Attention Segregation and Retention for Text-to-image Synthesis](https://openaccess.thecvf.com/content/ICCV2023/html/Agarwal_A-STAR_Test-time_Attention_Segregation_and_Retention_for_Text-to-image_Synthesis_ICCV_2023_paper.html)

[Aishwarya Agarwal](https://openaccess.thecvf.com/ICCV2023#), [Srikrishna Karanam](https://openaccess.thecvf.com/ICCV2023#), [K J Joseph](https://openaccess.thecvf.com/ICCV2023#), [Apoorv Saxena](https://openaccess.thecvf.com/ICCV2023#), [Koustava Goswami](https://openaccess.thecvf.com/ICCV2023#), [Balaji Vasan Srinivasan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Agarwal_A-STAR_Test-time_Attention_Segregation_and_Retention_for_Text-to-image_Synthesis_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Agarwal_A-STAR_Test-time_Attention_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Feature Modulation Transformer: Cross-Refinement of Global Representation via High-Frequency Prior for Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Feature_Modulation_Transformer_Cross-Refinement_of_Global_Representation_via_High-Frequency_Prior_ICCV_2023_paper.html)

[Ao Li](https://openaccess.thecvf.com/ICCV2023#), [Le Zhang](https://openaccess.thecvf.com/ICCV2023#), [Yun Liu](https://openaccess.thecvf.com/ICCV2023#), [Ce Zhu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Feature_Modulation_Transformer_Cross-Refinement_of_Global_Representation_via_High-Frequency_Prior_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Feature_Modulation_Transformer_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.05022)] 

[bibtex]


[ITI-GEN: Inclusive Text-to-Image Generation](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ITI-GEN_Inclusive_Text-to-Image_Generation_ICCV_2023_paper.html)

[Cheng Zhang](https://openaccess.thecvf.com/ICCV2023#), [Xuanbai Chen](https://openaccess.thecvf.com/ICCV2023#), [Siqi Chai](https://openaccess.thecvf.com/ICCV2023#), [Chen Henry Wu](https://openaccess.thecvf.com/ICCV2023#), [Dmitry Lagun](https://openaccess.thecvf.com/ICCV2023#), [Thabo Beeler](https://openaccess.thecvf.com/ICCV2023#), [Fernando De la Torre](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ITI-GEN_Inclusive_Text-to-Image_Generation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_ITI-GEN_Inclusive_Text-to-Image_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Bridging Vision and Language Encoders: Parameter-Efficient Tuning for Referring Image Segmentation](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Bridging_Vision_and_Language_Encoders_Parameter-Efficient_Tuning_for_Referring_Image_ICCV_2023_paper.html)

[Zunnan Xu](https://openaccess.thecvf.com/ICCV2023#), [Zhihong Chen](https://openaccess.thecvf.com/ICCV2023#), [Yong Zhang](https://openaccess.thecvf.com/ICCV2023#), [Yibing Song](https://openaccess.thecvf.com/ICCV2023#), [Xiang Wan](https://openaccess.thecvf.com/ICCV2023#), [Guanbin Li](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Bridging_Vision_and_Language_Encoders_Parameter-Efficient_Tuning_for_Referring_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Bridging_Vision_and_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.11545)] 

[bibtex]


[MEFLUT: Unsupervised 1D Lookup Tables for Multi-exposure Image Fusion](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_MEFLUT_Unsupervised_1D_Lookup_Tables_for_Multi-exposure_Image_Fusion_ICCV_2023_paper.html)

[Ting Jiang](https://openaccess.thecvf.com/ICCV2023#), [Chuan Wang](https://openaccess.thecvf.com/ICCV2023#), [Xinpeng Li](https://openaccess.thecvf.com/ICCV2023#), [Ru Li](https://openaccess.thecvf.com/ICCV2023#), [Haoqiang Fan](https://openaccess.thecvf.com/ICCV2023#), [Shuaicheng Liu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_MEFLUT_Unsupervised_1D_Lookup_Tables_for_Multi-exposure_Image_Fusion_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2309.11847)] 

[bibtex]


[Conditional 360-degree Image Synthesis for Immersive Indoor Scene Decoration](https://openaccess.thecvf.com/content/ICCV2023/html/Shum_Conditional_360-degree_Image_Synthesis_for_Immersive_Indoor_Scene_Decoration_ICCV_2023_paper.html)

[Ka Chun Shum](https://openaccess.thecvf.com/ICCV2023#), [Hong-Wing Pang](https://openaccess.thecvf.com/ICCV2023#), [Binh-Son Hua](https://openaccess.thecvf.com/ICCV2023#), [Duc Thanh Nguyen](https://openaccess.thecvf.com/ICCV2023#), [Sai-Kit Yeung](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shum_Conditional_360-degree_Image_Synthesis_for_Immersive_Indoor_Scene_Decoration_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shum_Conditional_360-degree_Image_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2307.09621)] 

[bibtex]


[Computationally-Efficient Neural Image Compression with Shallow Decoders](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Computationally-Efficient_Neural_Image_Compression_with_Shallow_Decoders_ICCV_2023_paper.html)

[Yibo Yang](https://openaccess.thecvf.com/ICCV2023#), [Stephan Mandt](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Computationally-Efficient_Neural_Image_Compression_with_Shallow_Decoders_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Computationally-Efficient_Neural_Image_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Scenimefy: Learning to Craft Anime Scene via Semi-Supervised Image-to-Image Translation](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Scenimefy_Learning_to_Craft_Anime_Scene_via_Semi-Supervised_Image-to-Image_Translation_ICCV_2023_paper.html)

[Yuxin Jiang](https://openaccess.thecvf.com/ICCV2023#), [Liming Jiang](https://openaccess.thecvf.com/ICCV2023#), [Shuai Yang](https://openaccess.thecvf.com/ICCV2023#), [Chen Change Loy](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Scenimefy_Learning_to_Craft_Anime_Scene_via_Semi-Supervised_Image-to-Image_Translation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Scenimefy_Learning_to_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.12968)] 

[bibtex]


[General Image-to-Image Translation with One-Shot Image Guidance](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_General_Image-to-Image_Translation_with_One-Shot_Image_Guidance_ICCV_2023_paper.html)

[Bin Cheng](https://openaccess.thecvf.com/ICCV2023#), [Zuhao Liu](https://openaccess.thecvf.com/ICCV2023#), [Yunbo Peng](https://openaccess.thecvf.com/ICCV2023#), [Yue Lin](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_General_Image-to-Image_Translation_with_One-Shot_Image_Guidance_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cheng_General_Image-to-Image_Translation_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.14352)] 

[bibtex]


[CO-PILOT: Dynamic Top-Down Point Cloud with Conditional Neighborhood Aggregation for Multi-Gigapixel Histopathology Image Representation](https://openaccess.thecvf.com/content/ICCV2023/html/Nakhli_CO-PILOT_Dynamic_Top-Down_Point_Cloud_with_Conditional_Neighborhood_Aggregation_for_ICCV_2023_paper.html)

[Ramin Nakhli](https://openaccess.thecvf.com/ICCV2023#), [Allen Zhang](https://openaccess.thecvf.com/ICCV2023#), [Ali Mirabadi](https://openaccess.thecvf.com/ICCV2023#), [Katherine Rich](https://openaccess.thecvf.com/ICCV2023#), [Maryam Asadi](https://openaccess.thecvf.com/ICCV2023#), [Blake Gilks](https://openaccess.thecvf.com/ICCV2023#), [Hossein Farahani](https://openaccess.thecvf.com/ICCV2023#), [Ali Bashashati](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nakhli_CO-PILOT_Dynamic_Top-Down_Point_Cloud_with_Conditional_Neighborhood_Aggregation_for_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nakhli_CO-PILOT_Dynamic_Top-Down_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Troubleshooting Ethnic Quality Bias with Curriculum Domain Adaptation for Face Image Quality Assessment](https://openaccess.thecvf.com/content/ICCV2023/html/Ou_Troubleshooting_Ethnic_Quality_Bias_with_Curriculum_Domain_Adaptation_for_Face_ICCV_2023_paper.html)

[Fu-Zhao Ou](https://openaccess.thecvf.com/ICCV2023#), [Baoliang Chen](https://openaccess.thecvf.com/ICCV2023#), [Chongyi Li](https://openaccess.thecvf.com/ICCV2023#), [Shiqi Wang](https://openaccess.thecvf.com/ICCV2023#), [Sam Kwong](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ou_Troubleshooting_Ethnic_Quality_Bias_with_Curriculum_Domain_Adaptation_for_Face_ICCV_2023_paper.pdf)] 

[bibtex]


[uSplit: Image Decomposition for Fluorescence Microscopy](https://openaccess.thecvf.com/content/ICCV2023/html/Ashesh_uSplit_Image_Decomposition_for_Fluorescence_Microscopy_ICCV_2023_paper.html)

[Ashesh Ashesh](https://openaccess.thecvf.com/ICCV2023#), [Alexander Krull](https://openaccess.thecvf.com/ICCV2023#), [Moises Di Sante](https://openaccess.thecvf.com/ICCV2023#), [Francesco Pasqualini](https://openaccess.thecvf.com/ICCV2023#), [Florian Jug](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ashesh_uSplit_Image_Decomposition_for_Fluorescence_Microscopy_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ashesh_uSplit_Image_Decomposition_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Personalized Image Generation for Color Vision Deficiency Population](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Personalized_Image_Generation_for_Color_Vision_Deficiency_Population_ICCV_2023_paper.html)

[Shuyi Jiang](https://openaccess.thecvf.com/ICCV2023#), [Daochang Liu](https://openaccess.thecvf.com/ICCV2023#), [Dingquan Li](https://openaccess.thecvf.com/ICCV2023#), [Chang Xu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Personalized_Image_Generation_for_Color_Vision_Deficiency_Population_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Personalized_Image_Generation_ICCV_2023_supplemental.pdf)] 

[bibtex]


[EGC: Image Generation and Classification via a Diffusion Energy-Based Model](https://openaccess.thecvf.com/content/ICCV2023/html/Guo_EGC_Image_Generation_and_Classification_via_a_Diffusion_Energy-Based_Model_ICCV_2023_paper.html)

[Qiushan Guo](https://openaccess.thecvf.com/ICCV2023#), [Chuofan Ma](https://openaccess.thecvf.com/ICCV2023#), [Yi Jiang](https://openaccess.thecvf.com/ICCV2023#), [Zehuan Yuan](https://openaccess.thecvf.com/ICCV2023#), [Yizhou Yu](https://openaccess.thecvf.com/ICCV2023#), [Ping Luo](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Guo_EGC_Image_Generation_and_Classification_via_a_Diffusion_Energy-Based_Model_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Guo_EGC_Image_Generation_and_Classification_via_a_Diffusion_Energy-Based_Model_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.02012)] 

[bibtex]


[Test Time Adaptation for Blind Image Quality Assessment](https://openaccess.thecvf.com/content/ICCV2023/html/Roy_Test_Time_Adaptation_for_Blind_Image_Quality_Assessment_ICCV_2023_paper.html)

[Subhadeep Roy](https://openaccess.thecvf.com/ICCV2023#), [Shankhanil Mitra](https://openaccess.thecvf.com/ICCV2023#), [Soma Biswas](https://openaccess.thecvf.com/ICCV2023#), [Rajiv Soundararajan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Roy_Test_Time_Adaptation_for_Blind_Image_Quality_Assessment_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Roy_Test_Time_Adaptation_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.14735)] 

[bibtex]


[Monocular 3D Object Detection with Bounding Box Denoising in 3D by Perceiver](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Monocular_3D_Object_Detection_with_Bounding_Box_Denoising_in_3D_ICCV_2023_paper.html)

[Xianpeng Liu](https://openaccess.thecvf.com/ICCV2023#), [Ce Zheng](https://openaccess.thecvf.com/ICCV2023#), [Kelvin B Cheng](https://openaccess.thecvf.com/ICCV2023#), [Nan Xue](https://openaccess.thecvf.com/ICCV2023#), [Guo-Jun Qi](https://openaccess.thecvf.com/ICCV2023#), [Tianfu Wu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Monocular_3D_Object_Detection_with_Bounding_Box_Denoising_in_3D_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Monocular_3D_Object_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.01289)] 

[bibtex]


[Editable Image Geometric Abstraction via Neural Primitive Assembly](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Editable_Image_Geometric_Abstraction_via_Neural_Primitive_Assembly_ICCV_2023_paper.html)

[Ye Chen](https://openaccess.thecvf.com/ICCV2023#), [Bingbing Ni](https://openaccess.thecvf.com/ICCV2023#), [Xuanhong Chen](https://openaccess.thecvf.com/ICCV2023#), [Zhangli Hu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Editable_Image_Geometric_Abstraction_via_Neural_Primitive_Assembly_ICCV_2023_paper.pdf)] 

[bibtex]


[CauSSL: Causality-inspired Semi-supervised Learning for Medical Image Segmentation](https://openaccess.thecvf.com/content/ICCV2023/html/Miao_CauSSL_Causality-inspired_Semi-supervised_Learning_for_Medical_Image_Segmentation_ICCV_2023_paper.html)

[Juzheng Miao](https://openaccess.thecvf.com/ICCV2023#), [Cheng Chen](https://openaccess.thecvf.com/ICCV2023#), [Furui Liu](https://openaccess.thecvf.com/ICCV2023#), [Hao Wei](https://openaccess.thecvf.com/ICCV2023#), [Pheng-Ann Heng](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_CauSSL_Causality-inspired_Semi-supervised_Learning_for_Medical_Image_Segmentation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Miao_CauSSL_Causality-inspired_Semi-supervised_Learning_for_Medical_Image_Segmentation_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Understanding 3D Object Interaction from a Single Image](https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Understanding_3D_Object_Interaction_from_a_Single_Image_ICCV_2023_paper.html)

[Shengyi Qian](https://openaccess.thecvf.com/ICCV2023#), [David F. Fouhey](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Understanding_3D_Object_Interaction_from_a_Single_Image_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2305.09664)] 

[bibtex]


[Towards Saner Deep Image Registration](https://openaccess.thecvf.com/content/ICCV2023/html/Duan_Towards_Saner_Deep_Image_Registration_ICCV_2023_paper.html)

[Bin Duan](https://openaccess.thecvf.com/ICCV2023#), [Ming Zhong](https://openaccess.thecvf.com/ICCV2023#), [Yan Yan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Duan_Towards_Saner_Deep_Image_Registration_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Duan_Towards_Saner_Deep_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.09696)] 

[bibtex]


[Fingerprinting Deep Image Restoration Models](https://openaccess.thecvf.com/content/ICCV2023/html/Quan_Fingerprinting_Deep_Image_Restoration_Models_ICCV_2023_paper.html)

[Yuhui Quan](https://openaccess.thecvf.com/ICCV2023#), [Huan Teng](https://openaccess.thecvf.com/ICCV2023#), [Ruotao Xu](https://openaccess.thecvf.com/ICCV2023#), [Jun Huang](https://openaccess.thecvf.com/ICCV2023#), [Hui Ji](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Fingerprinting_Deep_Image_Restoration_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Quan_Fingerprinting_Deep_Image_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Towards Universal Image Embeddings: A Large-Scale Dataset and Challenge for Generic Image Representations](https://openaccess.thecvf.com/content/ICCV2023/html/Ypsilantis_Towards_Universal_Image_Embeddings_A_Large-Scale_Dataset_and_Challenge_for_ICCV_2023_paper.html)

[Nikolaos-Antonios Ypsilantis](https://openaccess.thecvf.com/ICCV2023#), [Kaifeng Chen](https://openaccess.thecvf.com/ICCV2023#), [Bingyi Cao](https://openaccess.thecvf.com/ICCV2023#), [Mário Lipovský](https://openaccess.thecvf.com/ICCV2023#), [Pelin Dogan-Schönberger](https://openaccess.thecvf.com/ICCV2023#), [Grzegorz Makosa](https://openaccess.thecvf.com/ICCV2023#), [Boris Bluntschli](https://openaccess.thecvf.com/ICCV2023#), [Mojtaba Seyedhosseini](https://openaccess.thecvf.com/ICCV2023#), [Ondřej Chum](https://openaccess.thecvf.com/ICCV2023#), [André Araujo](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ypsilantis_Towards_Universal_Image_Embeddings_A_Large-Scale_Dataset_and_Challenge_for_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ypsilantis_Towards_Universal_Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.01858)] 

[bibtex]


[DDS2M: Self-Supervised Denoising Diffusion Spatio-Spectral Model for Hyperspectral Image Restoration](https://openaccess.thecvf.com/content/ICCV2023/html/Miao_DDS2M_Self-Supervised_Denoising_Diffusion_Spatio-Spectral_Model_for_Hyperspectral_Image_Restoration_ICCV_2023_paper.html)

[Yuchun Miao](https://openaccess.thecvf.com/ICCV2023#), [Lefei Zhang](https://openaccess.thecvf.com/ICCV2023#), [Liangpei Zhang](https://openaccess.thecvf.com/ICCV2023#), [Dacheng Tao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Miao_DDS2M_Self-Supervised_Denoising_Diffusion_Spatio-Spectral_Model_for_Hyperspectral_Image_Restoration_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Miao_DDS2M_Self-Supervised_Denoising_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.06682)] 

[bibtex]


[Zero-1-to-3: Zero-shot One Image to 3D Object](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Zero-1-to-3_Zero-shot_One_Image_to_3D_Object_ICCV_2023_paper.html)

[Ruoshi Liu](https://openaccess.thecvf.com/ICCV2023#), [Rundi Wu](https://openaccess.thecvf.com/ICCV2023#), [Basile Van Hoorick](https://openaccess.thecvf.com/ICCV2023#), [Pavel Tokmakov](https://openaccess.thecvf.com/ICCV2023#), [Sergey Zakharov](https://openaccess.thecvf.com/ICCV2023#), [Carl Vondrick](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Zero-1-to-3_Zero-shot_One_Image_to_3D_Object_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Zero-1-to-3_Zero-shot_One_ICCV_2023_supplemental.zip)] 

[bibtex]


[Low-Light Image Enhancement with Multi-Stage Residue Quantization and Brightness-Aware Attention](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Low-Light_Image_Enhancement_with_Multi-Stage_Residue_Quantization_and_Brightness-Aware_Attention_ICCV_2023_paper.html)

[Yunlong Liu](https://openaccess.thecvf.com/ICCV2023#), [Tao Huang](https://openaccess.thecvf.com/ICCV2023#), [Weisheng Dong](https://openaccess.thecvf.com/ICCV2023#), [Fangfang Wu](https://openaccess.thecvf.com/ICCV2023#), [Xin Li](https://openaccess.thecvf.com/ICCV2023#), [Guangming Shi](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Low-Light_Image_Enhancement_with_Multi-Stage_Residue_Quantization_and_Brightness-Aware_Attention_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Low-Light_Image_Enhancement_ICCV_2023_supplemental.pdf)] 

[bibtex]


[DynamicISP: Dynamically Controlled Image Signal Processor for Image Recognition](https://openaccess.thecvf.com/content/ICCV2023/html/Yoshimura_DynamicISP_Dynamically_Controlled_Image_Signal_Processor_for_Image_Recognition_ICCV_2023_paper.html)

[Masakazu Yoshimura](https://openaccess.thecvf.com/ICCV2023#), [Junji Otsuka](https://openaccess.thecvf.com/ICCV2023#), [Atsushi Irie](https://openaccess.thecvf.com/ICCV2023#), [Takeshi Ohashi](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yoshimura_DynamicISP_Dynamically_Controlled_Image_Signal_Processor_for_Image_Recognition_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yoshimura_DynamicISP_Dynamically_Controlled_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.01146)] 

[bibtex]


[Reconstructed Convolution Module Based Look-Up Tables for Efficient Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Reconstructed_Convolution_Module_Based_Look-Up_Tables_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.html)

[Guandu Liu](https://openaccess.thecvf.com/ICCV2023#), [Yukang Ding](https://openaccess.thecvf.com/ICCV2023#), [Mading Li](https://openaccess.thecvf.com/ICCV2023#), [Ming Sun](https://openaccess.thecvf.com/ICCV2023#), [Xing Wen](https://openaccess.thecvf.com/ICCV2023#), [Bin Wang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Reconstructed_Convolution_Module_Based_Look-Up_Tables_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2307.08544)] 

[bibtex]


[TIFA: Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_TIFA_Accurate_and_Interpretable_Text-to-Image_Faithfulness_Evaluation_with_Question_Answering_ICCV_2023_paper.html)

[Yushi Hu](https://openaccess.thecvf.com/ICCV2023#), [Benlin Liu](https://openaccess.thecvf.com/ICCV2023#), [Jungo Kasai](https://openaccess.thecvf.com/ICCV2023#), [Yizhong Wang](https://openaccess.thecvf.com/ICCV2023#), [Mari Ostendorf](https://openaccess.thecvf.com/ICCV2023#), [Ranjay Krishna](https://openaccess.thecvf.com/ICCV2023#), [Noah A. Smith](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_TIFA_Accurate_and_Interpretable_Text-to-Image_Faithfulness_Evaluation_with_Question_Answering_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_TIFA_Accurate_and_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.11897)] 

[bibtex]


[3DHumanGAN: 3D-Aware Human Image Generation with 3D Pose Mapping](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_3DHumanGAN_3D-Aware_Human_Image_Generation_with_3D_Pose_Mapping_ICCV_2023_paper.html)

[Zhuoqian Yang](https://openaccess.thecvf.com/ICCV2023#), [Shikai Li](https://openaccess.thecvf.com/ICCV2023#), [Wayne Wu](https://openaccess.thecvf.com/ICCV2023#), [Bo Dai](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_3DHumanGAN_3D-Aware_Human_Image_Generation_with_3D_Pose_Mapping_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_3DHumanGAN_3D-Aware_Human_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2212.07378)] 

[bibtex]


[Degradation-Resistant Unfolding Network for Heterogeneous Image Fusion](https://openaccess.thecvf.com/content/ICCV2023/html/He_Degradation-Resistant_Unfolding_Network_for_Heterogeneous_Image_Fusion_ICCV_2023_paper.html)

[Chunming He](https://openaccess.thecvf.com/ICCV2023#), [Kai Li](https://openaccess.thecvf.com/ICCV2023#), [Guoxia Xu](https://openaccess.thecvf.com/ICCV2023#), [Yulun Zhang](https://openaccess.thecvf.com/ICCV2023#), [Runze Hu](https://openaccess.thecvf.com/ICCV2023#), [Zhenhua Guo](https://openaccess.thecvf.com/ICCV2023#), [Xiu Li](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Degradation-Resistant_Unfolding_Network_for_Heterogeneous_Image_Fusion_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/He_Degradation-Resistant_Unfolding_Network_ICCV_2023_supplemental.pdf)] 

[bibtex]


[MI-GAN: A Simple Baseline for Image Inpainting on Mobile Devices](https://openaccess.thecvf.com/content/ICCV2023/html/Sargsyan_MI-GAN_A_Simple_Baseline_for_Image_Inpainting_on_Mobile_Devices_ICCV_2023_paper.html)

[Andranik Sargsyan](https://openaccess.thecvf.com/ICCV2023#), [Shant Navasardyan](https://openaccess.thecvf.com/ICCV2023#), [Xingqian Xu](https://openaccess.thecvf.com/ICCV2023#), [Humphrey Shi](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sargsyan_MI-GAN_A_Simple_Baseline_for_Image_Inpainting_on_Mobile_Devices_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sargsyan_MI-GAN_A_Simple_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Unleashing Vanilla Vision Transformer with Masked Image Modeling for Object Detection](https://openaccess.thecvf.com/content/ICCV2023/html/Fang_Unleashing_Vanilla_Vision_Transformer_with_Masked_Image_Modeling_for_Object_ICCV_2023_paper.html)

[Yuxin Fang](https://openaccess.thecvf.com/ICCV2023#), [Shusheng Yang](https://openaccess.thecvf.com/ICCV2023#), [Shijie Wang](https://openaccess.thecvf.com/ICCV2023#), [Yixiao Ge](https://openaccess.thecvf.com/ICCV2023#), [Ying Shan](https://openaccess.thecvf.com/ICCV2023#), [Xinggang Wang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fang_Unleashing_Vanilla_Vision_Transformer_with_Masked_Image_Modeling_for_Object_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fang_Unleashing_Vanilla_Vision_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2204.02964)] 

[bibtex]


[Zero-Shot Composed Image Retrieval with Textual Inversion](https://openaccess.thecvf.com/content/ICCV2023/html/Baldrati_Zero-Shot_Composed_Image_Retrieval_with_Textual_Inversion_ICCV_2023_paper.html)

[Alberto Baldrati](https://openaccess.thecvf.com/ICCV2023#), [Lorenzo Agnolucci](https://openaccess.thecvf.com/ICCV2023#), [Marco Bertini](https://openaccess.thecvf.com/ICCV2023#), [Alberto Del Bimbo](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Baldrati_Zero-Shot_Composed_Image_Retrieval_with_Textual_Inversion_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Baldrati_Zero-Shot_Composed_Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.15247)] 

[bibtex]


[COOL-CHIC: Coordinate-based Low Complexity Hierarchical Image Codec](https://openaccess.thecvf.com/content/ICCV2023/html/Ladune_COOL-CHIC_Coordinate-based_Low_Complexity_Hierarchical_Image_Codec_ICCV_2023_paper.html)

[Théo Ladune](https://openaccess.thecvf.com/ICCV2023#), [Pierrick Philippe](https://openaccess.thecvf.com/ICCV2023#), [Félix Henry](https://openaccess.thecvf.com/ICCV2023#), [Gordon Clare](https://openaccess.thecvf.com/ICCV2023#), [Thomas Leguay](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ladune_COOL-CHIC_Coordinate-based_Low_Complexity_Hierarchical_Image_Codec_ICCV_2023_paper.pdf)] 

[bibtex]


[What Does a Platypus Look Like? Generating Customized Prompts for Zero-Shot Image Classification](https://openaccess.thecvf.com/content/ICCV2023/html/Pratt_What_Does_a_Platypus_Look_Like_Generating_Customized_Prompts_for_ICCV_2023_paper.html)

[Sarah Pratt](https://openaccess.thecvf.com/ICCV2023#), [Ian Covert](https://openaccess.thecvf.com/ICCV2023#), [Rosanne Liu](https://openaccess.thecvf.com/ICCV2023#), [Ali Farhadi](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pratt_What_Does_a_Platypus_Look_Like_Generating_Customized_Prompts_for_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pratt_What_Does_a_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2209.03320)] 

[bibtex]


[PatchCT: Aligning Patch Set and Label Set with Conditional Transport for Multi-Label Image Classification](https://openaccess.thecvf.com/content/ICCV2023/html/Li_PatchCT_Aligning_Patch_Set_and_Label_Set_with_Conditional_Transport_ICCV_2023_paper.html)

[Miaoge Li](https://openaccess.thecvf.com/ICCV2023#), [Dongsheng Wang](https://openaccess.thecvf.com/ICCV2023#), [Xinyang Liu](https://openaccess.thecvf.com/ICCV2023#), [Zequn Zeng](https://openaccess.thecvf.com/ICCV2023#), [Ruiying Lu](https://openaccess.thecvf.com/ICCV2023#), [Bo Chen](https://openaccess.thecvf.com/ICCV2023#), [Mingyuan Zhou](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_PatchCT_Aligning_Patch_Set_and_Label_Set_with_Conditional_Transport_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2307.09066)] 

[bibtex]


[MRM: Masked Relation Modeling for Medical Image Pre-Training with Genetics](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_MRM_Masked_Relation_Modeling_for_Medical_Image_Pre-Training_with_Genetics_ICCV_2023_paper.html)

[Qiushi Yang](https://openaccess.thecvf.com/ICCV2023#), [Wuyang Li](https://openaccess.thecvf.com/ICCV2023#), [Baopu Li](https://openaccess.thecvf.com/ICCV2023#), [Yixuan Yuan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_MRM_Masked_Relation_Modeling_for_Medical_Image_Pre-Training_with_Genetics_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_MRM_Masked_Relation_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Multi-interactive Feature Learning and a Full-time Multi-modality Benchmark for Image Fusion and Segmentation](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Multi-interactive_Feature_Learning_and_a_Full-time_Multi-modality_Benchmark_for_Image_ICCV_2023_paper.html)

[Jinyuan Liu](https://openaccess.thecvf.com/ICCV2023#), [Zhu Liu](https://openaccess.thecvf.com/ICCV2023#), [Guanyao Wu](https://openaccess.thecvf.com/ICCV2023#), [Long Ma](https://openaccess.thecvf.com/ICCV2023#), [Risheng Liu](https://openaccess.thecvf.com/ICCV2023#), [Wei Zhong](https://openaccess.thecvf.com/ICCV2023#), [Zhongxuan Luo](https://openaccess.thecvf.com/ICCV2023#), [Xin Fan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Multi-interactive_Feature_Learning_and_a_Full-time_Multi-modality_Benchmark_for_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Multi-interactive_Feature_Learning_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2308.02097)] 

[bibtex]


[Boosting Single Image Super-Resolution via Partial Channel Shifting](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Boosting_Single_Image_Super-Resolution_via_Partial_Channel_Shifting_ICCV_2023_paper.html)

[Xiaoming Zhang](https://openaccess.thecvf.com/ICCV2023#), [Tianrui Li](https://openaccess.thecvf.com/ICCV2023#), [Xiaole Zhao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Boosting_Single_Image_Super-Resolution_via_Partial_Channel_Shifting_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Boosting_Single_Image_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Tune-A-Video_One-Shot_Tuning_of_Image_Diffusion_Models_for_Text-to-Video_Generation_ICCV_2023_paper.html)

[Jay Zhangjie Wu](https://openaccess.thecvf.com/ICCV2023#), [Yixiao Ge](https://openaccess.thecvf.com/ICCV2023#), [Xintao Wang](https://openaccess.thecvf.com/ICCV2023#), [Stan Weixian Lei](https://openaccess.thecvf.com/ICCV2023#), [Yuchao Gu](https://openaccess.thecvf.com/ICCV2023#), [Yufei Shi](https://openaccess.thecvf.com/ICCV2023#), [Wynne Hsu](https://openaccess.thecvf.com/ICCV2023#), [Ying Shan](https://openaccess.thecvf.com/ICCV2023#), [Xiaohu Qie](https://openaccess.thecvf.com/ICCV2023#), [Mike Zheng Shou](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Tune-A-Video_One-Shot_Tuning_of_Image_Diffusion_Models_for_Text-to-Video_Generation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Tune-A-Video_One-Shot_Tuning_of_Image_Diffusion_Models_for_Text-to-Video_Generation_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Weakly Supervised Referring Image Segmentation with Intra-Chunk and Inter-Chunk Consistency](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Weakly_Supervised_Referring_Image_Segmentation_with_Intra-Chunk_and_Inter-Chunk_Consistency_ICCV_2023_paper.html)

[Jungbeom Lee](https://openaccess.thecvf.com/ICCV2023#), [Sungjin Lee](https://openaccess.thecvf.com/ICCV2023#), [Jinseok Nam](https://openaccess.thecvf.com/ICCV2023#), [Seunghak Yu](https://openaccess.thecvf.com/ICCV2023#), [Jaeyoung Do](https://openaccess.thecvf.com/ICCV2023#), [Tara Taghavi](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Weakly_Supervised_Referring_Image_Segmentation_with_Intra-Chunk_and_Inter-Chunk_Consistency_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Weakly_Supervised_Referring_ICCV_2023_supplemental.pdf)] 

[bibtex]


[SimFIR: A Simple Framework for Fisheye Image Rectification with Self-supervised Representation Learning](https://openaccess.thecvf.com/content/ICCV2023/html/Feng_SimFIR_A_Simple_Framework_for_Fisheye_Image_Rectification_with_Self-supervised_ICCV_2023_paper.html)

[Hao Feng](https://openaccess.thecvf.com/ICCV2023#), [Wendi Wang](https://openaccess.thecvf.com/ICCV2023#), [Jiajun Deng](https://openaccess.thecvf.com/ICCV2023#), [Wengang Zhou](https://openaccess.thecvf.com/ICCV2023#), [Li Li](https://openaccess.thecvf.com/ICCV2023#), [Houqiang Li](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_SimFIR_A_Simple_Framework_for_Fisheye_Image_Rectification_with_Self-supervised_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Feng_SimFIR_A_Simple_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.09040)] 

[bibtex]


[Learning Support and Trivial Prototypes for Interpretable Image Classification](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Learning_Support_and_Trivial_Prototypes_for_Interpretable_Image_Classification_ICCV_2023_paper.html)

[Chong Wang](https://openaccess.thecvf.com/ICCV2023#), [Yuyuan Liu](https://openaccess.thecvf.com/ICCV2023#), [Yuanhong Chen](https://openaccess.thecvf.com/ICCV2023#), [Fengbei Liu](https://openaccess.thecvf.com/ICCV2023#), [Yu Tian](https://openaccess.thecvf.com/ICCV2023#), [Davis McCarthy](https://openaccess.thecvf.com/ICCV2023#), [Helen Frazer](https://openaccess.thecvf.com/ICCV2023#), [Gustavo Carneiro](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Learning_Support_and_Trivial_Prototypes_for_Interpretable_Image_Classification_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Learning_Support_and_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2301.04011)] 

[bibtex]


[Learning Continuous Exposure Value Representations for Single-Image HDR Reconstruction](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Learning_Continuous_Exposure_Value_Representations_for_Single-Image_HDR_Reconstruction_ICCV_2023_paper.html)

[Su-Kai Chen](https://openaccess.thecvf.com/ICCV2023#), [Hung-Lin Yen](https://openaccess.thecvf.com/ICCV2023#), [Yu-Lun Liu](https://openaccess.thecvf.com/ICCV2023#), [Min-Hung Chen](https://openaccess.thecvf.com/ICCV2023#), [Hou-Ning Hu](https://openaccess.thecvf.com/ICCV2023#), [Wen-Hsiao Peng](https://openaccess.thecvf.com/ICCV2023#), [Yen-Yu Lin](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Learning_Continuous_Exposure_Value_Representations_for_Single-Image_HDR_Reconstruction_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Learning_Continuous_Exposure_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2309.03900)] 

[bibtex]


[Dense Text-to-Image Generation with Attention Modulation](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Dense_Text-to-Image_Generation_with_Attention_Modulation_ICCV_2023_paper.html)

[Yunji Kim](https://openaccess.thecvf.com/ICCV2023#), [Jiyoung Lee](https://openaccess.thecvf.com/ICCV2023#), [Jin-Hwa Kim](https://openaccess.thecvf.com/ICCV2023#), [Jung-Woo Ha](https://openaccess.thecvf.com/ICCV2023#), [Jun-Yan Zhu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Dense_Text-to-Image_Generation_with_Attention_Modulation_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2308.12964)] 

[bibtex]


[Breaking Temporal Consistency: Generating Video Universal Adversarial Perturbations Using Image Models](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Breaking_Temporal_Consistency_Generating_Video_Universal_Adversarial_Perturbations_Using_Image_ICCV_2023_paper.html)

[Hee-Seon Kim](https://openaccess.thecvf.com/ICCV2023#), [Minji Son](https://openaccess.thecvf.com/ICCV2023#), [Minbeom Kim](https://openaccess.thecvf.com/ICCV2023#), [Myung-Joon Kwon](https://openaccess.thecvf.com/ICCV2023#), [Changick Kim](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Breaking_Temporal_Consistency_Generating_Video_Universal_Adversarial_Perturbations_Using_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Breaking_Temporal_Consistency_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Iterative Prompt Learning for Unsupervised Backlit Image Enhancement](https://openaccess.thecvf.com/content/ICCV2023/html/Liang_Iterative_Prompt_Learning_for_Unsupervised_Backlit_Image_Enhancement_ICCV_2023_paper.html)

[Zhexin Liang](https://openaccess.thecvf.com/ICCV2023#), [Chongyi Li](https://openaccess.thecvf.com/ICCV2023#), [Shangchen Zhou](https://openaccess.thecvf.com/ICCV2023#), [Ruicheng Feng](https://openaccess.thecvf.com/ICCV2023#), [Chen Change Loy](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liang_Iterative_Prompt_Learning_for_Unsupervised_Backlit_Image_Enhancement_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liang_Iterative_Prompt_Learning_for_Unsupervised_Backlit_Image_Enhancement_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.17569)] 

[bibtex]


[InterFormer: Real-time Interactive Image Segmentation](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_InterFormer_Real-time_Interactive_Image_Segmentation_ICCV_2023_paper.html)

[You Huang](https://openaccess.thecvf.com/ICCV2023#), [Hao Yang](https://openaccess.thecvf.com/ICCV2023#), [Ke Sun](https://openaccess.thecvf.com/ICCV2023#), [Shengchuan Zhang](https://openaccess.thecvf.com/ICCV2023#), [Liujuan Cao](https://openaccess.thecvf.com/ICCV2023#), [Guannan Jiang](https://openaccess.thecvf.com/ICCV2023#), [Rongrong Ji](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_InterFormer_Real-time_Interactive_Image_Segmentation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_InterFormer_Real-time_Interactive_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2304.02942)] 

[bibtex]


[COMPASS: High-Efficiency Deep Image Compression with Arbitrary-scale Spatial Scalability](https://openaccess.thecvf.com/content/ICCV2023/html/Park_COMPASS_High-Efficiency_Deep_Image_Compression_with_Arbitrary-scale_Spatial_Scalability_ICCV_2023_paper.html)

[Jongmin Park](https://openaccess.thecvf.com/ICCV2023#), [Jooyoung Lee](https://openaccess.thecvf.com/ICCV2023#), [Munchurl Kim](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Park_COMPASS_High-Efficiency_Deep_Image_Compression_with_Arbitrary-scale_Spatial_Scalability_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Park_COMPASS_High-Efficiency_Deep_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.07926)] 

[bibtex]


[Multiscale Structure Guided Diffusion for Image Deblurring](https://openaccess.thecvf.com/content/ICCV2023/html/Ren_Multiscale_Structure_Guided_Diffusion_for_Image_Deblurring_ICCV_2023_paper.html)

[Mengwei Ren](https://openaccess.thecvf.com/ICCV2023#), [Mauricio Delbracio](https://openaccess.thecvf.com/ICCV2023#), [Hossein Talebi](https://openaccess.thecvf.com/ICCV2023#), [Guido Gerig](https://openaccess.thecvf.com/ICCV2023#), [Peyman Milanfar](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_Multiscale_Structure_Guided_Diffusion_for_Image_Deblurring_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ren_Multiscale_Structure_Guided_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.01789)] 

[bibtex]


[ASIC: Aligning Sparse in-the-wild Image Collections](https://openaccess.thecvf.com/content/ICCV2023/html/Gupta_ASIC_Aligning_Sparse_in-the-wild_Image_Collections_ICCV_2023_paper.html)

[Kamal Gupta](https://openaccess.thecvf.com/ICCV2023#), [Varun Jampani](https://openaccess.thecvf.com/ICCV2023#), [Carlos Esteves](https://openaccess.thecvf.com/ICCV2023#), [Abhinav Shrivastava](https://openaccess.thecvf.com/ICCV2023#), [Ameesh Makadia](https://openaccess.thecvf.com/ICCV2023#), [Noah Snavely](https://openaccess.thecvf.com/ICCV2023#), [Abhishek Kar](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gupta_ASIC_Aligning_Sparse_in-the-wild_Image_Collections_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gupta_ASIC_Aligning_Sparse_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.16201)] 

[bibtex]


[Unsupervised Feature Representation Learning for Domain-generalized Cross-domain Image Retrieval](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Unsupervised_Feature_Representation_Learning_for_Domain-generalized_Cross-domain_Image_Retrieval_ICCV_2023_paper.html)

[Conghui Hu](https://openaccess.thecvf.com/ICCV2023#), [Can Zhang](https://openaccess.thecvf.com/ICCV2023#), [Gim Hee Lee](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Unsupervised_Feature_Representation_Learning_for_Domain-generalized_Cross-domain_Image_Retrieval_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_Unsupervised_Feature_Representation_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Dec-Adapter: Exploring Efficient Decoder-Side Adapter for Bridging Screen Content and Natural Image Compression](https://openaccess.thecvf.com/content/ICCV2023/html/Shen_Dec-Adapter_Exploring_Efficient_Decoder-Side_Adapter_for_Bridging_Screen_Content_and_ICCV_2023_paper.html)

[Sheng Shen](https://openaccess.thecvf.com/ICCV2023#), [Huanjing Yue](https://openaccess.thecvf.com/ICCV2023#), [Jingyu Yang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Dec-Adapter_Exploring_Efficient_Decoder-Side_Adapter_for_Bridging_Screen_Content_and_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shen_Dec-Adapter_Exploring_Efficient_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Under-Display Camera Image Restoration with Scattering Effect](https://openaccess.thecvf.com/content/ICCV2023/html/Song_Under-Display_Camera_Image_Restoration_with_Scattering_Effect_ICCV_2023_paper.html)

[Binbin Song](https://openaccess.thecvf.com/ICCV2023#), [Xiangyu Chen](https://openaccess.thecvf.com/ICCV2023#), [Shuning Xu](https://openaccess.thecvf.com/ICCV2023#), [Jiantao Zhou](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Song_Under-Display_Camera_Image_Restoration_with_Scattering_Effect_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Song_Under-Display_Camera_Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.04163)] 

[bibtex]


[3DMiner: Discovering Shapes from Large-Scale Unannotated Image Datasets](https://openaccess.thecvf.com/content/ICCV2023/html/Cheng_3DMiner_Discovering_Shapes_from_Large-Scale_Unannotated_Image_Datasets_ICCV_2023_paper.html)

[Ta-Ying Cheng](https://openaccess.thecvf.com/ICCV2023#), [Matheus Gadelha](https://openaccess.thecvf.com/ICCV2023#), [Sören Pirk](https://openaccess.thecvf.com/ICCV2023#), [Thibault Groueix](https://openaccess.thecvf.com/ICCV2023#), [Radomír Měch](https://openaccess.thecvf.com/ICCV2023#), [Andrew Markham](https://openaccess.thecvf.com/ICCV2023#), [Niki Trigoni](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cheng_3DMiner_Discovering_Shapes_from_Large-Scale_Unannotated_Image_Datasets_ICCV_2023_paper.pdf)] 

[bibtex]


[Identification of Systematic Errors of Image Classifiers on Rare Subgroups](https://openaccess.thecvf.com/content/ICCV2023/html/Metzen_Identification_of_Systematic_Errors_of_Image_Classifiers_on_Rare_Subgroups_ICCV_2023_paper.html)

[Jan Hendrik Metzen](https://openaccess.thecvf.com/ICCV2023#), [Robin Hutmacher](https://openaccess.thecvf.com/ICCV2023#), [N. Grace Hua](https://openaccess.thecvf.com/ICCV2023#), [Valentyn Boreiko](https://openaccess.thecvf.com/ICCV2023#), [Dan Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Metzen_Identification_of_Systematic_Errors_of_Image_Classifiers_on_Rare_Subgroups_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Metzen_Identification_of_Systematic_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.05072)] 

[bibtex]


[CDUL: CLIP-Driven Unsupervised Learning for Multi-Label Image Classification](https://openaccess.thecvf.com/content/ICCV2023/html/Abdelfattah_CDUL_CLIP-Driven_Unsupervised_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.html)

[Rabab Abdelfattah](https://openaccess.thecvf.com/ICCV2023#), [Qing Guo](https://openaccess.thecvf.com/ICCV2023#), [Xiaoguang Li](https://openaccess.thecvf.com/ICCV2023#), [Xiaofeng Wang](https://openaccess.thecvf.com/ICCV2023#), [Song Wang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Abdelfattah_CDUL_CLIP-Driven_Unsupervised_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2307.16634)] 

[bibtex]


[Image-Free Classifier Injection for Zero-Shot Classification](https://openaccess.thecvf.com/content/ICCV2023/html/Christensen_Image-Free_Classifier_Injection_for_Zero-Shot_Classification_ICCV_2023_paper.html)

[Anders Christensen](https://openaccess.thecvf.com/ICCV2023#), [Massimiliano Mancini](https://openaccess.thecvf.com/ICCV2023#), [A. Sophia Koepke](https://openaccess.thecvf.com/ICCV2023#), [Ole Winther](https://openaccess.thecvf.com/ICCV2023#), [Zeynep Akata](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Christensen_Image-Free_Classifier_Injection_for_Zero-Shot_Classification_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Christensen_Image-Free_Classifier_Injection_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.10599)] 

[bibtex]


[Multi-Scale Residual Low-Pass Filter Network for Image Deblurring](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Multi-Scale_Residual_Low-Pass_Filter_Network_for_Image_Deblurring_ICCV_2023_paper.html)

[Jiangxin Dong](https://openaccess.thecvf.com/ICCV2023#), [Jinshan Pan](https://openaccess.thecvf.com/ICCV2023#), [Zhongbao Yang](https://openaccess.thecvf.com/ICCV2023#), [Jinhui Tang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Multi-Scale_Residual_Low-Pass_Filter_Network_for_Image_Deblurring_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_Multi-Scale_Residual_Low-Pass_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Semantically Structured Image Compression via Irregular Group-Based Decoupling](https://openaccess.thecvf.com/content/ICCV2023/html/Feng_Semantically_Structured_Image_Compression_via_Irregular_Group-Based_Decoupling_ICCV_2023_paper.html)

[Ruoyu Feng](https://openaccess.thecvf.com/ICCV2023#), [Yixin Gao](https://openaccess.thecvf.com/ICCV2023#), [Xin Jin](https://openaccess.thecvf.com/ICCV2023#), [Runsen Feng](https://openaccess.thecvf.com/ICCV2023#), [Zhibo Chen](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Feng_Semantically_Structured_Image_Compression_via_Irregular_Group-Based_Decoupling_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Feng_Semantically_Structured_Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2305.02586)] 

[bibtex]


[SEMPART: Self-supervised Multi-resolution Partitioning of Image Semantics](https://openaccess.thecvf.com/content/ICCV2023/html/Ravindran_SEMPART_Self-supervised_Multi-resolution_Partitioning_of_Image_Semantics_ICCV_2023_paper.html)

[Sriram Ravindran](https://openaccess.thecvf.com/ICCV2023#), [Debraj Basu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ravindran_SEMPART_Self-supervised_Multi-resolution_Partitioning_of_Image_Semantics_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ravindran_SEMPART_Self-supervised_Multi-resolution_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.10972)] 

[bibtex]


[Preserving Tumor Volumes for Unsupervised Medical Image Registration](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Preserving_Tumor_Volumes_for_Unsupervised_Medical_Image_Registration_ICCV_2023_paper.html)

[Qihua Dong](https://openaccess.thecvf.com/ICCV2023#), [Hao Du](https://openaccess.thecvf.com/ICCV2023#), [Ying Song](https://openaccess.thecvf.com/ICCV2023#), [Yan Xu](https://openaccess.thecvf.com/ICCV2023#), [Jing Liao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Preserving_Tumor_Volumes_for_Unsupervised_Medical_Image_Registration_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_Preserving_Tumor_Volumes_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.10153)] 

[bibtex]


[Towards Real-World Burst Image Super-Resolution: Benchmark and Method](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_Towards_Real-World_Burst_Image_Super-Resolution_Benchmark_and_Method_ICCV_2023_paper.html)

[Pengxu Wei](https://openaccess.thecvf.com/ICCV2023#), [Yujing Sun](https://openaccess.thecvf.com/ICCV2023#), [Xingbei Guo](https://openaccess.thecvf.com/ICCV2023#), [Chang Liu](https://openaccess.thecvf.com/ICCV2023#), [Guanbin Li](https://openaccess.thecvf.com/ICCV2023#), [Jie Chen](https://openaccess.thecvf.com/ICCV2023#), [Xiangyang Ji](https://openaccess.thecvf.com/ICCV2023#), [Liang Lin](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_Towards_Real-World_Burst_Image_Super-Resolution_Benchmark_and_Method_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_Towards_Real-World_Burst_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Misalign, Contrast then Distill: Rethinking Misalignments in Language-Image Pre-training](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Misalign_Contrast_then_Distill_Rethinking_Misalignments_in_Language-Image_Pre-training_ICCV_2023_paper.html)

[Bumsoo Kim](https://openaccess.thecvf.com/ICCV2023#), [Yeonsik Jo](https://openaccess.thecvf.com/ICCV2023#), [Jinhyung Kim](https://openaccess.thecvf.com/ICCV2023#), [Seunghwan Kim](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Misalign_Contrast_then_Distill_Rethinking_Misalignments_in_Language-Image_Pre-training_ICCV_2023_paper.pdf)] 

[bibtex]


[Two Birds, One Stone: A Unified Framework for Joint Learning of Image and Video Style Transfers](https://openaccess.thecvf.com/content/ICCV2023/html/Gu_Two_Birds_One_Stone_A_Unified_Framework_for_Joint_Learning_ICCV_2023_paper.html)

[Bohai Gu](https://openaccess.thecvf.com/ICCV2023#), [Heng Fan](https://openaccess.thecvf.com/ICCV2023#), [Libo Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gu_Two_Birds_One_Stone_A_Unified_Framework_for_Joint_Learning_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gu_Two_Birds_One_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2304.11335)] 

[bibtex]


[Beyond Image Borders: Learning Feature Extrapolation for Unbounded Image Composition](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Beyond_Image_Borders_Learning_Feature_Extrapolation_for_Unbounded_Image_Composition_ICCV_2023_paper.html)

[Xiaoyu Liu](https://openaccess.thecvf.com/ICCV2023#), [Ming Liu](https://openaccess.thecvf.com/ICCV2023#), [Junyi Li](https://openaccess.thecvf.com/ICCV2023#), [Shuai Liu](https://openaccess.thecvf.com/ICCV2023#), [Xiaotao Wang](https://openaccess.thecvf.com/ICCV2023#), [Lei Lei](https://openaccess.thecvf.com/ICCV2023#), [Wangmeng Zuo](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Beyond_Image_Borders_Learning_Feature_Extrapolation_for_Unbounded_Image_Composition_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Beyond_Image_Borders_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.12042)] 

[bibtex]


[MasaCtrl: Tuning-Free Mutual Self-Attention Control for Consistent Image Synthesis and Editing](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_MasaCtrl_Tuning-Free_Mutual_Self-Attention_Control_for_Consistent_Image_Synthesis_and_ICCV_2023_paper.html)

[Mingdeng Cao](https://openaccess.thecvf.com/ICCV2023#), [Xintao Wang](https://openaccess.thecvf.com/ICCV2023#), [Zhongang Qi](https://openaccess.thecvf.com/ICCV2023#), [Ying Shan](https://openaccess.thecvf.com/ICCV2023#), [Xiaohu Qie](https://openaccess.thecvf.com/ICCV2023#), [Yinqiang Zheng](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_MasaCtrl_Tuning-Free_Mutual_Self-Attention_Control_for_Consistent_Image_Synthesis_and_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_MasaCtrl_Tuning-Free_Mutual_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.08465)] 

[bibtex]


[Ablating Concepts in Text-to-Image Diffusion Models](https://openaccess.thecvf.com/content/ICCV2023/html/Kumari_Ablating_Concepts_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html)

[Nupur Kumari](https://openaccess.thecvf.com/ICCV2023#), [Bingliang Zhang](https://openaccess.thecvf.com/ICCV2023#), [Sheng-Yu Wang](https://openaccess.thecvf.com/ICCV2023#), [Eli Shechtman](https://openaccess.thecvf.com/ICCV2023#), [Richard Zhang](https://openaccess.thecvf.com/ICCV2023#), [Jun-Yan Zhu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kumari_Ablating_Concepts_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.13516)] 

[bibtex]


[Masked Diffusion Transformer is a Strong Image Synthesizer](https://openaccess.thecvf.com/content/ICCV2023/html/Gao_Masked_Diffusion_Transformer_is_a_Strong_Image_Synthesizer_ICCV_2023_paper.html)

[Shanghua Gao](https://openaccess.thecvf.com/ICCV2023#), [Pan Zhou](https://openaccess.thecvf.com/ICCV2023#), [Ming-Ming Cheng](https://openaccess.thecvf.com/ICCV2023#), [Shuicheng Yan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Gao_Masked_Diffusion_Transformer_is_a_Strong_Image_Synthesizer_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Gao_Masked_Diffusion_Transformer_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.14389)] 

[bibtex]


[Referring Image Segmentation Using Text Supervision](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_Referring_Image_Segmentation_Using_Text_Supervision_ICCV_2023_paper.html)

[Fang Liu](https://openaccess.thecvf.com/ICCV2023#), [Yuhao Liu](https://openaccess.thecvf.com/ICCV2023#), [Yuqiu Kong](https://openaccess.thecvf.com/ICCV2023#), [Ke Xu](https://openaccess.thecvf.com/ICCV2023#), [Lihe Zhang](https://openaccess.thecvf.com/ICCV2023#), [Baocai Yin](https://openaccess.thecvf.com/ICCV2023#), [Gerhard Hancke](https://openaccess.thecvf.com/ICCV2023#), [Rynson Lau](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_Referring_Image_Segmentation_Using_Text_Supervision_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_Referring_Image_Segmentation_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.14575)] 

[bibtex]


[Beyond One-to-One: Rethinking the Referring Image Segmentation](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_Beyond_One-to-One_Rethinking_the_Referring_Image_Segmentation_ICCV_2023_paper.html)

[Yutao Hu](https://openaccess.thecvf.com/ICCV2023#), [Qixiong Wang](https://openaccess.thecvf.com/ICCV2023#), [Wenqi Shao](https://openaccess.thecvf.com/ICCV2023#), [Enze Xie](https://openaccess.thecvf.com/ICCV2023#), [Zhenguo Li](https://openaccess.thecvf.com/ICCV2023#), [Jungong Han](https://openaccess.thecvf.com/ICCV2023#), [Ping Luo](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_Beyond_One-to-One_Rethinking_the_Referring_Image_Segmentation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_Beyond_One-to-One_Rethinking_the_Referring_Image_Segmentation_ICCV_2023_supplemental.pdf)] 

[bibtex]


[DiffIR: Efficient Diffusion Model for Image Restoration](https://openaccess.thecvf.com/content/ICCV2023/html/Xia_DiffIR_Efficient_Diffusion_Model_for_Image_Restoration_ICCV_2023_paper.html)

[Bin Xia](https://openaccess.thecvf.com/ICCV2023#), [Yulun Zhang](https://openaccess.thecvf.com/ICCV2023#), [Shiyin Wang](https://openaccess.thecvf.com/ICCV2023#), [Yitong Wang](https://openaccess.thecvf.com/ICCV2023#), [Xinglong Wu](https://openaccess.thecvf.com/ICCV2023#), [Yapeng Tian](https://openaccess.thecvf.com/ICCV2023#), [Wenming Yang](https://openaccess.thecvf.com/ICCV2023#), [Luc Van Gool](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_DiffIR_Efficient_Diffusion_Model_for_Image_Restoration_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xia_DiffIR_Efficient_Diffusion_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.09472)] 

[bibtex]


[Evaluating Data Attribution for Text-to-Image Models](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Evaluating_Data_Attribution_for_Text-to-Image_Models_ICCV_2023_paper.html)

[Sheng-Yu Wang](https://openaccess.thecvf.com/ICCV2023#), [Alexei A. Efros](https://openaccess.thecvf.com/ICCV2023#), [Jun-Yan Zhu](https://openaccess.thecvf.com/ICCV2023#), [Richard Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Evaluating_Data_Attribution_for_Text-to-Image_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Evaluating_Data_Attribution_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2306.09345)] 

[bibtex]


[Delta Denoising Score](https://openaccess.thecvf.com/content/ICCV2023/html/Hertz_Delta_Denoising_Score_ICCV_2023_paper.html)

[Amir Hertz](https://openaccess.thecvf.com/ICCV2023#), [Kfir Aberman](https://openaccess.thecvf.com/ICCV2023#), [Daniel Cohen-Or](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hertz_Delta_Denoising_Score_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hertz_Delta_Denoising_Score_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.07090)] 

[bibtex]


[Generative Multiplane Neural Radiance for 3D-Aware Image Generation](https://openaccess.thecvf.com/content/ICCV2023/html/Kumar_Generative_Multiplane_Neural_Radiance_for_3D-Aware_Image_Generation_ICCV_2023_paper.html)

[Amandeep Kumar](https://openaccess.thecvf.com/ICCV2023#), [Ankan Kumar Bhunia](https://openaccess.thecvf.com/ICCV2023#), [Sanath Narayan](https://openaccess.thecvf.com/ICCV2023#), [Hisham Cholakkal](https://openaccess.thecvf.com/ICCV2023#), [Rao Muhammad Anwer](https://openaccess.thecvf.com/ICCV2023#), [Salman Khan](https://openaccess.thecvf.com/ICCV2023#), [Ming-Hsuan Yang](https://openaccess.thecvf.com/ICCV2023#), [Fahad Shahbaz Khan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kumar_Generative_Multiplane_Neural_Radiance_for_3D-Aware_Image_Generation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kumar_Generative_Multiplane_Neural_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2304.01172)] 

[bibtex]


[Editing Implicit Assumptions in Text-to-Image Diffusion Models](https://openaccess.thecvf.com/content/ICCV2023/html/Orgad_Editing_Implicit_Assumptions_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html)

[Hadas Orgad](https://openaccess.thecvf.com/ICCV2023#), [Bahjat Kawar](https://openaccess.thecvf.com/ICCV2023#), [Yonatan Belinkov](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Orgad_Editing_Implicit_Assumptions_in_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Orgad_Editing_Implicit_Assumptions_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.08084)] 

[bibtex]


[SatlasPretrain: A Large-Scale Dataset for Remote Sensing Image Understanding](https://openaccess.thecvf.com/content/ICCV2023/html/Bastani_SatlasPretrain_A_Large-Scale_Dataset_for_Remote_Sensing_Image_Understanding_ICCV_2023_paper.html)

[Favyen Bastani](https://openaccess.thecvf.com/ICCV2023#), [Piper Wolters](https://openaccess.thecvf.com/ICCV2023#), [Ritwik Gupta](https://openaccess.thecvf.com/ICCV2023#), [Joe Ferdinando](https://openaccess.thecvf.com/ICCV2023#), [Aniruddha Kembhavi](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bastani_SatlasPretrain_A_Large-Scale_Dataset_for_Remote_Sensing_Image_Understanding_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bastani_SatlasPretrain_A_Large-Scale_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.15660)] 

[bibtex]


[Empowering Low-Light Image Enhancer through Customized Learnable Priors](https://openaccess.thecvf.com/content/ICCV2023/html/Zheng_Empowering_Low-Light_Image_Enhancer_through_Customized_Learnable_Priors_ICCV_2023_paper.html)

[Naishan Zheng](https://openaccess.thecvf.com/ICCV2023#), [Man Zhou](https://openaccess.thecvf.com/ICCV2023#), [Yanmeng Dong](https://openaccess.thecvf.com/ICCV2023#), [Xiangyu Rui](https://openaccess.thecvf.com/ICCV2023#), [Jie Huang](https://openaccess.thecvf.com/ICCV2023#), [Chongyi Li](https://openaccess.thecvf.com/ICCV2023#), [Feng Zhao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zheng_Empowering_Low-Light_Image_Enhancer_through_Customized_Learnable_Priors_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zheng_Empowering_Low-Light_Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.01958)] 

[bibtex]


[Guiding Image Captioning Models Toward More Specific Captions](https://openaccess.thecvf.com/content/ICCV2023/html/Kornblith_Guiding_Image_Captioning_Models_Toward_More_Specific_Captions_ICCV_2023_paper.html)

[Simon Kornblith](https://openaccess.thecvf.com/ICCV2023#), [Lala Li](https://openaccess.thecvf.com/ICCV2023#), [Zirui Wang](https://openaccess.thecvf.com/ICCV2023#), [Thao Nguyen](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kornblith_Guiding_Image_Captioning_Models_Toward_More_Specific_Captions_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kornblith_Guiding_Image_Captioning_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.16686)] 

[bibtex]


[Affective Image Filter: Reflecting Emotions from Text to Images](https://openaccess.thecvf.com/content/ICCV2023/html/Weng_Affective_Image_Filter_Reflecting_Emotions_from_Text_to_Images_ICCV_2023_paper.html)

[Shuchen Weng](https://openaccess.thecvf.com/ICCV2023#), [Peixuan Zhang](https://openaccess.thecvf.com/ICCV2023#), [Zheng Chang](https://openaccess.thecvf.com/ICCV2023#), [Xinlong Wang](https://openaccess.thecvf.com/ICCV2023#), [Si Li](https://openaccess.thecvf.com/ICCV2023#), [Boxin Shi](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Weng_Affective_Image_Filter_Reflecting_Emotions_from_Text_to_Images_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Weng_Affective_Image_Filter_Reflecting_Emotions_from_Text_to_Images_ICCV_2023_supplemental.pdf)] 

[bibtex]


[TransTIC: Transferring Transformer-based Image Compression from Human Perception to Machine Perception](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_TransTIC_Transferring_Transformer-based_Image_Compression_from_Human_Perception_to_Machine_ICCV_2023_paper.html)

[Yi-Hsin Chen](https://openaccess.thecvf.com/ICCV2023#), [Ying-Chieh Weng](https://openaccess.thecvf.com/ICCV2023#), [Chia-Hao Kao](https://openaccess.thecvf.com/ICCV2023#), [Cheng Chien](https://openaccess.thecvf.com/ICCV2023#), [Wei-Chen Chiu](https://openaccess.thecvf.com/ICCV2023#), [Wen-Hsiao Peng](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_TransTIC_Transferring_Transformer-based_Image_Compression_from_Human_Perception_to_Machine_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_TransTIC_Transferring_Transformer-based_Image_Compression_from_Human_Perception_to_Machine_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2306.05085)] 

[bibtex]


[Deep Image Harmonization with Globally Guided Feature Transformation and Relation Distillation](https://openaccess.thecvf.com/content/ICCV2023/html/Niu_Deep_Image_Harmonization_with_Globally_Guided_Feature_Transformation_and_Relation_ICCV_2023_paper.html)

[Li Niu](https://openaccess.thecvf.com/ICCV2023#), [Linfeng Tan](https://openaccess.thecvf.com/ICCV2023#), [Xinhao Tao](https://openaccess.thecvf.com/ICCV2023#), [Junyan Cao](https://openaccess.thecvf.com/ICCV2023#), [Fengjun Guo](https://openaccess.thecvf.com/ICCV2023#), [Teng Long](https://openaccess.thecvf.com/ICCV2023#), [Liqing Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Deep_Image_Harmonization_with_Globally_Guided_Feature_Transformation_and_Relation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Niu_Deep_Image_Harmonization_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.00356)] 

[bibtex]


[Cross-Ray Neural Radiance Fields for Novel-View Synthesis from Unconstrained Image Collections](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Cross-Ray_Neural_Radiance_Fields_for_Novel-View_Synthesis_from_Unconstrained_Image_ICCV_2023_paper.html)

[Yifan Yang](https://openaccess.thecvf.com/ICCV2023#), [Shuhai Zhang](https://openaccess.thecvf.com/ICCV2023#), [Zixiong Huang](https://openaccess.thecvf.com/ICCV2023#), [Yubing Zhang](https://openaccess.thecvf.com/ICCV2023#), [Mingkui Tan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Cross-Ray_Neural_Radiance_Fields_for_Novel-View_Synthesis_from_Unconstrained_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Cross-Ray_Neural_Radiance_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2307.08093)] 

[bibtex]


[Prompt Tuning Inversion for Text-driven Image Editing Using Diffusion Models](https://openaccess.thecvf.com/content/ICCV2023/html/Dong_Prompt_Tuning_Inversion_for_Text-driven_Image_Editing_Using_Diffusion_Models_ICCV_2023_paper.html)

[Wenkai Dong](https://openaccess.thecvf.com/ICCV2023#), [Song Xue](https://openaccess.thecvf.com/ICCV2023#), [Xiaoyue Duan](https://openaccess.thecvf.com/ICCV2023#), [Shumin Han](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dong_Prompt_Tuning_Inversion_for_Text-driven_Image_Editing_Using_Diffusion_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dong_Prompt_Tuning_Inversion_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2305.04441)] 

[bibtex]


[UniverSeg: Universal Medical Image Segmentation](https://openaccess.thecvf.com/content/ICCV2023/html/Butoi_UniverSeg_Universal_Medical_Image_Segmentation_ICCV_2023_paper.html)

[Victor Ion Butoi](https://openaccess.thecvf.com/ICCV2023#), [Jose Javier Gonzalez Ortiz](https://openaccess.thecvf.com/ICCV2023#), [Tianyu Ma](https://openaccess.thecvf.com/ICCV2023#), [Mert R. Sabuncu](https://openaccess.thecvf.com/ICCV2023#), [John Guttag](https://openaccess.thecvf.com/ICCV2023#), [Adrian V. Dalca](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Butoi_UniverSeg_Universal_Medical_Image_Segmentation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Butoi_UniverSeg_Universal_Medical_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.06131)] 

[bibtex]


[Bayesian Prompt Learning for Image-Language Model Generalization](https://openaccess.thecvf.com/content/ICCV2023/html/Derakhshani_Bayesian_Prompt_Learning_for_Image-Language_Model_Generalization_ICCV_2023_paper.html)

[Mohammad Mahdi Derakhshani](https://openaccess.thecvf.com/ICCV2023#), [Enrique Sanchez](https://openaccess.thecvf.com/ICCV2023#), [Adrian Bulat](https://openaccess.thecvf.com/ICCV2023#), [Victor G. Turrisi da Costa](https://openaccess.thecvf.com/ICCV2023#), [Cees G.M. Snoek](https://openaccess.thecvf.com/ICCV2023#), [Georgios Tzimiropoulos](https://openaccess.thecvf.com/ICCV2023#), [Brais Martinez](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Derakhshani_Bayesian_Prompt_Learning_for_Image-Language_Model_Generalization_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Derakhshani_Bayesian_Prompt_Learning_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2210.02390)] 

[bibtex]


[DreamTeacher: Pretraining Image Backbones with Deep Generative Models](https://openaccess.thecvf.com/content/ICCV2023/html/Li_DreamTeacher_Pretraining_Image_Backbones_with_Deep_Generative_Models_ICCV_2023_paper.html)

[Daiqing Li](https://openaccess.thecvf.com/ICCV2023#), [Huan Ling](https://openaccess.thecvf.com/ICCV2023#), [Amlan Kar](https://openaccess.thecvf.com/ICCV2023#), [David Acuna](https://openaccess.thecvf.com/ICCV2023#), [Seung Wook Kim](https://openaccess.thecvf.com/ICCV2023#), [Karsten Kreis](https://openaccess.thecvf.com/ICCV2023#), [Antonio Torralba](https://openaccess.thecvf.com/ICCV2023#), [Sanja Fidler](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DreamTeacher_Pretraining_Image_Backbones_with_Deep_Generative_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_DreamTeacher_Pretraining_Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.07487)] 

[bibtex]


[Self-supervised Monocular Underwater Depth Recovery, Image Restoration, and a Real-sea Video Dataset](https://openaccess.thecvf.com/content/ICCV2023/html/Varghese_Self-supervised_Monocular_Underwater_Depth_Recovery_Image_Restoration_and_a_Real-sea_ICCV_2023_paper.html)

[Nisha Varghese](https://openaccess.thecvf.com/ICCV2023#), [Ashish Kumar](https://openaccess.thecvf.com/ICCV2023#), [A. N. Rajagopalan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Varghese_Self-supervised_Monocular_Underwater_Depth_Recovery_Image_Restoration_and_a_Real-sea_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Varghese_Self-supervised_Monocular_Underwater_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Sat2Density: Faithful Density Learning from Satellite-Ground Image Pairs](https://openaccess.thecvf.com/content/ICCV2023/html/Qian_Sat2Density_Faithful_Density_Learning_from_Satellite-Ground_Image_Pairs_ICCV_2023_paper.html)

[Ming Qian](https://openaccess.thecvf.com/ICCV2023#), [Jincheng Xiong](https://openaccess.thecvf.com/ICCV2023#), [Gui-Song Xia](https://openaccess.thecvf.com/ICCV2023#), [Nan Xue](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qian_Sat2Density_Faithful_Density_Learning_from_Satellite-Ground_Image_Pairs_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qian_Sat2Density_Faithful_Density_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.14672)] 

[bibtex]


[Expressive Text-to-Image Generation with Rich Text](https://openaccess.thecvf.com/content/ICCV2023/html/Ge_Expressive_Text-to-Image_Generation_with_Rich_Text_ICCV_2023_paper.html)

[Songwei Ge](https://openaccess.thecvf.com/ICCV2023#), [Taesung Park](https://openaccess.thecvf.com/ICCV2023#), [Jun-Yan Zhu](https://openaccess.thecvf.com/ICCV2023#), [Jia-Bin Huang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ge_Expressive_Text-to-Image_Generation_with_Rich_Text_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ge_Expressive_Text-to-Image_Generation_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.06720)] 

[bibtex]


[Foreground Object Search by Distilling Composite Image Feature](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Foreground_Object_Search_by_Distilling_Composite_Image_Feature_ICCV_2023_paper.html)

[Bo Zhang](https://openaccess.thecvf.com/ICCV2023#), [Jiacheng Sui](https://openaccess.thecvf.com/ICCV2023#), [Li Niu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Foreground_Object_Search_by_Distilling_Composite_Image_Feature_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Foreground_Object_Search_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.04990)] 

[bibtex]


[Harnessing the Spatial-Temporal Attention of Diffusion Models for High-Fidelity Text-to-Image Synthesis](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Harnessing_the_Spatial-Temporal_Attention_of_Diffusion_Models_for_High-Fidelity_Text-to-Image_ICCV_2023_paper.html)

[Qiucheng Wu](https://openaccess.thecvf.com/ICCV2023#), [Yujian Liu](https://openaccess.thecvf.com/ICCV2023#), [Handong Zhao](https://openaccess.thecvf.com/ICCV2023#), [Trung Bui](https://openaccess.thecvf.com/ICCV2023#), [Zhe Lin](https://openaccess.thecvf.com/ICCV2023#), [Yang Zhang](https://openaccess.thecvf.com/ICCV2023#), [Shiyu Chang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Harnessing_the_Spatial-Temporal_Attention_of_Diffusion_Models_for_High-Fidelity_Text-to-Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Harnessing_the_Spatial-Temporal_Attention_of_Diffusion_Models_for_High-Fidelity_Text-to-Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.03869)] 

[bibtex]


[Mesh2Tex: Generating Mesh Textures from Image Queries](https://openaccess.thecvf.com/content/ICCV2023/html/Bokhovkin_Mesh2Tex_Generating_Mesh_Textures_from_Image_Queries_ICCV_2023_paper.html)

[Alexey Bokhovkin](https://openaccess.thecvf.com/ICCV2023#), [Shubham Tulsiani](https://openaccess.thecvf.com/ICCV2023#), [Angela Dai](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bokhovkin_Mesh2Tex_Generating_Mesh_Textures_from_Image_Queries_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bokhovkin_Mesh2Tex_Generating_Mesh_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2304.05868)] 

[bibtex]


[RSFNet: A White-Box Image Retouching Approach using Region-Specific Color Filters](https://openaccess.thecvf.com/content/ICCV2023/html/Ouyang_RSFNet_A_White-Box_Image_Retouching_Approach_using_Region-Specific_Color_Filters_ICCV_2023_paper.html)

[Wenqi Ouyang](https://openaccess.thecvf.com/ICCV2023#), [Yi Dong](https://openaccess.thecvf.com/ICCV2023#), [Xiaoyang Kang](https://openaccess.thecvf.com/ICCV2023#), [Peiran Ren](https://openaccess.thecvf.com/ICCV2023#), [Xin Xu](https://openaccess.thecvf.com/ICCV2023#), [Xuansong Xie](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ouyang_RSFNet_A_White-Box_Image_Retouching_Approach_using_Region-Specific_Color_Filters_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ouyang_RSFNet_A_White-Box_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2303.08682)] 

[bibtex]


[Tem-Adapter: Adapting Image-Text Pretraining for Video Question Answer](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Tem-Adapter_Adapting_Image-Text_Pretraining_for_Video_Question_Answer_ICCV_2023_paper.html)

[Guangyi Chen](https://openaccess.thecvf.com/ICCV2023#), [Xiao Liu](https://openaccess.thecvf.com/ICCV2023#), [Guangrun Wang](https://openaccess.thecvf.com/ICCV2023#), [Kun Zhang](https://openaccess.thecvf.com/ICCV2023#), [Philip H.S. Torr](https://openaccess.thecvf.com/ICCV2023#), [Xiao-Ping Zhang](https://openaccess.thecvf.com/ICCV2023#), [Yansong Tang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Tem-Adapter_Adapting_Image-Text_Pretraining_for_Video_Question_Answer_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Tem-Adapter_Adapting_Image-Text_Pretraining_for_Video_Question_Answer_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Perceptual Artifacts Localization for Image Synthesis Tasks](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Perceptual_Artifacts_Localization_for_Image_Synthesis_Tasks_ICCV_2023_paper.html)

[Lingzhi Zhang](https://openaccess.thecvf.com/ICCV2023#), [Zhengjie Xu](https://openaccess.thecvf.com/ICCV2023#), [Connelly Barnes](https://openaccess.thecvf.com/ICCV2023#), [Yuqian Zhou](https://openaccess.thecvf.com/ICCV2023#), [Qing Liu](https://openaccess.thecvf.com/ICCV2023#), [He Zhang](https://openaccess.thecvf.com/ICCV2023#), [Sohrab Amirghodsi](https://openaccess.thecvf.com/ICCV2023#), [Zhe Lin](https://openaccess.thecvf.com/ICCV2023#), [Eli Shechtman](https://openaccess.thecvf.com/ICCV2023#), [Jianbo Shi](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Perceptual_Artifacts_Localization_for_Image_Synthesis_Tasks_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Perceptual_Artifacts_Localization_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Better May Not Be Fairer: A Study on Subgroup Discrepancy in Image Classification](https://openaccess.thecvf.com/content/ICCV2023/html/Chiu_Better_May_Not_Be_Fairer_A_Study_on_Subgroup_Discrepancy_ICCV_2023_paper.html)

[Ming-Chang Chiu](https://openaccess.thecvf.com/ICCV2023#), [Pin-Yu Chen](https://openaccess.thecvf.com/ICCV2023#), [Xuezhe Ma](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chiu_Better_May_Not_Be_Fairer_A_Study_on_Subgroup_Discrepancy_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chiu_Better_May_Not_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.08649)] 

[bibtex]


[Hybrid Spectral Denoising Transformer with Guided Attention](https://openaccess.thecvf.com/content/ICCV2023/html/Lai_Hybrid_Spectral_Denoising_Transformer_with_Guided_Attention_ICCV_2023_paper.html)

[Zeqiang Lai](https://openaccess.thecvf.com/ICCV2023#), [Chenggang Yan](https://openaccess.thecvf.com/ICCV2023#), [Ying Fu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lai_Hybrid_Spectral_Denoising_Transformer_with_Guided_Attention_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lai_Hybrid_Spectral_Denoising_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.09040)] 

[bibtex]


[PourIt!: Weakly-Supervised Liquid Perception from a Single Image for Visual Closed-Loop Robotic Pouring](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_PourIt_Weakly-Supervised_Liquid_Perception_from_a_Single_Image_for_Visual_ICCV_2023_paper.html)

[Haitao Lin](https://openaccess.thecvf.com/ICCV2023#), [Yanwei Fu](https://openaccess.thecvf.com/ICCV2023#), [Xiangyang Xue](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_PourIt_Weakly-Supervised_Liquid_Perception_from_a_Single_Image_for_Visual_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_PourIt_Weakly-Supervised_Liquid_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2307.11299)] 

[bibtex]


[A Latent Space of Stochastic Diffusion Models for Zero-Shot Image Editing and Guidance](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_A_Latent_Space_of_Stochastic_Diffusion_Models_for_Zero-Shot_Image_ICCV_2023_paper.html)

[Chen Henry Wu](https://openaccess.thecvf.com/ICCV2023#), [Fernando De la Torre](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_A_Latent_Space_of_Stochastic_Diffusion_Models_for_Zero-Shot_Image_ICCV_2023_paper.pdf)] 

[bibtex]


[Single Image Defocus Deblurring via Implicit Neural Inverse Kernels](https://openaccess.thecvf.com/content/ICCV2023/html/Quan_Single_Image_Defocus_Deblurring_via_Implicit_Neural_Inverse_Kernels_ICCV_2023_paper.html)

[Yuhui Quan](https://openaccess.thecvf.com/ICCV2023#), [Xin Yao](https://openaccess.thecvf.com/ICCV2023#), [Hui Ji](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Quan_Single_Image_Defocus_Deblurring_via_Implicit_Neural_Inverse_Kernels_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Quan_Single_Image_Defocus_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Unified Pre-Training with Pseudo Texts for Text-To-Image Person Re-Identification](https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Unified_Pre-Training_with_Pseudo_Texts_for_Text-To-Image_Person_Re-Identification_ICCV_2023_paper.html)

[Zhiyin Shao](https://openaccess.thecvf.com/ICCV2023#), [Xinyu Zhang](https://openaccess.thecvf.com/ICCV2023#), [Changxing Ding](https://openaccess.thecvf.com/ICCV2023#), [Jian Wang](https://openaccess.thecvf.com/ICCV2023#), [Jingdong Wang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Unified_Pre-Training_with_Pseudo_Texts_for_Text-To-Image_Person_Re-Identification_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shao_Unified_Pre-Training_with_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.01420)] 

[bibtex]


[Focus the Discrepancy: Intra- and Inter-Correlation Learning for Image Anomaly Detection](https://openaccess.thecvf.com/content/ICCV2023/html/Yao_Focus_the_Discrepancy_Intra-_and_Inter-Correlation_Learning_for_Image_Anomaly_ICCV_2023_paper.html)

[Xincheng Yao](https://openaccess.thecvf.com/ICCV2023#), [Ruoqi Li](https://openaccess.thecvf.com/ICCV2023#), [Zefeng Qian](https://openaccess.thecvf.com/ICCV2023#), [Yan Luo](https://openaccess.thecvf.com/ICCV2023#), [Chongyang Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yao_Focus_the_Discrepancy_Intra-_and_Inter-Correlation_Learning_for_Image_Anomaly_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yao_Focus_the_Discrepancy_ICCV_2023_supplemental.pdf)] 

[bibtex]


[DDFM: Denoising Diffusion Model for Multi-Modality Image Fusion](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_DDFM_Denoising_Diffusion_Model_for_Multi-Modality_Image_Fusion_ICCV_2023_paper.html)

[Zixiang Zhao](https://openaccess.thecvf.com/ICCV2023#), [Haowen Bai](https://openaccess.thecvf.com/ICCV2023#), [Yuanzhi Zhu](https://openaccess.thecvf.com/ICCV2023#), [Jiangshe Zhang](https://openaccess.thecvf.com/ICCV2023#), [Shuang Xu](https://openaccess.thecvf.com/ICCV2023#), [Yulun Zhang](https://openaccess.thecvf.com/ICCV2023#), [Kai Zhang](https://openaccess.thecvf.com/ICCV2023#), [Deyu Meng](https://openaccess.thecvf.com/ICCV2023#), [Radu Timofte](https://openaccess.thecvf.com/ICCV2023#), [Luc Van Gool](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_DDFM_Denoising_Diffusion_Model_for_Multi-Modality_Image_Fusion_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_DDFM_Denoising_Diffusion_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.06840)] 

[bibtex]


[Foreground and Text-lines Aware Document Image Rectification](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Foreground_and_Text-lines_Aware_Document_Image_Rectification_ICCV_2023_paper.html)

[Heng Li](https://openaccess.thecvf.com/ICCV2023#), [Xiangping Wu](https://openaccess.thecvf.com/ICCV2023#), [Qingcai Chen](https://openaccess.thecvf.com/ICCV2023#), [Qianjin Xiang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Foreground_and_Text-lines_Aware_Document_Image_Rectification_ICCV_2023_paper.pdf)] 

[bibtex]


[GrowCLIP: Data-Aware Automatic Model Growing for Large-scale Contrastive Language-Image Pre-Training](https://openaccess.thecvf.com/content/ICCV2023/html/Deng_GrowCLIP_Data-Aware_Automatic_Model_Growing_for_Large-scale_Contrastive_Language-Image_Pre-Training_ICCV_2023_paper.html)

[Xinchi Deng](https://openaccess.thecvf.com/ICCV2023#), [Han Shi](https://openaccess.thecvf.com/ICCV2023#), [Runhui Huang](https://openaccess.thecvf.com/ICCV2023#), [Changlin Li](https://openaccess.thecvf.com/ICCV2023#), [Hang Xu](https://openaccess.thecvf.com/ICCV2023#), [Jianhua Han](https://openaccess.thecvf.com/ICCV2023#), [James Kwok](https://openaccess.thecvf.com/ICCV2023#), [Shen Zhao](https://openaccess.thecvf.com/ICCV2023#), [Wei Zhang](https://openaccess.thecvf.com/ICCV2023#), [Xiaodan Liang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_GrowCLIP_Data-Aware_Automatic_Model_Growing_for_Large-scale_Contrastive_Language-Image_Pre-Training_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Deng_GrowCLIP_Data-Aware_Automatic_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.11331)] 

[bibtex]


[Scene-Aware Label Graph Learning for Multi-Label Image Classification](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Scene-Aware_Label_Graph_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.html)

[Xuelin Zhu](https://openaccess.thecvf.com/ICCV2023#), [Jian Liu](https://openaccess.thecvf.com/ICCV2023#), [Weijia Liu](https://openaccess.thecvf.com/ICCV2023#), [Jiawei Ge](https://openaccess.thecvf.com/ICCV2023#), [Bo Liu](https://openaccess.thecvf.com/ICCV2023#), [Jiuxin Cao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Scene-Aware_Label_Graph_Learning_for_Multi-Label_Image_Classification_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhu_Scene-Aware_Label_Graph_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Relightify: Relightable 3D Faces from a Single Image via Diffusion Models](https://openaccess.thecvf.com/content/ICCV2023/html/Papantoniou_Relightify_Relightable_3D_Faces_from_a_Single_Image_via_Diffusion_ICCV_2023_paper.html)

[Foivos Paraperas Papantoniou](https://openaccess.thecvf.com/ICCV2023#), [Alexandros Lattas](https://openaccess.thecvf.com/ICCV2023#), [Stylianos Moschoglou](https://openaccess.thecvf.com/ICCV2023#), [Stefanos Zafeiriou](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Papantoniou_Relightify_Relightable_3D_Faces_from_a_Single_Image_via_Diffusion_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Papantoniou_Relightify_Relightable_3D_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2305.06077)] 

[bibtex]


[DeFormer: Integrating Transformers with Deformable Models for 3D Shape Abstraction from a Single Image](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_DeFormer_Integrating_Transformers_with_Deformable_Models_for_3D_Shape_Abstraction_ICCV_2023_paper.html)

[Di Liu](https://openaccess.thecvf.com/ICCV2023#), [Xiang Yu](https://openaccess.thecvf.com/ICCV2023#), [Meng Ye](https://openaccess.thecvf.com/ICCV2023#), [Qilong Zhangli](https://openaccess.thecvf.com/ICCV2023#), [Zhuowei Li](https://openaccess.thecvf.com/ICCV2023#), [Zhixing Zhang](https://openaccess.thecvf.com/ICCV2023#), [Dimitris N. Metaxas](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_DeFormer_Integrating_Transformers_with_Deformable_Models_for_3D_Shape_Abstraction_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_DeFormer_Integrating_Transformers_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.12594)] 

[bibtex]


[Continuously Masked Transformer for Image Inpainting](https://openaccess.thecvf.com/content/ICCV2023/html/Ko_Continuously_Masked_Transformer_for_Image_Inpainting_ICCV_2023_paper.html)

[Keunsoo Ko](https://openaccess.thecvf.com/ICCV2023#), [Chang-Su Kim](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ko_Continuously_Masked_Transformer_for_Image_Inpainting_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ko_Continuously_Masked_Transformer_for_Image_Inpainting_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Label-Free Event-based Object Recognition via Joint Learning with Image Reconstruction from Events](https://openaccess.thecvf.com/content/ICCV2023/html/Cho_Label-Free_Event-based_Object_Recognition_via_Joint_Learning_with_Image_Reconstruction_ICCV_2023_paper.html)

[Hoonhee Cho](https://openaccess.thecvf.com/ICCV2023#), [Hyeonseong Kim](https://openaccess.thecvf.com/ICCV2023#), [Yujeong Chae](https://openaccess.thecvf.com/ICCV2023#), [Kuk-Jin Yoon](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_Label-Free_Event-based_Object_Recognition_via_Joint_Learning_with_Image_Reconstruction_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cho_Label-Free_Event-based_Object_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.09383)] 

[bibtex]


[BallGAN: 3D-aware Image Synthesis with a Spherical Background](https://openaccess.thecvf.com/content/ICCV2023/html/Shin_BallGAN_3D-aware_Image_Synthesis_with_a_Spherical_Background_ICCV_2023_paper.html)

[Minjung Shin](https://openaccess.thecvf.com/ICCV2023#), [Yunji Seo](https://openaccess.thecvf.com/ICCV2023#), [Jeongmin Bae](https://openaccess.thecvf.com/ICCV2023#), [Young Sun Choi](https://openaccess.thecvf.com/ICCV2023#), [Hyunsu Kim](https://openaccess.thecvf.com/ICCV2023#), [Hyeran Byun](https://openaccess.thecvf.com/ICCV2023#), [Youngjung Uh](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shin_BallGAN_3D-aware_Image_Synthesis_with_a_Spherical_Background_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shin_BallGAN_3D-aware_Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2301.09091)] 

[bibtex]


[GeoMIM: Towards Better 3D Knowledge Transfer via Masked Image Modeling for Multi-view 3D Understanding](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_GeoMIM_Towards_Better_3D_Knowledge_Transfer_via_Masked_Image_Modeling_ICCV_2023_paper.html)

[Jihao Liu](https://openaccess.thecvf.com/ICCV2023#), [Tai Wang](https://openaccess.thecvf.com/ICCV2023#), [Boxiao Liu](https://openaccess.thecvf.com/ICCV2023#), [Qihang Zhang](https://openaccess.thecvf.com/ICCV2023#), [Yu Liu](https://openaccess.thecvf.com/ICCV2023#), [Hongsheng Li](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_GeoMIM_Towards_Better_3D_Knowledge_Transfer_via_Masked_Image_Modeling_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.11325)] 

[bibtex]


[Transferable Decoding with Visual Entities for Zero-Shot Image Captioning](https://openaccess.thecvf.com/content/ICCV2023/html/Fei_Transferable_Decoding_with_Visual_Entities_for_Zero-Shot_Image_Captioning_ICCV_2023_paper.html)

[Junjie Fei](https://openaccess.thecvf.com/ICCV2023#), [Teng Wang](https://openaccess.thecvf.com/ICCV2023#), [Jinrui Zhang](https://openaccess.thecvf.com/ICCV2023#), [Zhenyu He](https://openaccess.thecvf.com/ICCV2023#), [Chengjie Wang](https://openaccess.thecvf.com/ICCV2023#), [Feng Zheng](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Fei_Transferable_Decoding_with_Visual_Entities_for_Zero-Shot_Image_Captioning_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Fei_Transferable_Decoding_with_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.16525)] 

[bibtex]


[GlueStick: Robust Image Matching by Sticking Points and Lines Together](https://openaccess.thecvf.com/content/ICCV2023/html/Pautrat_GlueStick_Robust_Image_Matching_by_Sticking_Points_and_Lines_Together_ICCV_2023_paper.html)

[Rémi Pautrat](https://openaccess.thecvf.com/ICCV2023#), [Iago Suárez](https://openaccess.thecvf.com/ICCV2023#), [Yifan Yu](https://openaccess.thecvf.com/ICCV2023#), [Marc Pollefeys](https://openaccess.thecvf.com/ICCV2023#), [Viktor Larsson](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pautrat_GlueStick_Robust_Image_Matching_by_Sticking_Points_and_Lines_Together_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pautrat_GlueStick_Robust_Image_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Advancing Referring Expression Segmentation Beyond Single Image](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Advancing_Referring_Expression_Segmentation_Beyond_Single_Image_ICCV_2023_paper.html)

[Yixuan Wu](https://openaccess.thecvf.com/ICCV2023#), [Zhao Zhang](https://openaccess.thecvf.com/ICCV2023#), [Chi Xie](https://openaccess.thecvf.com/ICCV2023#), [Feng Zhu](https://openaccess.thecvf.com/ICCV2023#), [Rui Zhao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Advancing_Referring_Expression_Segmentation_Beyond_Single_Image_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2305.12452)] 

[bibtex]


[Learning Image Harmonization in the Linear Color Space](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Learning_Image_Harmonization_in_the_Linear_Color_Space_ICCV_2023_paper.html)

[Ke Xu](https://openaccess.thecvf.com/ICCV2023#), [Gerhard Petrus Hancke](https://openaccess.thecvf.com/ICCV2023#), [Rynson W.H. Lau](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Learning_Image_Harmonization_in_the_Linear_Color_Space_ICCV_2023_paper.pdf)] 

[bibtex]


[The Devil is in the Upsampling: Architectural Decisions Made Simpler for Denoising with Deep Image Prior](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_The_Devil_is_in_the_Upsampling_Architectural_Decisions_Made_Simpler_ICCV_2023_paper.html)

[Yilin Liu](https://openaccess.thecvf.com/ICCV2023#), [Jiang Li](https://openaccess.thecvf.com/ICCV2023#), [Yunkui Pang](https://openaccess.thecvf.com/ICCV2023#), [Dong Nie](https://openaccess.thecvf.com/ICCV2023#), [Pew-Thian Yap](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_The_Devil_is_in_the_Upsampling_Architectural_Decisions_Made_Simpler_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_The_Devil_is_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.11409)] 

[bibtex]


[SimpleClick: Interactive Image Segmentation with Simple Vision Transformers](https://openaccess.thecvf.com/content/ICCV2023/html/Liu_SimpleClick_Interactive_Image_Segmentation_with_Simple_Vision_Transformers_ICCV_2023_paper.html)

[Qin Liu](https://openaccess.thecvf.com/ICCV2023#), [Zhenlin Xu](https://openaccess.thecvf.com/ICCV2023#), [Gedas Bertasius](https://openaccess.thecvf.com/ICCV2023#), [Marc Niethammer](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Liu_SimpleClick_Interactive_Image_Segmentation_with_Simple_Vision_Transformers_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Liu_SimpleClick_Interactive_Image_ICCV_2023_supplemental.zip)] [[arXiv](http://arxiv.org/abs/2210.11006)] 

[bibtex]


[Pix2Video: Video Editing using Image Diffusion](https://openaccess.thecvf.com/content/ICCV2023/html/Ceylan_Pix2Video_Video_Editing_using_Image_Diffusion_ICCV_2023_paper.html)

[Duygu Ceylan](https://openaccess.thecvf.com/ICCV2023#), [Chun-Hao P. Huang](https://openaccess.thecvf.com/ICCV2023#), [Niloy J. Mitra](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ceylan_Pix2Video_Video_Editing_using_Image_Diffusion_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.12688)] 

[bibtex]


[Uncertainty-guided Learning for Improving Image Manipulation Detection](https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Uncertainty-guided_Learning_for_Improving_Image_Manipulation_Detection_ICCV_2023_paper.html)

[Kaixiang Ji](https://openaccess.thecvf.com/ICCV2023#), [Feng Chen](https://openaccess.thecvf.com/ICCV2023#), [Xin Guo](https://openaccess.thecvf.com/ICCV2023#), [Yadong Xu](https://openaccess.thecvf.com/ICCV2023#), [Jian Wang](https://openaccess.thecvf.com/ICCV2023#), [Jingdong Chen](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Uncertainty-guided_Learning_for_Improving_Image_Manipulation_Detection_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ji_Uncertainty-guided_Learning_for_ICCV_2023_supplemental.pdf)] 

[bibtex]


[CuNeRF: Cube-Based Neural Radiance Field for Zero-Shot Medical Image Arbitrary-Scale Super Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_CuNeRF_Cube-Based_Neural_Radiance_Field_for_Zero-Shot_Medical_Image_Arbitrary-Scale_ICCV_2023_paper.html)

[Zixuan Chen](https://openaccess.thecvf.com/ICCV2023#), [Lingxiao Yang](https://openaccess.thecvf.com/ICCV2023#), [Jian-Huang Lai](https://openaccess.thecvf.com/ICCV2023#), [Xiaohua Xie](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_CuNeRF_Cube-Based_Neural_Radiance_Field_for_Zero-Shot_Medical_Image_Arbitrary-Scale_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.16242)] 

[bibtex]


[Pixel Adaptive Deep Unfolding Transformer for Hyperspectral Image Reconstruction](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Pixel_Adaptive_Deep_Unfolding_Transformer_for_Hyperspectral_Image_Reconstruction_ICCV_2023_paper.html)

[Miaoyu Li](https://openaccess.thecvf.com/ICCV2023#), [Ying Fu](https://openaccess.thecvf.com/ICCV2023#), [Ji Liu](https://openaccess.thecvf.com/ICCV2023#), [Yulun Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Pixel_Adaptive_Deep_Unfolding_Transformer_for_Hyperspectral_Image_Reconstruction_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Pixel_Adaptive_Deep_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.10820)] 

[bibtex]


[Fan-Beam Binarization Difference Projection (FB-BDP): A Novel Local Object Descriptor for Fine-Grained Leaf Image Retrieval](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Fan-Beam_Binarization_Difference_Projection_FB-BDP_A_Novel_Local_Object_Descriptor_ICCV_2023_paper.html)

[Xin Chen](https://openaccess.thecvf.com/ICCV2023#), [Bin Wang](https://openaccess.thecvf.com/ICCV2023#), [Yongsheng Gao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Fan-Beam_Binarization_Difference_Projection_FB-BDP_A_Novel_Local_Object_Descriptor_ICCV_2023_paper.pdf)] 

[bibtex]


[Localizing Object-Level Shape Variations with Text-to-Image Diffusion Models](https://openaccess.thecvf.com/content/ICCV2023/html/Patashnik_Localizing_Object-Level_Shape_Variations_with_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html)

[Or Patashnik](https://openaccess.thecvf.com/ICCV2023#), [Daniel Garibi](https://openaccess.thecvf.com/ICCV2023#), [Idan Azuri](https://openaccess.thecvf.com/ICCV2023#), [Hadar Averbuch-Elor](https://openaccess.thecvf.com/ICCV2023#), [Daniel Cohen-Or](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Patashnik_Localizing_Object-Level_Shape_Variations_with_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Patashnik_Localizing_Object-Level_Shape_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.11306)] 

[bibtex]


[MagicFusion: Boosting Text-to-Image Generation Performance by Fusing Diffusion Models](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_MagicFusion_Boosting_Text-to-Image_Generation_Performance_by_Fusing_Diffusion_Models_ICCV_2023_paper.html)

[Jing Zhao](https://openaccess.thecvf.com/ICCV2023#), [Heliang Zheng](https://openaccess.thecvf.com/ICCV2023#), [Chaoyue Wang](https://openaccess.thecvf.com/ICCV2023#), [Long Lan](https://openaccess.thecvf.com/ICCV2023#), [Wenjing Yang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_MagicFusion_Boosting_Text-to-Image_Generation_Performance_by_Fusing_Diffusion_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhao_MagicFusion_Boosting_Text-to-Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.13126)] 

[bibtex]


[LIMITR: Leveraging Local Information for Medical Image-Text Representation](https://openaccess.thecvf.com/content/ICCV2023/html/Dawidowicz_LIMITR_Leveraging_Local_Information_for_Medical_Image-Text_Representation_ICCV_2023_paper.html)

[Gefen Dawidowicz](https://openaccess.thecvf.com/ICCV2023#), [Elad Hirsch](https://openaccess.thecvf.com/ICCV2023#), [Ayellet Tal](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Dawidowicz_LIMITR_Leveraging_Local_Information_for_Medical_Image-Text_Representation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Dawidowicz_LIMITR_Leveraging_Local_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.11755)] 

[bibtex]


[Efficient Unified Demosaicing for Bayer and Non-Bayer Patterned Image Sensors](https://openaccess.thecvf.com/content/ICCV2023/html/Lee_Efficient_Unified_Demosaicing_for_Bayer_and_Non-Bayer_Patterned_Image_Sensors_ICCV_2023_paper.html)

[Haechang Lee](https://openaccess.thecvf.com/ICCV2023#), [Dongwon Park](https://openaccess.thecvf.com/ICCV2023#), [Wongi Jeong](https://openaccess.thecvf.com/ICCV2023#), [Kijeong Kim](https://openaccess.thecvf.com/ICCV2023#), [Hyunwoo Je](https://openaccess.thecvf.com/ICCV2023#), [Dongil Ryu](https://openaccess.thecvf.com/ICCV2023#), [Se Young Chun](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lee_Efficient_Unified_Demosaicing_for_Bayer_and_Non-Bayer_Patterned_Image_Sensors_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lee_Efficient_Unified_Demosaicing_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.10667)] 

[bibtex]


[Spatially-Adaptive Feature Modulation for Efficient Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_Spatially-Adaptive_Feature_Modulation_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.html)

[Long Sun](https://openaccess.thecvf.com/ICCV2023#), [Jiangxin Dong](https://openaccess.thecvf.com/ICCV2023#), [Jinhui Tang](https://openaccess.thecvf.com/ICCV2023#), [Jinshan Pan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_Spatially-Adaptive_Feature_Modulation_for_Efficient_Image_Super-Resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_Spatially-Adaptive_Feature_Modulation_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.13800)] 

[bibtex]


[Unsupervised Image Denoising in Real-World Scenarios via Self-Collaboration Parallel Generative Adversarial Branches](https://openaccess.thecvf.com/content/ICCV2023/html/Lin_Unsupervised_Image_Denoising_in_Real-World_Scenarios_via_Self-Collaboration_Parallel_Generative_ICCV_2023_paper.html)

[Xin Lin](https://openaccess.thecvf.com/ICCV2023#), [Chao Ren](https://openaccess.thecvf.com/ICCV2023#), [Xiao Liu](https://openaccess.thecvf.com/ICCV2023#), [Jie Huang](https://openaccess.thecvf.com/ICCV2023#), [Yinjie Lei](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lin_Unsupervised_Image_Denoising_in_Real-World_Scenarios_via_Self-Collaboration_Parallel_Generative_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lin_Unsupervised_Image_Denoising_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.06776)] 

[bibtex]


[Self-supervised Image Denoising with Downsampled Invariance Loss and Conditional Blind-Spot Network](https://openaccess.thecvf.com/content/ICCV2023/html/Jang_Self-supervised_Image_Denoising_with_Downsampled_Invariance_Loss_and_Conditional_Blind-Spot_ICCV_2023_paper.html)

[Yeong Il Jang](https://openaccess.thecvf.com/ICCV2023#), [Keuntek Lee](https://openaccess.thecvf.com/ICCV2023#), [Gu Yong Park](https://openaccess.thecvf.com/ICCV2023#), [Seyun Kim](https://openaccess.thecvf.com/ICCV2023#), [Nam Ik Cho](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jang_Self-supervised_Image_Denoising_with_Downsampled_Invariance_Loss_and_Conditional_Blind-Spot_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jang_Self-supervised_Image_Denoising_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.09507)] 

[bibtex]


[ESSAformer: Efficient Transformer for Hyperspectral Image Super-resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_ESSAformer_Efficient_Transformer_for_Hyperspectral_Image_Super-resolution_ICCV_2023_paper.html)

[Mingjin Zhang](https://openaccess.thecvf.com/ICCV2023#), [Chi Zhang](https://openaccess.thecvf.com/ICCV2023#), [Qiming Zhang](https://openaccess.thecvf.com/ICCV2023#), [Jie Guo](https://openaccess.thecvf.com/ICCV2023#), [Xinbo Gao](https://openaccess.thecvf.com/ICCV2023#), [Jing Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_ESSAformer_Efficient_Transformer_for_Hyperspectral_Image_Super-resolution_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_ESSAformer_Efficient_Transformer_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.14010)] 

[bibtex]


[Thinking Image Color Aesthetics Assessment: Models, Datasets and Benchmarks](https://openaccess.thecvf.com/content/ICCV2023/html/He_Thinking_Image_Color_Aesthetics_Assessment_Models_Datasets_and_Benchmarks_ICCV_2023_paper.html)

[Shuai He](https://openaccess.thecvf.com/ICCV2023#), [Anlong Ming](https://openaccess.thecvf.com/ICCV2023#), [Yaqi Li](https://openaccess.thecvf.com/ICCV2023#), [Jinyuan Sun](https://openaccess.thecvf.com/ICCV2023#), [ShunTian Zheng](https://openaccess.thecvf.com/ICCV2023#), [Huadong Ma](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/He_Thinking_Image_Color_Aesthetics_Assessment_Models_Datasets_and_Benchmarks_ICCV_2023_paper.pdf)] 

[bibtex]


[The Euclidean Space is Evil: Hyperbolic Attribute Editing for Few-shot Image Generation](https://openaccess.thecvf.com/content/ICCV2023/html/Li_The_Euclidean_Space_is_Evil_Hyperbolic_Attribute_Editing_for_Few-shot_ICCV_2023_paper.html)

[Lingxiao Li](https://openaccess.thecvf.com/ICCV2023#), [Yi Zhang](https://openaccess.thecvf.com/ICCV2023#), [Shuhui Wang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_The_Euclidean_Space_is_Evil_Hyperbolic_Attribute_Editing_for_Few-shot_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_The_Euclidean_Space_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.12347)] 

[bibtex]


[Transparent Shape from a Single View Polarization Image](https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Transparent_Shape_from_a_Single_View_Polarization_Image_ICCV_2023_paper.html)

[Mingqi Shao](https://openaccess.thecvf.com/ICCV2023#), [Chongkun Xia](https://openaccess.thecvf.com/ICCV2023#), [Zhendong Yang](https://openaccess.thecvf.com/ICCV2023#), [Junnan Huang](https://openaccess.thecvf.com/ICCV2023#), [Xueqian Wang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Transparent_Shape_from_a_Single_View_Polarization_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shao_Transparent_Shape_from_a_Single_View_Polarization_Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2204.06331)] 

[bibtex]


[Single Depth-image 3D Reflection Symmetry and Shape Prediction](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Single_Depth-image_3D_Reflection_Symmetry_and_Shape_Prediction_ICCV_2023_paper.html)

[Zhaoxuan Zhang](https://openaccess.thecvf.com/ICCV2023#), [Bo Dong](https://openaccess.thecvf.com/ICCV2023#), [Tong Li](https://openaccess.thecvf.com/ICCV2023#), [Felix Heide](https://openaccess.thecvf.com/ICCV2023#), [Pieter Peers](https://openaccess.thecvf.com/ICCV2023#), [Baocai Yin](https://openaccess.thecvf.com/ICCV2023#), [Xin Yang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Single_Depth-image_3D_Reflection_Symmetry_and_Shape_Prediction_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Single_Depth-image_3D_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Downscaled Representation Matters: Improving Image Rescaling with Collaborative Downscaled Images](https://openaccess.thecvf.com/content/ICCV2023/html/Xu_Downscaled_Representation_Matters_Improving_Image_Rescaling_with_Collaborative_Downscaled_Images_ICCV_2023_paper.html)

[Bingna Xu](https://openaccess.thecvf.com/ICCV2023#), [Yong Guo](https://openaccess.thecvf.com/ICCV2023#), [Luoqian Jiang](https://openaccess.thecvf.com/ICCV2023#), [Mianjie Yu](https://openaccess.thecvf.com/ICCV2023#), [Jian Chen](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_Downscaled_Representation_Matters_Improving_Image_Rescaling_with_Collaborative_Downscaled_Images_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xu_Downscaled_Representation_Matters_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2211.10643)] 

[bibtex]


[PODIA-3D: Domain Adaptation of 3D Generative Model Across Large Domain Gap Using Pose-Preserved Text-to-Image Diffusion](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_PODIA-3D_Domain_Adaptation_of_3D_Generative_Model_Across_Large_Domain_ICCV_2023_paper.html)

[Gwanghyun Kim](https://openaccess.thecvf.com/ICCV2023#), [Ji Ha Jang](https://openaccess.thecvf.com/ICCV2023#), [Se Young Chun](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_PODIA-3D_Domain_Adaptation_of_3D_Generative_Model_Across_Large_Domain_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_PODIA-3D_Domain_Adaptation_ICCV_2023_supplemental.zip)] 

[bibtex]


[Steered Diffusion: A Generalized Framework for Plug-and-Play Conditional Image Synthesis](https://openaccess.thecvf.com/content/ICCV2023/html/Nair_Steered_Diffusion_A_Generalized_Framework_for_Plug-and-Play_Conditional_Image_Synthesis_ICCV_2023_paper.html)

[Nithin Gopalakrishnan Nair](https://openaccess.thecvf.com/ICCV2023#), [Anoop Cherian](https://openaccess.thecvf.com/ICCV2023#), [Suhas Lohit](https://openaccess.thecvf.com/ICCV2023#), [Ye Wang](https://openaccess.thecvf.com/ICCV2023#), [Toshiaki Koike-Akino](https://openaccess.thecvf.com/ICCV2023#), [Vishal M. Patel](https://openaccess.thecvf.com/ICCV2023#), [Tim K. Marks](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Nair_Steered_Diffusion_A_Generalized_Framework_for_Plug-and-Play_Conditional_Image_Synthesis_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Nair_Steered_Diffusion_A_Generalized_Framework_for_Plug-and-Play_Conditional_Image_Synthesis_ICCV_2023_supplemental.pdf)] 

[bibtex]


[DALL-Eval: Probing the Reasoning Skills and Social Biases of Text-to-Image Generation Models](https://openaccess.thecvf.com/content/ICCV2023/html/Cho_DALL-Eval_Probing_the_Reasoning_Skills_and_Social_Biases_of_Text-to-Image_ICCV_2023_paper.html)

[Jaemin Cho](https://openaccess.thecvf.com/ICCV2023#), [Abhay Zala](https://openaccess.thecvf.com/ICCV2023#), [Mohit Bansal](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cho_DALL-Eval_Probing_the_Reasoning_Skills_and_Social_Biases_of_Text-to-Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cho_DALL-Eval_Probing_the_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Physics-Driven Turbulence Image Restoration with Stochastic Refinement](https://openaccess.thecvf.com/content/ICCV2023/html/Jaiswal_Physics-Driven_Turbulence_Image_Restoration_with_Stochastic_Refinement_ICCV_2023_paper.html)

[Ajay Jaiswal](https://openaccess.thecvf.com/ICCV2023#), [Xingguang Zhang](https://openaccess.thecvf.com/ICCV2023#), [Stanley H. Chan](https://openaccess.thecvf.com/ICCV2023#), [Zhangyang Wang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jaiswal_Physics-Driven_Turbulence_Image_Restoration_with_Stochastic_Refinement_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2307.10603)] 

[bibtex]


[HairNeRF: Geometry-Aware Image Synthesis for Hairstyle Transfer](https://openaccess.thecvf.com/content/ICCV2023/html/Chang_HairNeRF_Geometry-Aware_Image_Synthesis_for_Hairstyle_Transfer_ICCV_2023_paper.html)

[Seunggyu Chang](https://openaccess.thecvf.com/ICCV2023#), [Gihoon Kim](https://openaccess.thecvf.com/ICCV2023#), [Hayeon Kim](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chang_HairNeRF_Geometry-Aware_Image_Synthesis_for_Hairstyle_Transfer_ICCV_2023_paper.pdf)] 

[bibtex]


[Multi-Modal Gated Mixture of Local-to-Global Experts for Dynamic Image Fusion](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Multi-Modal_Gated_Mixture_of_Local-to-Global_Experts_for_Dynamic_Image_Fusion_ICCV_2023_paper.html)

[Bing Cao](https://openaccess.thecvf.com/ICCV2023#), [Yiming Sun](https://openaccess.thecvf.com/ICCV2023#), [Pengfei Zhu](https://openaccess.thecvf.com/ICCV2023#), [Qinghua Hu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Multi-Modal_Gated_Mixture_of_Local-to-Global_Experts_for_Dynamic_Image_Fusion_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Cao_Multi-Modal_Gated_Mixture_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.01392)] 

[bibtex]


[Deep Image Harmonization with Learnable Augmentation](https://openaccess.thecvf.com/content/ICCV2023/html/Niu_Deep_Image_Harmonization_with_Learnable_Augmentation_ICCV_2023_paper.html)

[Li Niu](https://openaccess.thecvf.com/ICCV2023#), [Junyan Cao](https://openaccess.thecvf.com/ICCV2023#), [Wenyan Cong](https://openaccess.thecvf.com/ICCV2023#), [Liqing Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Niu_Deep_Image_Harmonization_with_Learnable_Augmentation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Niu_Deep_Image_Harmonization_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.00376)] 

[bibtex]


[RFD-ECNet: Extreme Underwater Image Compression with Reference to Feature Dictionary](https://openaccess.thecvf.com/content/ICCV2023/html/Li_RFD-ECNet_Extreme_Underwater_Image_Compression_with_Reference_to_Feature_Dictionary_ICCV_2023_paper.html)

[Mengyao Li](https://openaccess.thecvf.com/ICCV2023#), [Liquan Shen](https://openaccess.thecvf.com/ICCV2023#), [Peng Ye](https://openaccess.thecvf.com/ICCV2023#), [Guorui Feng](https://openaccess.thecvf.com/ICCV2023#), [Zheyin Wang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_RFD-ECNet_Extreme_Underwater_Image_Compression_with_Reference_to_Feature_Dictionary_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_RFD-ECNet_Extreme_Underwater_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Grounded Image Text Matching with Mismatched Relation Reasoning](https://openaccess.thecvf.com/content/ICCV2023/html/Wu_Grounded_Image_Text_Matching_with_Mismatched_Relation_Reasoning_ICCV_2023_paper.html)

[Yu Wu](https://openaccess.thecvf.com/ICCV2023#), [Yana Wei](https://openaccess.thecvf.com/ICCV2023#), [Haozhe Wang](https://openaccess.thecvf.com/ICCV2023#), [Yongfei Liu](https://openaccess.thecvf.com/ICCV2023#), [Sibei Yang](https://openaccess.thecvf.com/ICCV2023#), [Xuming He](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_Grounded_Image_Text_Matching_with_Mismatched_Relation_Reasoning_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wu_Grounded_Image_Text_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.01236)] 

[bibtex]


[BoxDiff: Text-to-Image Synthesis with Training-Free Box-Constrained Diffusion](https://openaccess.thecvf.com/content/ICCV2023/html/Xie_BoxDiff_Text-to-Image_Synthesis_with_Training-Free_Box-Constrained_Diffusion_ICCV_2023_paper.html)

[Jinheng Xie](https://openaccess.thecvf.com/ICCV2023#), [Yuexiang Li](https://openaccess.thecvf.com/ICCV2023#), [Yawen Huang](https://openaccess.thecvf.com/ICCV2023#), [Haozhe Liu](https://openaccess.thecvf.com/ICCV2023#), [Wentian Zhang](https://openaccess.thecvf.com/ICCV2023#), [Yefeng Zheng](https://openaccess.thecvf.com/ICCV2023#), [Mike Zheng Shou](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xie_BoxDiff_Text-to-Image_Synthesis_with_Training-Free_Box-Constrained_Diffusion_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xie_BoxDiff_Text-to-Image_Synthesis_with_Training-Free_Box-Constrained_Diffusion_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.10816)] 

[bibtex]


[Vision HGNN: An Image is More than a Graph of Nodes](https://openaccess.thecvf.com/content/ICCV2023/html/Han_Vision_HGNN_An_Image_is_More_than_a_Graph_of_ICCV_2023_paper.html)

[Yan Han](https://openaccess.thecvf.com/ICCV2023#), [Peihao Wang](https://openaccess.thecvf.com/ICCV2023#), [Souvik Kundu](https://openaccess.thecvf.com/ICCV2023#), [Ying Ding](https://openaccess.thecvf.com/ICCV2023#), [Zhangyang Wang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Vision_HGNN_An_Image_is_More_than_a_Graph_of_ICCV_2023_paper.pdf)] 

[bibtex]


[HumanSD: A Native Skeleton-Guided Diffusion Model for Human Image Generation](https://openaccess.thecvf.com/content/ICCV2023/html/Ju_HumanSD_A_Native_Skeleton-Guided_Diffusion_Model_for_Human_Image_Generation_ICCV_2023_paper.html)

[Xuan Ju](https://openaccess.thecvf.com/ICCV2023#), [Ailing Zeng](https://openaccess.thecvf.com/ICCV2023#), [Chenchen Zhao](https://openaccess.thecvf.com/ICCV2023#), [Jianan Wang](https://openaccess.thecvf.com/ICCV2023#), [Lei Zhang](https://openaccess.thecvf.com/ICCV2023#), [Qiang Xu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ju_HumanSD_A_Native_Skeleton-Guided_Diffusion_Model_for_Human_Image_Generation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ju_HumanSD_A_Native_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2304.04269)] 

[bibtex]


[HRS-Bench: Holistic, Reliable and Scalable Benchmark for Text-to-Image Models](https://openaccess.thecvf.com/content/ICCV2023/html/Bakr_HRS-Bench_Holistic_Reliable_and_Scalable_Benchmark_for_Text-to-Image_Models_ICCV_2023_paper.html)

[Eslam Mohamed Bakr](https://openaccess.thecvf.com/ICCV2023#), [Pengzhan Sun](https://openaccess.thecvf.com/ICCV2023#), [Xiaoqian Shen](https://openaccess.thecvf.com/ICCV2023#), [Faizan Farooq Khan](https://openaccess.thecvf.com/ICCV2023#), [Li Erran Li](https://openaccess.thecvf.com/ICCV2023#), [Mohamed Elhoseiny](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Bakr_HRS-Bench_Holistic_Reliable_and_Scalable_Benchmark_for_Text-to-Image_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Bakr_HRS-Bench_Holistic_Reliable_ICCV_2023_supplemental.pdf)] 

[bibtex]


[GRAM-HD: 3D-Consistent Image Generation at High Resolution with Generative Radiance Manifolds](https://openaccess.thecvf.com/content/ICCV2023/html/Xiang_GRAM-HD_3D-Consistent_Image_Generation_at_High_Resolution_with_Generative_Radiance_ICCV_2023_paper.html)

[Jianfeng Xiang](https://openaccess.thecvf.com/ICCV2023#), [Jiaolong Yang](https://openaccess.thecvf.com/ICCV2023#), [Yu Deng](https://openaccess.thecvf.com/ICCV2023#), [Xin Tong](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xiang_GRAM-HD_3D-Consistent_Image_Generation_at_High_Resolution_with_Generative_Radiance_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Xiang_GRAM-HD_3D-Consistent_Image_ICCV_2023_supplemental.pdf)] 

[bibtex]


[PIRNet: Privacy-Preserving Image Restoration Network via Wavelet Lifting](https://openaccess.thecvf.com/content/ICCV2023/html/Deng_PIRNet_Privacy-Preserving_Image_Restoration_Network_via_Wavelet_Lifting_ICCV_2023_paper.html)

[Xin Deng](https://openaccess.thecvf.com/ICCV2023#), [Chao Gao](https://openaccess.thecvf.com/ICCV2023#), [Mai Xu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Deng_PIRNet_Privacy-Preserving_Image_Restoration_Network_via_Wavelet_Lifting_ICCV_2023_paper.pdf)] 

[bibtex]


[ConSlide: Asynchronous Hierarchical Interaction Transformer with Breakup-Reorganize Rehearsal for Continual Whole Slide Image Analysis](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_ConSlide_Asynchronous_Hierarchical_Interaction_Transformer_with_Breakup-Reorganize_Rehearsal_for_Continual_ICCV_2023_paper.html)

[Yanyan Huang](https://openaccess.thecvf.com/ICCV2023#), [Weiqin Zhao](https://openaccess.thecvf.com/ICCV2023#), [Shujun Wang](https://openaccess.thecvf.com/ICCV2023#), [Yu Fu](https://openaccess.thecvf.com/ICCV2023#), [Yuming Jiang](https://openaccess.thecvf.com/ICCV2023#), [Lequan Yu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_ConSlide_Asynchronous_Hierarchical_Interaction_Transformer_with_Breakup-Reorganize_Rehearsal_for_Continual_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_ConSlide_Asynchronous_Hierarchical_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.13324)] 

[bibtex]


[ImGeoNet: Image-induced Geometry-aware Voxel Representation for Multi-view 3D Object Detection](https://openaccess.thecvf.com/content/ICCV2023/html/Tu_ImGeoNet_Image-induced_Geometry-aware_Voxel_Representation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.html)

[Tao Tu](https://openaccess.thecvf.com/ICCV2023#), [Shun-Po Chuang](https://openaccess.thecvf.com/ICCV2023#), [Yu-Lun Liu](https://openaccess.thecvf.com/ICCV2023#), [Cheng Sun](https://openaccess.thecvf.com/ICCV2023#), [Ke Zhang](https://openaccess.thecvf.com/ICCV2023#), [Donna Roy](https://openaccess.thecvf.com/ICCV2023#), [Cheng-Hao Kuo](https://openaccess.thecvf.com/ICCV2023#), [Min Sun](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_ImGeoNet_Image-induced_Geometry-aware_Voxel_Representation_for_Multi-view_3D_Object_Detection_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Tu_ImGeoNet_Image-induced_Geometry-aware_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.09098)] 

[bibtex]


[DRAW: Defending Camera-shooted RAW Against Image Manipulation](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_DRAW_Defending_Camera-shooted_RAW_Against_Image_Manipulation_ICCV_2023_paper.html)

[Xiaoxiao Hu](https://openaccess.thecvf.com/ICCV2023#), [Qichao Ying](https://openaccess.thecvf.com/ICCV2023#), [Zhenxing Qian](https://openaccess.thecvf.com/ICCV2023#), [Sheng Li](https://openaccess.thecvf.com/ICCV2023#), [Xinpeng Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_DRAW_Defending_Camera-shooted_RAW_Against_Image_Manipulation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_DRAW_Defending_Camera-shooted_RAW_Against_Image_Manipulation_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2307.16418)] 

[bibtex]


[Controllable Person Image Synthesis with Pose-Constrained Latent Diffusion](https://openaccess.thecvf.com/content/ICCV2023/html/Han_Controllable_Person_Image_Synthesis_with_Pose-Constrained_Latent_Diffusion_ICCV_2023_paper.html)

[Xiao Han](https://openaccess.thecvf.com/ICCV2023#), [Xiatian Zhu](https://openaccess.thecvf.com/ICCV2023#), [Jiankang Deng](https://openaccess.thecvf.com/ICCV2023#), [Yi-Zhe Song](https://openaccess.thecvf.com/ICCV2023#), [Tao Xiang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Controllable_Person_Image_Synthesis_with_Pose-Constrained_Latent_Diffusion_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_Controllable_Person_Image_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Diffusion-based Image Translation with Label Guidance for Domain Adaptive Semantic Segmentation](https://openaccess.thecvf.com/content/ICCV2023/html/Peng_Diffusion-based_Image_Translation_with_Label_Guidance_for_Domain_Adaptive_Semantic_ICCV_2023_paper.html)

[Duo Peng](https://openaccess.thecvf.com/ICCV2023#), [Ping Hu](https://openaccess.thecvf.com/ICCV2023#), [Qiuhong Ke](https://openaccess.thecvf.com/ICCV2023#), [Jun Liu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Peng_Diffusion-based_Image_Translation_with_Label_Guidance_for_Domain_Adaptive_Semantic_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Peng_Diffusion-based_Image_Translation_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.12350)] 

[bibtex]


[MB-TaylorFormer: Multi-Branch Efficient Transformer Expanded by Taylor Formula for Image Dehazing](https://openaccess.thecvf.com/content/ICCV2023/html/Qiu_MB-TaylorFormer_Multi-Branch_Efficient_Transformer_Expanded_by_Taylor_Formula_for_Image_ICCV_2023_paper.html)

[Yuwei Qiu](https://openaccess.thecvf.com/ICCV2023#), [Kaihao Zhang](https://openaccess.thecvf.com/ICCV2023#), [Chenxi Wang](https://openaccess.thecvf.com/ICCV2023#), [Wenhan Luo](https://openaccess.thecvf.com/ICCV2023#), [Hongdong Li](https://openaccess.thecvf.com/ICCV2023#), [Zhi Jin](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qiu_MB-TaylorFormer_Multi-Branch_Efficient_Transformer_Expanded_by_Taylor_Formula_for_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qiu_MB-TaylorFormer_Multi-Branch_Efficient_ICCV_2023_supplemental.pdf)] 

[bibtex]


[ELITE: Encoding Visual Concepts into Textual Embeddings for Customized Text-to-Image Generation](https://openaccess.thecvf.com/content/ICCV2023/html/Wei_ELITE_Encoding_Visual_Concepts_into_Textual_Embeddings_for_Customized_Text-to-Image_ICCV_2023_paper.html)

[Yuxiang Wei](https://openaccess.thecvf.com/ICCV2023#), [Yabo Zhang](https://openaccess.thecvf.com/ICCV2023#), [Zhilong Ji](https://openaccess.thecvf.com/ICCV2023#), [Jinfeng Bai](https://openaccess.thecvf.com/ICCV2023#), [Lei Zhang](https://openaccess.thecvf.com/ICCV2023#), [Wangmeng Zuo](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wei_ELITE_Encoding_Visual_Concepts_into_Textual_Embeddings_for_Customized_Text-to-Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wei_ELITE_Encoding_Visual_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.13848)] 

[bibtex]


[Global Features are All You Need for Image Retrieval and Reranking](https://openaccess.thecvf.com/content/ICCV2023/html/Shao_Global_Features_are_All_You_Need_for_Image_Retrieval_and_ICCV_2023_paper.html)

[Shihao Shao](https://openaccess.thecvf.com/ICCV2023#), [Kaifeng Chen](https://openaccess.thecvf.com/ICCV2023#), [Arjun Karpur](https://openaccess.thecvf.com/ICCV2023#), [Qinghua Cui](https://openaccess.thecvf.com/ICCV2023#), [André Araujo](https://openaccess.thecvf.com/ICCV2023#), [Bingyi Cao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shao_Global_Features_are_All_You_Need_for_Image_Retrieval_and_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Shao_Global_Features_are_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.06954)] 

[bibtex]


[LDP-Feat: Image Features with Local Differential Privacy](https://openaccess.thecvf.com/content/ICCV2023/html/Pittaluga_LDP-Feat_Image_Features_with_Local_Differential_Privacy_ICCV_2023_paper.html)

[Francesco Pittaluga](https://openaccess.thecvf.com/ICCV2023#), [Bingbing Zhuang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Pittaluga_LDP-Feat_Image_Features_with_Local_Differential_Privacy_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Pittaluga_LDP-Feat_Image_Features_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Pre-Training-Free Image Manipulation Localization through Non-Mutually Exclusive Contrastive Learning](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Pre-Training-Free_Image_Manipulation_Localization_through_Non-Mutually_Exclusive_Contrastive_Learning_ICCV_2023_paper.html)

[Jizhe Zhou](https://openaccess.thecvf.com/ICCV2023#), [Xiaochen Ma](https://openaccess.thecvf.com/ICCV2023#), [Xia Du](https://openaccess.thecvf.com/ICCV2023#), [Ahmed Y. Alhammadi](https://openaccess.thecvf.com/ICCV2023#), [Wentao Feng](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Pre-Training-Free_Image_Manipulation_Localization_through_Non-Mutually_Exclusive_Contrastive_Learning_ICCV_2023_paper.pdf)] 

[bibtex]


[Efficient-VQGAN: Towards High-Resolution Image Generation with Efficient Vision Transformers](https://openaccess.thecvf.com/content/ICCV2023/html/Cao_Efficient-VQGAN_Towards_High-Resolution_Image_Generation_with_Efficient_Vision_Transformers_ICCV_2023_paper.html)

[Shiyue Cao](https://openaccess.thecvf.com/ICCV2023#), [Yueqin Yin](https://openaccess.thecvf.com/ICCV2023#), [Lianghua Huang](https://openaccess.thecvf.com/ICCV2023#), [Yu Liu](https://openaccess.thecvf.com/ICCV2023#), [Xin Zhao](https://openaccess.thecvf.com/ICCV2023#), [Deli Zhao](https://openaccess.thecvf.com/ICCV2023#), [Kaigi Huang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cao_Efficient-VQGAN_Towards_High-Resolution_Image_Generation_with_Efficient_Vision_Transformers_ICCV_2023_paper.pdf)] 

[bibtex]


[DLGSANet: Lightweight Dynamic Local and Global Self-Attention Networks for Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Li_DLGSANet_Lightweight_Dynamic_Local_and_Global_Self-Attention_Networks_for_Image_ICCV_2023_paper.html)

[Xiang Li](https://openaccess.thecvf.com/ICCV2023#), [Jiangxin Dong](https://openaccess.thecvf.com/ICCV2023#), [Jinhui Tang](https://openaccess.thecvf.com/ICCV2023#), [Jinshan Pan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_DLGSANet_Lightweight_Dynamic_Local_and_Global_Self-Attention_Networks_for_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_DLGSANet_Lightweight_Dynamic_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2301.02031)] 

[bibtex]


[Towards Fair and Comprehensive Comparisons for Image-Based 3D Object Detection](https://openaccess.thecvf.com/content/ICCV2023/html/Ma_Towards_Fair_and_Comprehensive_Comparisons_for_Image-Based_3D_Object_Detection_ICCV_2023_paper.html)

[Xinzhu Ma](https://openaccess.thecvf.com/ICCV2023#), [Yongtao Wang](https://openaccess.thecvf.com/ICCV2023#), [Yinmin Zhang](https://openaccess.thecvf.com/ICCV2023#), [Zhiyi Xia](https://openaccess.thecvf.com/ICCV2023#), [Yuan Meng](https://openaccess.thecvf.com/ICCV2023#), [Zhihui Wang](https://openaccess.thecvf.com/ICCV2023#), [Haojie Li](https://openaccess.thecvf.com/ICCV2023#), [Wanli Ouyang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ma_Towards_Fair_and_Comprehensive_Comparisons_for_Image-Based_3D_Object_Detection_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ma_Towards_Fair_and_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Disentangling Spatial and Temporal Learning for Efficient Image-to-Video Transfer Learning](https://openaccess.thecvf.com/content/ICCV2023/html/Qing_Disentangling_Spatial_and_Temporal_Learning_for_Efficient_Image-to-Video_Transfer_Learning_ICCV_2023_paper.html)

[Zhiwu Qing](https://openaccess.thecvf.com/ICCV2023#), [Shiwei Zhang](https://openaccess.thecvf.com/ICCV2023#), [Ziyuan Huang](https://openaccess.thecvf.com/ICCV2023#), [Yingya Zhang](https://openaccess.thecvf.com/ICCV2023#), [Changxin Gao](https://openaccess.thecvf.com/ICCV2023#), [Deli Zhao](https://openaccess.thecvf.com/ICCV2023#), [Nong Sang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qing_Disentangling_Spatial_and_Temporal_Learning_for_Efficient_Image-to-Video_Transfer_Learning_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Qing_Disentangling_Spatial_and_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.07911)] 

[bibtex]


[Coarse-to-Fine: Learning Compact Discriminative Representation for Single-Stage Image Retrieval](https://openaccess.thecvf.com/content/ICCV2023/html/Zhu_Coarse-to-Fine_Learning_Compact_Discriminative_Representation_for_Single-Stage_Image_Retrieval_ICCV_2023_paper.html)

[Yunquan Zhu](https://openaccess.thecvf.com/ICCV2023#), [Xinkai Gao](https://openaccess.thecvf.com/ICCV2023#), [Bo Ke](https://openaccess.thecvf.com/ICCV2023#), [Ruizhi Qiao](https://openaccess.thecvf.com/ICCV2023#), [Xing Sun](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhu_Coarse-to-Fine_Learning_Compact_Discriminative_Representation_for_Single-Stage_Image_Retrieval_ICCV_2023_paper.pdf)] 

[bibtex]


[Multi-weather Image Restoration via Domain Translation](https://openaccess.thecvf.com/content/ICCV2023/html/Patil_Multi-weather_Image_Restoration_via_Domain_Translation_ICCV_2023_paper.html)

[Prashant W. Patil](https://openaccess.thecvf.com/ICCV2023#), [Sunil Gupta](https://openaccess.thecvf.com/ICCV2023#), [Santu Rana](https://openaccess.thecvf.com/ICCV2023#), [Svetha Venkatesh](https://openaccess.thecvf.com/ICCV2023#), [Subrahmanyam Murala](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Patil_Multi-weather_Image_Restoration_via_Domain_Translation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Patil_Multi-weather_Image_Restoration_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Probabilistic Modeling of Inter- and Intra-observer Variability in Medical Image Segmentation](https://openaccess.thecvf.com/content/ICCV2023/html/Schmidt_Probabilistic_Modeling_of_Inter-_and_Intra-observer_Variability_in_Medical_Image_ICCV_2023_paper.html)

[Arne Schmidt](https://openaccess.thecvf.com/ICCV2023#), [Pablo Morales-Álvarez](https://openaccess.thecvf.com/ICCV2023#), [Rafael Molina](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Schmidt_Probabilistic_Modeling_of_Inter-_and_Intra-observer_Variability_in_Medical_Image_ICCV_2023_paper.pdf)] 

[bibtex]


[AdaNIC: Towards Practical Neural Image Compression via Dynamic Transform Routing](https://openaccess.thecvf.com/content/ICCV2023/html/Tao_AdaNIC_Towards_Practical_Neural_Image_Compression_via_Dynamic_Transform_Routing_ICCV_2023_paper.html)

[Lvfang Tao](https://openaccess.thecvf.com/ICCV2023#), [Wei Gao](https://openaccess.thecvf.com/ICCV2023#), [Ge Li](https://openaccess.thecvf.com/ICCV2023#), [Chenhao Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Tao_AdaNIC_Towards_Practical_Neural_Image_Compression_via_Dynamic_Transform_Routing_ICCV_2023_paper.pdf)] 

[bibtex]


[SMMix: Self-Motivated Image Mixing for Vision Transformers](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_SMMix_Self-Motivated_Image_Mixing_for_Vision_Transformers_ICCV_2023_paper.html)

[Mengzhao Chen](https://openaccess.thecvf.com/ICCV2023#), [Mingbao Lin](https://openaccess.thecvf.com/ICCV2023#), [Zhihang Lin](https://openaccess.thecvf.com/ICCV2023#), [Yuxin Zhang](https://openaccess.thecvf.com/ICCV2023#), [Fei Chao](https://openaccess.thecvf.com/ICCV2023#), [Rongrong Ji](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_SMMix_Self-Motivated_Image_Mixing_for_Vision_Transformers_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_SMMix_Self-Motivated_Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.12977)] 

[bibtex]


[Noise-Aware Learning from Web-Crawled Image-Text Data for Image Captioning](https://openaccess.thecvf.com/content/ICCV2023/html/Kang_Noise-Aware_Learning_from_Web-Crawled_Image-Text_Data_for_Image_Captioning_ICCV_2023_paper.html)

[Wooyoung Kang](https://openaccess.thecvf.com/ICCV2023#), [Jonghwan Mun](https://openaccess.thecvf.com/ICCV2023#), [Sungjun Lee](https://openaccess.thecvf.com/ICCV2023#), [Byungseok Roh](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Noise-Aware_Learning_from_Web-Crawled_Image-Text_Data_for_Image_Captioning_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kang_Noise-Aware_Learning_from_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2212.13563)] 

[bibtex]


[Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models](https://openaccess.thecvf.com/content/ICCV2023/html/Hollein_Text2Room_Extracting_Textured_3D_Meshes_from_2D_Text-to-Image_Models_ICCV_2023_paper.html)

[Lukas Höllein](https://openaccess.thecvf.com/ICCV2023#), [Ang Cao](https://openaccess.thecvf.com/ICCV2023#), [Andrew Owens](https://openaccess.thecvf.com/ICCV2023#), [Justin Johnson](https://openaccess.thecvf.com/ICCV2023#), [Matthias Nießner](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hollein_Text2Room_Extracting_Textured_3D_Meshes_from_2D_Text-to-Image_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hollein_Text2Room_Extracting_Textured_ICCV_2023_supplemental.pdf)] 

[bibtex]


[With a Little Help from Your Own Past: Prototypical Memory Networks for Image Captioning](https://openaccess.thecvf.com/content/ICCV2023/html/Barraco_With_a_Little_Help_from_Your_Own_Past_Prototypical_Memory_ICCV_2023_paper.html)

[Manuele Barraco](https://openaccess.thecvf.com/ICCV2023#), [Sara Sarto](https://openaccess.thecvf.com/ICCV2023#), [Marcella Cornia](https://openaccess.thecvf.com/ICCV2023#), [Lorenzo Baraldi](https://openaccess.thecvf.com/ICCV2023#), [Rita Cucchiara](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Barraco_With_a_Little_Help_from_Your_Own_Past_Prototypical_Memory_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Barraco_With_a_Little_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.12383)] 

[bibtex]


[Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement](https://openaccess.thecvf.com/content/ICCV2023/html/Cai_Retinexformer_One-stage_Retinex-based_Transformer_for_Low-light_Image_Enhancement_ICCV_2023_paper.html)

[Yuanhao Cai](https://openaccess.thecvf.com/ICCV2023#), [Hao Bian](https://openaccess.thecvf.com/ICCV2023#), [Jing Lin](https://openaccess.thecvf.com/ICCV2023#), [Haoqian Wang](https://openaccess.thecvf.com/ICCV2023#), [Radu Timofte](https://openaccess.thecvf.com/ICCV2023#), [Yulun Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Cai_Retinexformer_One-stage_Retinex-based_Transformer_for_Low-light_Image_Enhancement_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.06705)] 

[bibtex]


[Shatter and Gather: Learning Referring Image Segmentation with Text Supervision](https://openaccess.thecvf.com/content/ICCV2023/html/Kim_Shatter_and_Gather_Learning_Referring_Image_Segmentation_with_Text_Supervision_ICCV_2023_paper.html)

[Dongwon Kim](https://openaccess.thecvf.com/ICCV2023#), [Namyup Kim](https://openaccess.thecvf.com/ICCV2023#), [Cuiling Lan](https://openaccess.thecvf.com/ICCV2023#), [Suha Kwak](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Kim_Shatter_and_Gather_Learning_Referring_Image_Segmentation_with_Text_Supervision_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Kim_Shatter_and_Gather_Learning_Referring_Image_Segmentation_with_Text_Supervision_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.15512)] 

[bibtex]


[SAFL-Net: Semantic-Agnostic Feature Learning Network with Auxiliary Plugins for Image Manipulation Detection](https://openaccess.thecvf.com/content/ICCV2023/html/Sun_SAFL-Net_Semantic-Agnostic_Feature_Learning_Network_with_Auxiliary_Plugins_for_Image_ICCV_2023_paper.html)

[Zhihao Sun](https://openaccess.thecvf.com/ICCV2023#), [Haoran Jiang](https://openaccess.thecvf.com/ICCV2023#), [Danding Wang](https://openaccess.thecvf.com/ICCV2023#), [Xirong Li](https://openaccess.thecvf.com/ICCV2023#), [Juan Cao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Sun_SAFL-Net_Semantic-Agnostic_Feature_Learning_Network_with_Auxiliary_Plugins_for_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Sun_SAFL-Net_Semantic-Agnostic_Feature_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Anti-DreamBooth: Protecting Users from Personalized Text-to-image Synthesis](https://openaccess.thecvf.com/content/ICCV2023/html/Van_Le_Anti-DreamBooth_Protecting_Users_from_Personalized_Text-to-image_Synthesis_ICCV_2023_paper.html)

[Thanh Van Le](https://openaccess.thecvf.com/ICCV2023#), [Hao Phung](https://openaccess.thecvf.com/ICCV2023#), [Thuan Hoang Nguyen](https://openaccess.thecvf.com/ICCV2023#), [Quan Dao](https://openaccess.thecvf.com/ICCV2023#), [Ngoc N. Tran](https://openaccess.thecvf.com/ICCV2023#), [Anh Tran](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Van_Le_Anti-DreamBooth_Protecting_Users_from_Personalized_Text-to-image_Synthesis_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Van_Le_Anti-DreamBooth_Protecting_Users_ICCV_2023_supplemental.zip)] 

[bibtex]


[Treating Pseudo-labels Generation as Image Matting for Weakly Supervised Semantic Segmentation](https://openaccess.thecvf.com/content/ICCV2023/html/Wang_Treating_Pseudo-labels_Generation_as_Image_Matting_for_Weakly_Supervised_Semantic_ICCV_2023_paper.html)

[Changwei Wang](https://openaccess.thecvf.com/ICCV2023#), [Rongtao Xu](https://openaccess.thecvf.com/ICCV2023#), [Shibiao Xu](https://openaccess.thecvf.com/ICCV2023#), [Weiliang Meng](https://openaccess.thecvf.com/ICCV2023#), [Xiaopeng Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Wang_Treating_Pseudo-labels_Generation_as_Image_Matting_for_Weakly_Supervised_Semantic_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Wang_Treating_Pseudo-labels_Generation_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Learning Correction Filter via Degradation-Adaptive Regression for Blind Single Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_Learning_Correction_Filter_via_Degradation-Adaptive_Regression_for_Blind_Single_Image_ICCV_2023_paper.html)

[Hongyang Zhou](https://openaccess.thecvf.com/ICCV2023#), [Xiaobin Zhu](https://openaccess.thecvf.com/ICCV2023#), [Jianqing Zhu](https://openaccess.thecvf.com/ICCV2023#), [Zheng Han](https://openaccess.thecvf.com/ICCV2023#), [Shi-Xue Zhang](https://openaccess.thecvf.com/ICCV2023#), [Jingyan Qin](https://openaccess.thecvf.com/ICCV2023#), [Xu-Cheng Yin](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_Learning_Correction_Filter_via_Degradation-Adaptive_Regression_for_Blind_Single_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhou_Learning_Correction_Filter_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Discriminative Class Tokens for Text-to-Image Diffusion Models](https://openaccess.thecvf.com/content/ICCV2023/html/Schwartz_Discriminative_Class_Tokens_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html)

[Idan Schwartz](https://openaccess.thecvf.com/ICCV2023#), [Vésteinn Snæbjarnarson](https://openaccess.thecvf.com/ICCV2023#), [Hila Chefer](https://openaccess.thecvf.com/ICCV2023#), [Serge Belongie](https://openaccess.thecvf.com/ICCV2023#), [Lior Wolf](https://openaccess.thecvf.com/ICCV2023#), [Sagie Benaim](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Schwartz_Discriminative_Class_Tokens_for_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Schwartz_Discriminative_Class_Tokens_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Anatomical Invariance Modeling and Semantic Alignment for Self-supervised Learning in 3D Medical Image Analysis](https://openaccess.thecvf.com/content/ICCV2023/html/Jiang_Anatomical_Invariance_Modeling_and_Semantic_Alignment_for_Self-supervised_Learning_in_ICCV_2023_paper.html)

[Yankai Jiang](https://openaccess.thecvf.com/ICCV2023#), [Mingze Sun](https://openaccess.thecvf.com/ICCV2023#), [Heng Guo](https://openaccess.thecvf.com/ICCV2023#), [Xiaoyu Bai](https://openaccess.thecvf.com/ICCV2023#), [Ke Yan](https://openaccess.thecvf.com/ICCV2023#), [Le Lu](https://openaccess.thecvf.com/ICCV2023#), [Minfeng Xu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Jiang_Anatomical_Invariance_Modeling_and_Semantic_Alignment_for_Self-supervised_Learning_in_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Jiang_Anatomical_Invariance_Modeling_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.05615)] 

[bibtex]


[AGG-Net: Attention Guided Gated-Convolutional Network for Depth Image Completion](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_AGG-Net_Attention_Guided_Gated-Convolutional_Network_for_Depth_Image_Completion_ICCV_2023_paper.html)

[Dongyue Chen](https://openaccess.thecvf.com/ICCV2023#), [Tingxuan Huang](https://openaccess.thecvf.com/ICCV2023#), [Zhimin Song](https://openaccess.thecvf.com/ICCV2023#), [Shizhuo Deng](https://openaccess.thecvf.com/ICCV2023#), [Tong Jia](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_AGG-Net_Attention_Guided_Gated-Convolutional_Network_for_Depth_Image_Completion_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_AGG-Net_Attention_Guided_Gated-Convolutional_Network_for_Depth_Image_Completion_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Learning Global-aware Kernel for Image Harmonization](https://openaccess.thecvf.com/content/ICCV2023/html/Shen_Learning_Global-aware_Kernel_for_Image_Harmonization_ICCV_2023_paper.html)

[Xintian Shen](https://openaccess.thecvf.com/ICCV2023#), [Jiangning Zhang](https://openaccess.thecvf.com/ICCV2023#), [Jun Chen](https://openaccess.thecvf.com/ICCV2023#), [Shipeng Bai](https://openaccess.thecvf.com/ICCV2023#), [Yue Han](https://openaccess.thecvf.com/ICCV2023#), [Yabiao Wang](https://openaccess.thecvf.com/ICCV2023#), [Chengjie Wang](https://openaccess.thecvf.com/ICCV2023#), [Yong Liu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shen_Learning_Global-aware_Kernel_for_Image_Harmonization_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2305.11676)] 

[bibtex]


[UGC: Unified GAN Compression for Efficient Image-to-Image Translation](https://openaccess.thecvf.com/content/ICCV2023/html/Ren_UGC_Unified_GAN_Compression_for_Efficient_Image-to-Image_Translation_ICCV_2023_paper.html)

[Yuxi Ren](https://openaccess.thecvf.com/ICCV2023#), [Jie Wu](https://openaccess.thecvf.com/ICCV2023#), [Peng Zhang](https://openaccess.thecvf.com/ICCV2023#), [Manlin Zhang](https://openaccess.thecvf.com/ICCV2023#), [Xuefeng Xiao](https://openaccess.thecvf.com/ICCV2023#), [Qian He](https://openaccess.thecvf.com/ICCV2023#), [Rui Wang](https://openaccess.thecvf.com/ICCV2023#), [Min Zheng](https://openaccess.thecvf.com/ICCV2023#), [Xin Pan](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ren_UGC_Unified_GAN_Compression_for_Efficient_Image-to-Image_Translation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ren_UGC_Unified_GAN_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.09310)] 

[bibtex]


[Boosting Whole Slide Image Classification from the Perspectives of Distribution, Correlation and Magnification](https://openaccess.thecvf.com/content/ICCV2023/html/Qu_Boosting_Whole_Slide_Image_Classification_from_the_Perspectives_of_Distribution_ICCV_2023_paper.html)

[Linhao Qu](https://openaccess.thecvf.com/ICCV2023#), [Zhiwei Yang](https://openaccess.thecvf.com/ICCV2023#), [Minghong Duan](https://openaccess.thecvf.com/ICCV2023#), [Yingfan Ma](https://openaccess.thecvf.com/ICCV2023#), [Shuo Wang](https://openaccess.thecvf.com/ICCV2023#), [Manning Wang](https://openaccess.thecvf.com/ICCV2023#), [Zhijian Song](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Qu_Boosting_Whole_Slide_Image_Classification_from_the_Perspectives_of_Distribution_ICCV_2023_paper.pdf)] 

[bibtex]


[Innovating Real Fisheye Image Correction with Dual Diffusion Architecture](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Innovating_Real_Fisheye_Image_Correction_with_Dual_Diffusion_Architecture_ICCV_2023_paper.html)

[Shangrong Yang](https://openaccess.thecvf.com/ICCV2023#), [Chunyu Lin](https://openaccess.thecvf.com/ICCV2023#), [Kang Liao](https://openaccess.thecvf.com/ICCV2023#), [Yao Zhao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Innovating_Real_Fisheye_Image_Correction_with_Dual_Diffusion_Architecture_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Innovating_Real_Fisheye_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Class-incremental Continual Learning for Instance Segmentation with Image-level Weak Supervision](https://openaccess.thecvf.com/content/ICCV2023/html/Hsieh_Class-incremental_Continual_Learning_for_Instance_Segmentation_with_Image-level_Weak_Supervision_ICCV_2023_paper.html)

[Yu-Hsing Hsieh](https://openaccess.thecvf.com/ICCV2023#), [Guan-Sheng Chen](https://openaccess.thecvf.com/ICCV2023#), [Shun-Xian Cai](https://openaccess.thecvf.com/ICCV2023#), [Ting-Yun Wei](https://openaccess.thecvf.com/ICCV2023#), [Huei-Fang Yang](https://openaccess.thecvf.com/ICCV2023#), [Chu-Song Chen](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hsieh_Class-incremental_Continual_Learning_for_Instance_Segmentation_with_Image-level_Weak_Supervision_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hsieh_Class-incremental_Continual_Learning_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Prototypical Mixing and Retrieval-Based Refinement for Label Noise-Resistant Image Retrieval](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Prototypical_Mixing_and_Retrieval-Based_Refinement_for_Label_Noise-Resistant_Image_Retrieval_ICCV_2023_paper.html)

[Xinlong Yang](https://openaccess.thecvf.com/ICCV2023#), [Haixin Wang](https://openaccess.thecvf.com/ICCV2023#), [Jinan Sun](https://openaccess.thecvf.com/ICCV2023#), [Shikun Zhang](https://openaccess.thecvf.com/ICCV2023#), [Chong Chen](https://openaccess.thecvf.com/ICCV2023#), [Xian-Sheng Hua](https://openaccess.thecvf.com/ICCV2023#), [Xiao Luo](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Prototypical_Mixing_and_Retrieval-Based_Refinement_for_Label_Noise-Resistant_Image_Retrieval_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Prototypical_Mixing_and_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Class-Aware Patch Embedding Adaptation for Few-Shot Image Classification](https://openaccess.thecvf.com/content/ICCV2023/html/Hao_Class-Aware_Patch_Embedding_Adaptation_for_Few-Shot_Image_Classification_ICCV_2023_paper.html)

[Fusheng Hao](https://openaccess.thecvf.com/ICCV2023#), [Fengxiang He](https://openaccess.thecvf.com/ICCV2023#), [Liu Liu](https://openaccess.thecvf.com/ICCV2023#), [Fuxiang Wu](https://openaccess.thecvf.com/ICCV2023#), [Dacheng Tao](https://openaccess.thecvf.com/ICCV2023#), [Jun Cheng](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hao_Class-Aware_Patch_Embedding_Adaptation_for_Few-Shot_Image_Classification_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hao_Class-Aware_Patch_Embedding_ICCV_2023_supplemental.pdf)] 

[bibtex]


[TF-ICON: Diffusion-Based Training-Free Cross-Domain Image Composition](https://openaccess.thecvf.com/content/ICCV2023/html/Lu_TF-ICON_Diffusion-Based_Training-Free_Cross-Domain_Image_Composition_ICCV_2023_paper.html)

[Shilin Lu](https://openaccess.thecvf.com/ICCV2023#), [Yanzhu Liu](https://openaccess.thecvf.com/ICCV2023#), [Adams Wai-Kin Kong](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Lu_TF-ICON_Diffusion-Based_Training-Free_Cross-Domain_Image_Composition_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Lu_TF-ICON_Diffusion-Based_Training-Free_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Single Image Deblurring with Row-dependent Blur Magnitude](https://openaccess.thecvf.com/content/ICCV2023/html/Ji_Single_Image_Deblurring_with_Row-dependent_Blur_Magnitude_ICCV_2023_paper.html)

[Xiang Ji](https://openaccess.thecvf.com/ICCV2023#), [Zhixiang Wang](https://openaccess.thecvf.com/ICCV2023#), [Shin'ichi Satoh](https://openaccess.thecvf.com/ICCV2023#), [Yinqiang Zheng](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Ji_Single_Image_Deblurring_with_Row-dependent_Blur_Magnitude_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Ji_Single_Image_Deblurring_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Time Does Tell: Self-Supervised Time-Tuning of Dense Image Representations](https://openaccess.thecvf.com/content/ICCV2023/html/Salehi_Time_Does_Tell_Self-Supervised_Time-Tuning_of_Dense_Image_Representations_ICCV_2023_paper.html)

[Mohammadreza Salehi](https://openaccess.thecvf.com/ICCV2023#), [Efstratios Gavves](https://openaccess.thecvf.com/ICCV2023#), [Cees G.M. Snoek](https://openaccess.thecvf.com/ICCV2023#), [Yuki M. Asano](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Salehi_Time_Does_Tell_Self-Supervised_Time-Tuning_of_Dense_Image_Representations_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Salehi_Time_Does_Tell_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.11796)] 

[bibtex]


[Text2Video-Zero: Text-to-Image Diffusion Models are Zero-Shot Video Generators](https://openaccess.thecvf.com/content/ICCV2023/html/Khachatryan_Text2Video-Zero_Text-to-Image_Diffusion_Models_are_Zero-Shot_Video_Generators_ICCV_2023_paper.html)

[Levon Khachatryan](https://openaccess.thecvf.com/ICCV2023#), [Andranik Movsisyan](https://openaccess.thecvf.com/ICCV2023#), [Vahram Tadevosyan](https://openaccess.thecvf.com/ICCV2023#), [Roberto Henschel](https://openaccess.thecvf.com/ICCV2023#), [Zhangyang Wang](https://openaccess.thecvf.com/ICCV2023#), [Shant Navasardyan](https://openaccess.thecvf.com/ICCV2023#), [Humphrey Shi](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Khachatryan_Text2Video-Zero_Text-to-Image_Diffusion_Models_are_Zero-Shot_Video_Generators_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Khachatryan_Text2Video-Zero_Text-to-Image_Diffusion_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Leveraging Inpainting for Single-Image Shadow Removal](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Leveraging_Inpainting_for_Single-Image_Shadow_Removal_ICCV_2023_paper.html)

[Xiaoguang Li](https://openaccess.thecvf.com/ICCV2023#), [Qing Guo](https://openaccess.thecvf.com/ICCV2023#), [Rabab Abdelfattah](https://openaccess.thecvf.com/ICCV2023#), [Di Lin](https://openaccess.thecvf.com/ICCV2023#), [Wei Feng](https://openaccess.thecvf.com/ICCV2023#), [Ivor Tsang](https://openaccess.thecvf.com/ICCV2023#), [Song Wang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Leveraging_Inpainting_for_Single-Image_Shadow_Removal_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2302.05361)] 

[bibtex]


[Neural Characteristic Function Learning for Conditional Image Generation](https://openaccess.thecvf.com/content/ICCV2023/html/Li_Neural_Characteristic_Function_Learning_for_Conditional_Image_Generation_ICCV_2023_paper.html)

[Shengxi Li](https://openaccess.thecvf.com/ICCV2023#), [Jialu Zhang](https://openaccess.thecvf.com/ICCV2023#), [Yifei Li](https://openaccess.thecvf.com/ICCV2023#), [Mai Xu](https://openaccess.thecvf.com/ICCV2023#), [Xin Deng](https://openaccess.thecvf.com/ICCV2023#), [Li Li](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_Neural_Characteristic_Function_Learning_for_Conditional_Image_Generation_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_Neural_Characteristic_Function_ICCV_2023_supplemental.pdf)] 

[bibtex]


[Personalized Semantics Excitation for Federated Image Classification](https://openaccess.thecvf.com/content/ICCV2023/html/Xia_Personalized_Semantics_Excitation_for_Federated_Image_Classification_ICCV_2023_paper.html)

[Haifeng Xia](https://openaccess.thecvf.com/ICCV2023#), [Kai Li](https://openaccess.thecvf.com/ICCV2023#), [Zhengming Ding](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Xia_Personalized_Semantics_Excitation_for_Federated_Image_Classification_ICCV_2023_paper.pdf)] 

[bibtex]


[Implicit Neural Representation for Cooperative Low-light Image Enhancement](https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Implicit_Neural_Representation_for_Cooperative_Low-light_Image_Enhancement_ICCV_2023_paper.html)

[Shuzhou Yang](https://openaccess.thecvf.com/ICCV2023#), [Moxuan Ding](https://openaccess.thecvf.com/ICCV2023#), [Yanmin Wu](https://openaccess.thecvf.com/ICCV2023#), [Zihan Li](https://openaccess.thecvf.com/ICCV2023#), [Jian Zhang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Implicit_Neural_Representation_for_Cooperative_Low-light_Image_Enhancement_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yang_Implicit_Neural_Representation_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.11722)] 

[bibtex]


[CiteTracker: Correlating Image and Text for Visual Tracking](https://openaccess.thecvf.com/content/ICCV2023/html/Li_CiteTracker_Correlating_Image_and_Text_for_Visual_Tracking_ICCV_2023_paper.html)

[Xin Li](https://openaccess.thecvf.com/ICCV2023#), [Yuqing Huang](https://openaccess.thecvf.com/ICCV2023#), [Zhenyu He](https://openaccess.thecvf.com/ICCV2023#), [Yaowei Wang](https://openaccess.thecvf.com/ICCV2023#), [Huchuan Lu](https://openaccess.thecvf.com/ICCV2023#), [Ming-Hsuan Yang](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Li_CiteTracker_Correlating_Image_and_Text_for_Visual_Tracking_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Li_CiteTracker_Correlating_Image_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.11322)] 

[bibtex]


[Adding Conditional Control to Text-to-Image Diffusion Models](https://openaccess.thecvf.com/content/ICCV2023/html/Zhang_Adding_Conditional_Control_to_Text-to-Image_Diffusion_Models_ICCV_2023_paper.html)

[Lvmin Zhang](https://openaccess.thecvf.com/ICCV2023#), [Anyi Rao](https://openaccess.thecvf.com/ICCV2023#), [Maneesh Agrawala](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Adding_Conditional_Control_to_Text-to-Image_Diffusion_Models_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Zhang_Adding_Conditional_Control_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2302.05543)] 

[bibtex]


[Unleashing Text-to-Image Diffusion Models for Visual Perception](https://openaccess.thecvf.com/content/ICCV2023/html/Zhao_Unleashing_Text-to-Image_Diffusion_Models_for_Visual_Perception_ICCV_2023_paper.html)

[Wenliang Zhao](https://openaccess.thecvf.com/ICCV2023#), [Yongming Rao](https://openaccess.thecvf.com/ICCV2023#), [Zuyan Liu](https://openaccess.thecvf.com/ICCV2023#), [Benlin Liu](https://openaccess.thecvf.com/ICCV2023#), [Jie Zhou](https://openaccess.thecvf.com/ICCV2023#), [Jiwen Lu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_Unleashing_Text-to-Image_Diffusion_Models_for_Visual_Perception_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.02153)] 

[bibtex]


[Adaptive Image Anonymization in the Context of Image Classification with Neural Networks](https://openaccess.thecvf.com/content/ICCV2023/html/Shvai_Adaptive_Image_Anonymization_in_the_Context_of_Image_Classification_with_ICCV_2023_paper.html)

[Nadiya Shvai](https://openaccess.thecvf.com/ICCV2023#), [Arcadi Llanza Carmona](https://openaccess.thecvf.com/ICCV2023#), [Amir Nakib](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Shvai_Adaptive_Image_Anonymization_in_the_Context_of_Image_Classification_with_ICCV_2023_paper.pdf)] 

[bibtex]


[Multi-view Self-supervised Disentanglement for General Image Denoising](https://openaccess.thecvf.com/content/ICCV2023/html/Chen_Multi-view_Self-supervised_Disentanglement_for_General_Image_Denoising_ICCV_2023_paper.html)

[Hao Chen](https://openaccess.thecvf.com/ICCV2023#), [Chenyuan Qu](https://openaccess.thecvf.com/ICCV2023#), [Yu Zhang](https://openaccess.thecvf.com/ICCV2023#), [Chen Chen](https://openaccess.thecvf.com/ICCV2023#), [Jianbo Jiao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Chen_Multi-view_Self-supervised_Disentanglement_for_General_Image_Denoising_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Chen_Multi-view_Self-supervised_Disentanglement_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.05049)] 

[bibtex]


[SHERF: Generalizable Human NeRF from a Single Image](https://openaccess.thecvf.com/content/ICCV2023/html/Hu_SHERF_Generalizable_Human_NeRF_from_a_Single_Image_ICCV_2023_paper.html)

[Shoukang Hu](https://openaccess.thecvf.com/ICCV2023#), [Fangzhou Hong](https://openaccess.thecvf.com/ICCV2023#), [Liang Pan](https://openaccess.thecvf.com/ICCV2023#), [Haiyi Mei](https://openaccess.thecvf.com/ICCV2023#), [Lei Yang](https://openaccess.thecvf.com/ICCV2023#), [Ziwei Liu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Hu_SHERF_Generalizable_Human_NeRF_from_a_Single_Image_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Hu_SHERF_Generalizable_Human_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2303.12791)] 

[bibtex]


[SRFormer: Permuted Self-Attention for Single Image Super-Resolution](https://openaccess.thecvf.com/content/ICCV2023/html/Zhou_SRFormer_Permuted_Self-Attention_for_Single_Image_Super-Resolution_ICCV_2023_paper.html)

[Yupeng Zhou](https://openaccess.thecvf.com/ICCV2023#), [Zhen Li](https://openaccess.thecvf.com/ICCV2023#), [Chun-Le Guo](https://openaccess.thecvf.com/ICCV2023#), [Song Bai](https://openaccess.thecvf.com/ICCV2023#), [Ming-Ming Cheng](https://openaccess.thecvf.com/ICCV2023#), [Qibin Hou](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhou_SRFormer_Permuted_Self-Attention_for_Single_Image_Super-Resolution_ICCV_2023_paper.pdf)] [[arXiv](http://arxiv.org/abs/2303.09735)] 

[bibtex]


[Deep Homography Mixture for Single Image Rolling Shutter Correction](https://openaccess.thecvf.com/content/ICCV2023/html/Yan_Deep_Homography_Mixture_for_Single_Image_Rolling_Shutter_Correction_ICCV_2023_paper.html)

[Weilong Yan](https://openaccess.thecvf.com/ICCV2023#), [Robby T. Tan](https://openaccess.thecvf.com/ICCV2023#), [Bing Zeng](https://openaccess.thecvf.com/ICCV2023#), [Shuaicheng Liu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yan_Deep_Homography_Mixture_for_Single_Image_Rolling_Shutter_Correction_ICCV_2023_paper.pdf)] 

[bibtex]


[Neglected Free Lunch - Learning Image Classifiers Using Annotation Byproducts](https://openaccess.thecvf.com/content/ICCV2023/html/Han_Neglected_Free_Lunch_-_Learning_Image_Classifiers_Using_Annotation_Byproducts_ICCV_2023_paper.html)

[Dongyoon Han](https://openaccess.thecvf.com/ICCV2023#), [Junsuk Choe](https://openaccess.thecvf.com/ICCV2023#), [Seonghyeok Chun](https://openaccess.thecvf.com/ICCV2023#), [John Joon Young Chung](https://openaccess.thecvf.com/ICCV2023#), [Minsuk Chang](https://openaccess.thecvf.com/ICCV2023#), [Sangdoo Yun](https://openaccess.thecvf.com/ICCV2023#), [Jean Y. Song](https://openaccess.thecvf.com/ICCV2023#), [Seong Joon Oh](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Han_Neglected_Free_Lunch_-_Learning_Image_Classifiers_Using_Annotation_Byproducts_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Han_Neglected_Free_Lunch_ICCV_2023_supplemental.pdf)] 

[bibtex]


[RLIPv2: Fast Scaling of Relational Language-Image Pre-Training](https://openaccess.thecvf.com/content/ICCV2023/html/Yuan_RLIPv2_Fast_Scaling_of_Relational_Language-Image_Pre-Training_ICCV_2023_paper.html)

[Hangjie Yuan](https://openaccess.thecvf.com/ICCV2023#), [Shiwei Zhang](https://openaccess.thecvf.com/ICCV2023#), [Xiang Wang](https://openaccess.thecvf.com/ICCV2023#), [Samuel Albanie](https://openaccess.thecvf.com/ICCV2023#), [Yining Pan](https://openaccess.thecvf.com/ICCV2023#), [Tao Feng](https://openaccess.thecvf.com/ICCV2023#), [Jianwen Jiang](https://openaccess.thecvf.com/ICCV2023#), [Dong Ni](https://openaccess.thecvf.com/ICCV2023#), [Yingya Zhang](https://openaccess.thecvf.com/ICCV2023#), [Deli Zhao](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Yuan_RLIPv2_Fast_Scaling_of_Relational_Language-Image_Pre-Training_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Yuan_RLIPv2_Fast_Scaling_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2308.09351)] 

[bibtex]


[Video Task Decathlon: Unifying Image and Video Tasks in Autonomous Driving](https://openaccess.thecvf.com/content/ICCV2023/html/Huang_Video_Task_Decathlon_Unifying_Image_and_Video_Tasks_in_Autonomous_ICCV_2023_paper.html)

[Thomas E. Huang](https://openaccess.thecvf.com/ICCV2023#), [Yifan Liu](https://openaccess.thecvf.com/ICCV2023#), [Luc Van Gool](https://openaccess.thecvf.com/ICCV2023#), [Fisher Yu](https://openaccess.thecvf.com/ICCV2023#)

[[pdf](https://openaccess.thecvf.com/content/ICCV2023/papers/Huang_Video_Task_Decathlon_Unifying_Image_and_Video_Tasks_in_Autonomous_ICCV_2023_paper.pdf)] [[supp](https://openaccess.thecvf.com/content/ICCV2023/supplemental/Huang_Video_Task_Decathlon_ICCV_2023_supplemental.pdf)] [[arXiv](http://arxiv.org/abs/2309.04422)] 

[bibtex]

##### 图像信号处理领域的旗舰会议

ICIP

